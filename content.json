{"meta":{"title":"倚楼听风雨","subtitle":"淡看江湖路","description":"青苔边，折梅不赏;古道旁，煮酒不饮。","author":"xbynet","url":"http://xbynet.top"},"pages":[{"title":"","date":"2017-12-17T06:38:27.031Z","updated":"2017-12-17T06:38:27.031Z","comments":true,"path":"404.html","permalink":"http://xbynet.top/404.html","excerpt":"","text":""},{"title":"分类","date":"2017-12-16T09:58:38.000Z","updated":"2017-12-17T06:38:27.039Z","comments":true,"path":"categories/index.html","permalink":"http://xbynet.top/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2017-12-16T09:59:31.000Z","updated":"2017-12-19T03:15:04.490Z","comments":true,"path":"about/index.html","permalink":"http://xbynet.top/about/index.html","excerpt":"","text":"倚楼听风雨，淡看江湖路。青苔边，折梅不赏;古道旁，煮酒不饮。"},{"title":"标签","date":"2017-12-16T09:57:47.000Z","updated":"2017-12-17T06:38:27.090Z","comments":true,"path":"tags/index.html","permalink":"http://xbynet.top/tags/index.html","excerpt":"","text":""},{"title":"相册","date":"2017-12-18T14:43:31.000Z","updated":"2017-12-18T17:49:53.796Z","comments":true,"path":"photos/index.html","permalink":"http://xbynet.top/photos/index.html","excerpt":"","text":""},{"title":"","date":"2017-12-17T06:38:27.038Z","updated":"2017-12-17T06:38:27.038Z","comments":true,"path":"asserts/js/APlayer.min.js","permalink":"http://xbynet.top/asserts/js/APlayer.min.js","excerpt":"","text":"!function(e,t){\"object\"==typeof exports&&\"object\"==typeof module?module.exports=t():\"function\"==typeof define&&define.amd?define(\"APlayer\",[],t):\"object\"==typeof exports?exports.APlayer=t():e.APlayer=t()}(this,function(){return function(e){function t(r){if(n[r])return n[r].exports;var a=n[r]={i:r,l:!1,exports:{}};return e[r].call(a.exports,a,a.exports,t),a.l=!0,a.exports}var n={};return t.m=e,t.c=n,t.i=function(e){return e},t.d=function(e,n,r){t.o(e,n)||Object.defineProperty(e,n,{configurable:!1,enumerable:!0,get:r})},t.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return t.d(n,\"a\",n),n},t.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},t.p=\"\",t(t.s=13)}([function(e,t,n){var r=n(3);\"string\"==typeof r&&(r=[[e.i,r,\"\"]]);n(10)(r,{});r.locals&&(e.exports=r.locals)},function(e,t,n){\"use strict\";function r(e){var t=e.length;if(t%4>0)throw new Error(\"Invalid string. Length must be a multiple of 4\");return\"=\"===e[t-2]?2:\"=\"===e[t-1]?1:0}function a(e){return 3*e.length/4-r(e)}function i(e){var t,n,a,i,o,l,s=e.length;o=r(e),l=new c(3*s/4-o),a=o>0?s-4:s;var u=0;for(t=0,n=0;t>12&63]+u[e>>6&63]+u[63&e]}function l(e,t,n){for(var r,a=[],i=t;i=0,n2147483647?n=2147483647:n=0;u--){for(var c=!0,h=0;ha&&(r=a):r=a;var i=t.length;if(i%2!=0)throw new TypeError(\"Invalid hex string\");r>i/2&&(r=i/2);for(var o=0;o239?4:i>223?3:i>191?2:1;if(a+le.length)throw new RangeError(\"Index out of range\");if(n-1&&i.push(239,191,189);continue}if(o+1===r){(t-=3)>-1&&i.push(239,191,189);continue}a=n;continue}if(n-1&&i.push(239,191,189),a=n;continue}n=65536+(a-552966&63|128,63&n|128)}else{if(!(n>18|240,n>>12&63|128,n>>6&63|128,63&n|128)}}return i}function Z(e){for(var t=[],n=0;n>8,a=n%256,i.push(a),i.push(r);return i}function Q(e){return W.toByteArray(J(e))}function V(e,t,n,r){for(var a=0;a=t.length||a>=e.length);++a)t[a+n]=e[a];return a}function K(e){return e!==e}/*! * The buffer module from node.js, for the browser. * * @author Feross Aboukhadijeh * @license MIT */ var W=n(1),X=n(6),$=n(7);t.Buffer=o,t.SlowBuffer=m,t.INSPECT_MAX_BYTES=50,o.TYPED_ARRAY_SUPPORT=void 0!==e.TYPED_ARRAY_SUPPORT?e.TYPED_ARRAY_SUPPORT:r(),t.kMaxLength=a(),o.poolSize=8192,o._augment=function(e){return e.__proto__=o.prototype,e},o.from=function(e,t,n){return l(null,e,t,n)},o.TYPED_ARRAY_SUPPORT&&(o.prototype.__proto__=Uint8Array.prototype,o.__proto__=Uint8Array,\"undefined\"!=typeof Symbol&&Symbol.species&&o[Symbol.species]===o&&Object.defineProperty(o,Symbol.species,{value:null,configurable:!0})),o.alloc=function(e,t,n){return u(null,e,t,n)},o.allocUnsafe=function(e){return p(null,e)},o.allocUnsafeSlow=function(e){return p(null,e)},o.isBuffer=function(e){return!(null==e||!e._isBuffer)},o.compare=function(e,t){if(!o.isBuffer(e)||!o.isBuffer(t))throw new TypeError(\"Arguments must be Buffers\");if(e===t)return 0;for(var n=e.length,r=t.length,a=0,i=Math.min(n,r);a>1,p=-7,c=n?a-1:0,h=n?-1:1,f=e[t+c];for(c+=h,i=f&(1=-p,p+=l;p>0;i=256*i+e[t+c],c+=h,p-=8);for(o=i&(1=-p,p+=r;p>0;o=256*o+e[t+c],c+=h,p-=8);if(0===i)i=1-u;else{if(i===s)return o?NaN:1/0*(f?-1:1);o+=Math.pow(2,r),i-=u}return(f?-1:1)*o*Math.pow(2,i-r)},t.write=function(e,t,n,r,a,i){var o,l,s,u=8*i-a-1,p=(11,h=23===a?Math.pow(2,-24)-Math.pow(2,-77):0,f=r?0:i-1,d=r?1:-1,y=t=2&&(o++,s/=2),o+c>=p?(l=0,o=p):o+c>=1?(l=(t*s-1)*Math.pow(2,a),o+=c):(l=t*Math.pow(2,c-1)*Math.pow(2,a),o=0));a>=8;e[n+f]=255&l,f+=d,l/=256,a-=8);for(o=o=0;r--){var a=e[r];\".\"===a?e.splice(r,1):\"..\"===a?(e.splice(r,1),n++):n&&(e.splice(r,1),n--)}if(t)for(;n--;n)e.unshift(\"..\");return e}function r(e,t){if(e.filter)return e.filter(t);for(var n=[],r=0;r=-1&&!a;i--){var o=i>=0?arguments[i]:e.cwd();if(\"string\"!=typeof o)throw new TypeError(\"Arguments to path.resolve must be strings\");o&&(t=o+\"/\"+t,a=\"/\"===o.charAt(0))}return t=n(r(t.split(\"/\"),function(e){return!!e}),!a).join(\"/\"),(a?\"/\":\"\")+t||\".\"},t.normalize=function(e){var a=t.isAbsolute(e),i=\"/\"===o(e,-1);return e=n(r(e.split(\"/\"),function(e){return!!e}),!a).join(\"/\"),e||a||(e=\".\"),e&&i&&(e+=\"/\"),(a?\"/\":\"\")+e},t.isAbsolute=function(e){return\"/\"===e.charAt(0)},t.join=function(){var e=Array.prototype.slice.call(arguments,0);return t.normalize(r(e,function(e,t){if(\"string\"!=typeof e)throw new TypeError(\"Arguments to path.join must be strings\");return e}).join(\"/\"))},t.relative=function(e,n){function r(e){for(var t=0;t=0&&\"\"===e[n];n--);return t>n?[]:e.slice(t,n-t+1)}e=t.resolve(e).substr(1),n=t.resolve(n).substr(1);for(var a=r(e.split(\"/\")),i=r(n.split(\"/\")),o=Math.min(a.length,i.length),l=o,s=0;s\\n \",this.element.innerHTML=f,this.element.offsetWidth"}],"posts":[{"title":"[历史博文迁移]Spring-Boot学习笔记","slug":"历史博文迁移-Spring-Boot学习笔记","date":"2017-12-20T08:57:08.000Z","updated":"2017-12-20T09:00:45.959Z","comments":true,"path":"2017/12/20/历史博文迁移-Spring-Boot学习笔记/","link":"","permalink":"http://xbynet.top/2017/12/20/历史博文迁移-Spring-Boot学习笔记/","excerpt":"原地址在我的segmentfault专栏里:https://segmentfault.com/a/1190000009888085,现进行部分博文迁移. Spring-Boot 1.5 学习笔记使用Spring Boot很容易创建一个独立运行（运行jar,内嵌Servlet容器）、准生产级别的基于Spring框架的项目，使用Spring Boot你可以不用或者只需要很少的Spring配置。 Spring将很多魔法带入了Spring应用程序的开发之中，其中最重要的是以下四个核心。 自动配置：针对很多Spring应用程序常见的应用功能，Spring Boot能自动提供相关配置 起步依赖：告诉Spring Boot需要什么功能，它就能引入需要的库。 命令行界面：这是Spring Boot的可选特性，借此你只需写代码就能完成完整的应用程序，无需传统项目构建。 Actuator：让你能够深入运行中的Spring Boot应用程序，一探究竟。 Java版本：推荐使用java8 构建一个Sping Boot的Maven项目，强烈推荐Spring Initializr,它从本质上来说就是一个Web应用程序，它能为你生成Spring Boot项目结构。Spring Initializr有几种用法： 1、通过Web界面使用，访问：http://start.spring.io/ 2、通过ide相关插件创建 @SpringBootApplication是Sprnig Boot项目的核心注解，主要目的是开启自动配置。使用命令 mvn spring-boot:run”在命令行启动该应用","text":"原地址在我的segmentfault专栏里:https://segmentfault.com/a/1190000009888085,现进行部分博文迁移. Spring-Boot 1.5 学习笔记使用Spring Boot很容易创建一个独立运行（运行jar,内嵌Servlet容器）、准生产级别的基于Spring框架的项目，使用Spring Boot你可以不用或者只需要很少的Spring配置。 Spring将很多魔法带入了Spring应用程序的开发之中，其中最重要的是以下四个核心。 自动配置：针对很多Spring应用程序常见的应用功能，Spring Boot能自动提供相关配置 起步依赖：告诉Spring Boot需要什么功能，它就能引入需要的库。 命令行界面：这是Spring Boot的可选特性，借此你只需写代码就能完成完整的应用程序，无需传统项目构建。 Actuator：让你能够深入运行中的Spring Boot应用程序，一探究竟。 Java版本：推荐使用java8 构建一个Sping Boot的Maven项目，强烈推荐Spring Initializr,它从本质上来说就是一个Web应用程序，它能为你生成Spring Boot项目结构。Spring Initializr有几种用法： 1、通过Web界面使用，访问：http://start.spring.io/ 2、通过ide相关插件创建 @SpringBootApplication是Sprnig Boot项目的核心注解，主要目的是开启自动配置。使用命令 mvn spring-boot:run”在命令行启动该应用 配置文件spring-boot配置文件application.properties支持的属性列表：http://docs.spring.io/spring-boot/docs/current/reference/html/common-application-properties.html1、直接在要使用的地方通过注解@Value(value=”${configName}”)就可以绑定到你想要的属性上面。2、在application.properties中的各个参数之间也可以直接引用来使用。 123com.name=&quot;111&quot;com.want=&quot;222&quot;com.dudu.yearhope=$&#123;com.name&#125;-$&#123;com.want&#125; 3、有时候属性太多了，一个个绑定到属性字段上太累，官方提倡绑定一个对象的bean，这里我们建一个ConfigBean.java类，顶部需要使用注解@ConfigurationProperties(prefix = “com.xxx”)来指明使用哪个.这点可以参考：org.springframework.boot.autoconfigure.jdbc.DataSourceProperties类的写法 这里配置完还需要在spring Boot入口类加上@EnableConfigurationProperties并指明要加载哪个bean比如：@EnableConfigurationProperties(DataSourceProperties.class) 4、有时候我们不希望把所有配置都放在application.properties里面，这时候我们可以另外定义一个，如test.properties,路径跟也放在src/main/resources下面。我们新建一个bean类,如下： 12345678@Configuration@ConfigurationProperties(prefix = &quot;com.md&quot;) @PropertySource(&quot;classpath:test.properties&quot;)public class ConfigTestBean &#123; private String name; private String want; // 省略getter和setter&#125; 5、随机值配置配置文件中${random} 可以用来生成各种不同类型的随机值，从而简化了代码生成的麻烦，例如 生成 int 值、long 值或者 string 字符串。 1234dudu.number=$&#123;random.int&#125;dudu.uuid=$&#123;random.uuid&#125;dudu.number.less.than.ten=$&#123;random.int(10)&#125;dudu.number.in.range=$&#123;random.int[1024,65536]&#125; 6、外部配置-命令行参数配置如java -jar xx.jar –server.port=9090其中server.port是application.properties里面的选项 7、Profile-多环境配置在Spring Boot中多环境配置文件名需要满足application-{profile}.properties的格式，其中{profile}对应你的环境标识，比如：application-dev.properties：开发环境application-prod.properties：生产环境想要使用对应的环境，有两种方式 只需要在application.properties中使用spring.profiles.active属性来设置，值对应上面提到的{profile}，这里就是指dev、prod这2个。 当然你也可以用命令行启动的时候带上参数：java -jar xxx.jar –spring.profiles.active=dev 还可以像这样设置SPRING_PROFILES_ACTIVE环境变量：$ export SPRING_PROFILES_ACTIVE=production 在代码里，我们还可以直接用@Profile注解来进行配置如下：12345678910111213141516171819202122/** * 测试数据库 */@Component@Profile(&quot;testdb&quot;)public class TestDBConnector implements DBConnector &#123; @Override public void configure() &#123; System.out.println(&quot;testdb&quot;); &#125;&#125;/** * 生产数据库 */@Component@Profile(&quot;devdb&quot;)public class DevDBConnector implements DBConnector &#123; @Override public void configure() &#123; System.out.println(&quot;devdb&quot;); &#125;&#125; 通过在配置文件激活具体使用哪个实现类spring.profiles.active=testdb 启动原理解析123456@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; @SpringBootApplication与@EnableAutoConfiguration@SpringBootApplication背后：打开源码看看，有三个Annotation原注解： @Configuration（@SpringBootConfiguration点开查看发现里面还是应用了@Configuration） @EnableAutoConfiguration @ComponentScan(如果不指定basePackages等属性，则默认Spring框架实现会从声明@ComponentScan所在类的package进行扫描。) @EnableAutoConfiguration这个Annotation最为重要(点开源码看看),Spring框架提供的各种名字为@Enable开头的Annotation定义？比如@EnableScheduling、@EnableCaching、@EnableMBeanExport等，@EnableAutoConfiguration的理念和做事方式其实一脉相承，简单概括一下就是，借助@Import的支持，收集和注册特定场景相关的bean定义。 @EnableScheduling是通过@Import将Spring调度框架相关的bean定义都加载到IoC容器。 @EnableMBeanExport是通过@Import将JMX相关的bean定义加载到IoC容器。 而@EnableAutoConfiguration也是借助@Import的帮助，将所有符合自动配置条件的bean定义加载到IoC容器，仅此而已！ 借助于Spring框架原有的一个工具类：SpringFactoriesLoader的支持，@EnableAutoConfiguration可以智能的自动配置SpringFactoriesLoader属于Spring框架私有的一种扩展方案，其主要功能就是从指定的配置文件META-INF/spring.factories加载配置。@EnableAutoConfiguration自动配置的魔法骑士是从classpath中搜寻所有的META-INF/spring.factories配置文件，并将其中org.springframework.boot.autoconfigure.EnableutoConfiguration对应的配置项(主要在SpringBoot的autoconfigure依赖包中)通过反射（Java Refletion）实例化为对应的标注了@Configuration的JavaConfig形式的IoC容器配置类，然后汇总为一个并加载到IoC容器。 SpringApplication执行流程1） 如果使用的是SpringApplication.run静态方法，那么，这个方法里面首先要创建一个SpringApplication实例，在初始化的时候，它会提前做几件事情： 根据classpath里面是否存在某个特征类（org.springframework.web.context.ConfigurableWebApplicationContext）来决定是否应该创建一个为Web应用使用的ApplicationContext类型。 使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationContextInitializer,ApplicationListener 2）执行run方法的逻辑，首先遍历执行所有通过SpringFactoriesLoader可以查找到并加载的SpringApplicationRunListener。调用它们的started()方法。然后创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。然后遍历调用所有SpringApplicationRunListener的environmentPrepared()的方法。之后，如果SpringApplication的showBanner属性被设置为true，则打印banner。 3） 根据用户是否明确设置了applicationContextClass类型以及初始化阶段的推断结果，决定该为当前SpringBoot应用创建什么类型的ApplicationContext并创建完成，然后根据条件决定是否添加ShutdownHook，决定是否使用自定义的BeanNameGenerator，决定是否使用自定义的ResourceLoader，当然，最重要的，将之前准备好的Environment设置给创建好的ApplicationContext使用。 4） ApplicationContext创建好之后，遍历调用先前找到的ApplicationContextInitializer的initialize（applicationContext）方法来对已经创建好的ApplicationContext进行进一步的处理。5） 遍历调用所有SpringApplicationRunListener的contextPrepared()方法。6） 最核心的一步，将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext。7） 遍历调用所有SpringApplicationRunListener的contextLoaded()方法。8） 调用ApplicationContext的refresh()方法，完成IoC容器可用的最后一道工序。9） 查找当前ApplicationContext中是否注册有CommandLineRunner，如果有，则遍历执行它们。10） 正常情况下，遍历执行SpringApplicationRunListener的finished()方法. 模板引擎Spring Boot为Spring MVC提供适用于多数应用的自动配置功能。在Spring默认基础上，自动配置添加了以下特性： 引入ContentNegotiatingViewResolver和BeanNameViewResolver beans。 对静态资源的支持，包括对WebJars的支持。 自动注册Converter，GenericConverter，Formatter beans。 对HttpMessageConverters的支持。 自动注册MessageCodeResolver。 对静态index.html的支持。 对自定义Favicon的支持。 如果想全面控制Spring MVC，你可以添加自己的@Configuration，并使用@EnableWebMvc对其注解。如果想保留Spring Boot MVC的特性，并只是添加其他的MVC配置(拦截器，formatters，视图控制器等)，你可以添加自己的WebMvcConfigurerAdapter类型的@Bean（不使用@EnableWebMvc注解）例如：配置一个拦截器12345678910111213@Configurationpublic class WebConfiguration extends WebMvcConfigurerAdapter &#123; @Bean public RemoteIpFilter remoteIpFilter() &#123; return new RemoteIpFilter(); &#125; @Bean public LocaleChangeInterceptor localeChangeInterceptor() &#123; return new LocaleChangeInterceptor(); &#125; @Override public void addInterceptors(InterceptorRegistry registry &#123; registry.addInterceptor(localeChangeInterceptor()); &#125;&#125; Spring Boot 默认为我们提供了静态资源处理，使用 WebMvcAutoConfiguration 中的配置各种属性。建议大家使用Spring Boot的默认配置方式，提供的静态资源映射如下: classpath:/META-INF/resources classpath:/resources classpath:/static classpath:/public 这使用了Spring MVC的ResourceHttpRequestHandler. Spring Boot支持多种模版引擎包括： FreeMarker Groovy Thymeleaf(官方推荐) Mustache JSP技术Spring Boot官方是不推荐的，原因有三： tomcat只支持war的打包方式，不支持可执行的jar。 Jetty 嵌套的容器不支持jsp 创建自定义error.jsp页面不会覆盖错误处理的默认视图，而应该使用自定义错误页面 当你使用上述模板引擎中的任何一个，它们默认的模板配置路径为：src/main/resources/templates。当然也可以修改这个路径 配置错误页面Spring Boot自动配置的默认错误处理器会查找名为error的视图，如果找不到就用默认的白标错误视图，如图3-1所示。因此，最简单的方法就是创建一个自定义视图，让解析出的视图名为error。这一点归根到底取决于错误视图解析时的视图解析器。  实现了Spring的View接口的Bean，其 ID为error（由Spring的BeanNameViewResolver所解析）。  如果配置了Thymeleaf，则有名为error.html的Thymeleaf模板。  如果配置了FreeMarker，则有名为error.ftl的FreeMarker模板。  如果配置了Velocity，则有名为error.vm的Velocity模板。  如果是用JSP视图，则有名为error.jsp的JSP模板。 Spring Boot会为错误视图提供如下错误属性。  timestamp：错误发生的时间。  status：HTTP状态码。  error：错误原因。  exception：异常的类名。  message：异常消息（如果这个错误是由异常引起的）。  errors：BindingResult异常里的各种错误（如果这个错误是由异常引起的）。  trace：异常跟踪信息（如果这个错误是由异常引起的）。  path：错误发生时请求的URL路径。 默认日志logback配置spring-boot-starter-logging根据不同的日志系统，你可以按如下规则组织配置文件名，就能被正确加载： Logback：logback-spring.xml, logback-spring.groovy, logback.xml Log4j：log4j-spring.properties, log4j-spring.xml, log4j.properties, log4j.xml Log4j2：log4j2-spring.xml, log4j2.xml 如果你不想用logback.xml作为Logback配置的名字，可以通过logging.config属性指定自定义的名字：logging.config=classpath:logging-config.xml 多环境日志输出据不同环境（prod:生产环境，test:测试环境，dev:开发环境）来定义不同的日志输出，在 logback-spring.xml中使用 springProfile 节点来定义，方法如下：文件名称不是logback.xml，想使用spring扩展profile支持，要以logback-spring.xml命名12345678&lt;!-- 测试环境+开发环境. 多个使用逗号隔开. --&gt;&lt;springProfile name=&quot;test,dev&quot;&gt; &lt;logger name=&quot;com.dudu.controller&quot; level=&quot;info&quot; /&gt;&lt;/springProfile&gt;&lt;!-- 生产环境. --&gt;&lt;springProfile name=&quot;prod&quot;&gt; &lt;logger name=&quot;com.dudu.controller&quot; level=&quot;ERROR&quot; /&gt;&lt;/springProfile&gt; 可以启动服务的时候指定 profile （如不指定使用默认），如指定prod 的方式为：java -jar xxx.jar –spring.profiles.active=prod 数据源与事务配置1、使用普通jdbc12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; application.properties中配置数据源信息。1234spring.datasource.url = jdbc:mysql://localhost:3306/spring?useUnicode=true&amp;characterEncoding=utf-8spring.datasource.username = rootspring.datasource.password = rootspring.datasource.driver-class-name = com.mysql.jdbc.Driver 自定义数据源12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.19&lt;/version&gt;&lt;/dependency&gt; 1234567891011121314151617181920212223242526272829@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Autowired private Environment env; //destroy-method=&quot;close&quot;的作用是当数据库连接不使用的时候,就把该连接重新放到数据池中,方便下次使用调用. @Bean(destroyMethod = &quot;close&quot;) public DataSource dataSource() &#123; DruidDataSource dataSource = new DruidDataSource(); dataSource.setUrl(env.getProperty(&quot;spring.datasource.url&quot;)); dataSource.setUsername(env.getProperty(&quot;spring.datasource.username&quot;));//用户名 dataSource.setPassword(env.getProperty(&quot;spring.datasource.password&quot;));//密码 dataSource.setDriverClassName(env.getProperty(&quot;spring.datasource.driver-class-name&quot;)); dataSource.setInitialSize(2);//初始化时建立物理连接的个数 dataSource.setMaxActive(20);//最大连接池数量 dataSource.setMinIdle(0);//最小连接池数量 dataSource.setMaxWait(60000);//获取连接时最大等待时间，单位毫秒。 dataSource.setValidationQuery(&quot;SELECT 1&quot;);//用来检测连接是否有效的sql dataSource.setTestOnBorrow(false);//申请连接时执行validationQuery检测连接是否有效 dataSource.setTestWhileIdle(true);//建议配置为true，不影响性能，并且保证安全性。 dataSource.setPoolPreparedStatements(false);//是否缓存preparedStatement，也就是PSCache return dataSource; &#125;&#125; 覆盖Spring Boot 配置Spring Boot自动配置自带了很多配置类，每一个都能运用在你的应用程序里。它们都使用了Spring 4.0的条件化配置，可以在运行时判断这个配置是该被运用，还是该被忽略。如:12345@Bean@ConditionalOnMissingBean(JdbcOperations.class)public JdbcTemplate jdbcTemplate() &#123;return new JdbcTemplate(this.dataSource);&#125; 条件注解有如下： @ConditionalOnBean 配置了某个特定Bean @ConditionalOnMissingBean 没有配置特定的Bean @ConditionalOnClass Classpath里有指定的类 @ConditionalOnMissingClass Classpath里缺少指定的类 @ConditionalOnExpression 给定的Spring Expression Language（SpEL）表达式计算结果为true @ConditionalOnJava Java的版本匹配特定值或者一个范围值 @ConditionalOnJndi 参数中给定的JNDI位置必须存在一个，如果没有给参数，则要有JNDI InitialContext @ConditionalOnProperty 指定的配置属性要有一个明确的值 @ConditionalOnResource Classpath里有指定的资源 @ConditionalOnWebApplication 这是一个Web应用程序 @ConditionalOnNotWebApplication 这不是一个Web应用程序 单元测试12345678@RunWith(SpringRunner.class)@SpringBootTest(classes = App.class)public MyTest&#123; @Test public void test1()&#123; &#125;&#125; 测试Web 应用程序1、普通测试 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(classes = App.class)@WebAppConfigurationpublic class MockMvcWebTests &#123; @Autowired private WebApplicationContext webContext; private MockMvc mockMvc; @Before public void setupMockMvc() &#123; mockMvc = MockMvcBuilders.webAppContextSetup(webContext).build(); &#125; @Test public void homePage() throws Exception &#123; mockMvc.perform(MockMvcRequestBuilders.get(\"/readingList\")) .andExpect(MockMvcResultMatchers.status().isOk()) .andExpect(MockMvcResultMatchers.view().name(\"readingList\")) .andExpect(MockMvcResultMatchers.model().attributeExists(\"books\")) .andExpect(MockMvcResultMatchers.model().attribute(\"books\", Matchers.is(Matchers.empty()))); &#125;&#125; 首先向/readingList发起一个GET请求，接下来希望该请求处理成功（isOk()会判断HTTP 200响应码），并且视图的逻辑名称为readingList。测试还要断定模型包含一个名为books的属性，该属性是一个空集合。所有的断言都很直观。 2、测试运行中的应用程序在测试类上添加@Web-IntegrationTest注解，可以声明你不仅希望Spring Boot为测试创建应用程序上下文，还要启动一个嵌入式的Servlet容器。一旦应用程序运行在嵌入式容器里，你就可以发起真实的HTTP请求，断言结果了。这里采用@WebIntegration-Test，在服务器里启动了应用程序, 以Spring的RestTemplate对应用程序发起HTTP请求。Spring-boot 1.4以后推荐采用SpringBootTest(webEnvironment=WebEnvironment.DEFINED_PORT) (or RANDOM_PORT)来代替@WebIntegrationTest,而此类在1.5已经被移除了。https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-1.4-Release-Notes 12345678910111213141516171819@RunWith(SpringRunner.class)@SpringBootTest(classes = App.class,webEnvironment=WebEnvironment.RANDOM_PORT)public class WebInRuntimeTest &#123; @Value(\"$&#123;local.server.port&#125;\") private int port; @Autowired private TestRestTemplate template; @Test public void test1()&#123;// Assert.state(true,\"测试成功\"); System.out.println(port); ResponseEntity&lt;String&gt; response=template.getForEntity(\"/test/111\", String.class); System.out.println(response.getStatusCodeValue()); System.out.println(response.getHeaders()); System.out.println(response.getBody()); Assert.hasText(\"111\",\"true\"); &#125;&#125; 用随机端口启动服务器,@WebIntegrationTest的value属性接受一个String数组，数组中的每项都是键值对，形如name=value，用来设置测试中使用的属性。要设置server.port，你可以这样做：@WebIntegrationTest(“server.port:0”) //使用0表示端口号随机，也可以具体指定如8888这样的固定端口.或者直接这样@WebIntegrationTest(randomPort=true) Spring Boot将local.server.port的值设置为了选中的端口。我们只需使用Spring的@Value注解将其注入即可：12@Value(\"$&#123;local.server.port&#125;\")private int port; 3、使用Selenium 测试HTML 页面12345678910111213141516171819202122232425262728@RunWith(SpringRunner.class)@SpringBootTest(classes = App.class)@WebIntegrationTest(randomPort=true)public class ServerWebTests &#123; private static FirefoxDriver browser; @Value(\"$&#123;local.server.port&#125;\") private int port; @BeforeClass public static void openBrowser() &#123; browser = new FirefoxDriver(); browser.manage().timeouts().implicitlyWait(10, TimeUnit.SECONDS); &#125; @Test public void addBookToEmptyList() &#123; String baseUrl = \"http://localhost:\" + port; browser.get(baseUrl); assertEquals(\"You have no books in your book list\",browser.findElementByTagName(\"div\").getText()); browser.findElementByName(\"title\").sendKeys(\"BOOK TITLE\"); browser.findElementByTagName(\"form\").submit(); WebElement dl = browser.findElementByCssSelector(\"dt.bookHeadline\"); assertEquals(\"BOOK TITLE by BOOK AUTHOR (ISBN: 1234567890)\",dl.getText()); &#125; @AfterClass public static void closeBrowser() &#123; browser.quit(); &#125;&#125; 外部tomcat部署war配置当我们不想使用内嵌tomcat部署时，我们也可以使用外部tomcat，并打包成war：1、继承SpringBootServletInitializer外部容器部署的话，就不能依赖于Application的main函数了，而是要以类似于web.xml文件配置的方式来启动Spring应用上下文，此时我们需要在启动类中继承SpringBootServletInitializer并实现configure方法： 123456public class Application extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; return application.sources(Application.class); &#125;&#125; 这个类的作用与在web.xml中配置负责初始化Spring应用上下文的监听器作用类似，只不过在这里不需要编写额外的XML文件了。 SpringBootServletInitializer是一个支持Spring WebApplicationInitializer实现。除了配置Spring的Dispatcher-Servlet，还会在Spring应用程序上下文里查找Filter、Servlet或ServletContextInitializer类型的Bean，把它们绑定到Servlet容器里。 还有一点值得注意：就算我们在构建的是WAR文件，这个文件仍旧可以脱离应用服务器直接运行。如果你没有删除Application里的main()方法，构建过程生成的WAR文件仍可直接运行，一如可执行的JAR文件：$ java -jar readinglist-0.0.1-SNAPSHOT.war这样一来，同一个部署产物就能有两种部署方式了！ 2、pom.xml修改tomcat相关的配置如果要将最终的打包形式改为war的话，还需要对pom.xml文件进行修改，因为spring-boot-starter-web中包含内嵌的tomcat容器，所以直接部署在外部容器会冲突报错。所以需要进行依赖排除123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 开发常用的热部署方式汇总 Spring Loaded spring-boot-devtools IDE的JRebel插件 1、Spring Loaded 实现热部署Spring Loaded是一个用于在JVM运行时重新加载类文件更改的JVM代理,Spring Loaded允许你动态的新增/修改/删除某个方法/字段/构造方法,同样可以修改作用在类/方法/字段/构造方法上的注解.也可以新增/删除/改变枚举中的值。 spring-loaded是一个开源项目,项目地址:https://github.com/spring-projects/spring-loaded Spring Loaded有两种方式实现，分别是Maven引入依赖方式或者添加启动参数方式1234567891011&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;springloaded&lt;/artifactId&gt; &lt;version&gt;1.2.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 启动：mvn spring-boot:run注意：maven依赖的方式只适合spring-boot:run的启动方式，右键那种方式不行。 出现如下配置表实配置成功：[INFO] Attaching agents: [C:\\Users\\tengj.m2\\repository\\org\\springframework\\springloaded\\1.2.6.R 添加启动参数方式这种方式是右键运行启动类.首先先下载对应的springloaded-xxx.RELEASE.jar，可以去上面提到的官网获取,在VM options中输入-javaagent:&lt; pathTo &gt;/springloaded-{VERSION}.jar 上面2种方式随便选择一种即可,当系统通过 mvn spring-boot:run启动或者 右键application debug启动Java文件时，系统会监视classes文件，当有classes文件被改动时，系统会重新加载类文件，不用重启启动服务。注：IDEA下需要重新编译文件 Ctrl+Shift+F9或者编译项目 Ctrl+F9 在 Spring Boot，模板引擎的页面默认是开启缓存，如果修改页面内容，刷新页面是无法获取修改后的页面内容，所以，如果我们不需要模板引擎的缓存，可以进行关闭。1234spring.freemarker.cache=falsespring.thymeleaf.cache=falsespring.velocity.cache=falsespring.mustache.cache=false 不过还是有一些情况下需要重新启动，不可用的情况如下： 1：对于一些第三方框架的注解的修改，不能自动加载，比如：spring mvc的@RequestMapping 2：application.properties的修改也不行 3：log4j的配置文件的修改不能即时生效 2、spring-boot-devtools 实现热部署spring-boot-devtools为应用提供一些开发时特性，包括默认值设置，自动重启，livereload等。1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 将依赖关系标记为可选&lt; optional &gt;true&lt; /optional&gt;是一种最佳做法，可以防止使用项目将devtools传递性地应用于其他模块。在Spring Boot集成Thymeleaf时，spring.thymeleaf.cache属性设置为false可以禁用模板引擎编译的缓存结果。现在，devtools会自动帮你做到这些，禁用所有模板的缓存，包括Thymeleaf, Freemarker, Groovy Templates, Velocity, Mustache等。 自动重启的原理在于spring boot使用两个classloader：不改变的类（如第三方jar）由base类加载器加载，正在开发的类由restart类加载器加载。应用重启时，restart类加载器被扔掉重建，而base类加载器不变，这种方法意味着应用程序重新启动通常比“冷启动”快得多，因为base类加载器已经可用并已填充。 所以，当我们开启devtools后，classpath中的文件变化会导致应用自动重启。当然不同的IDE效果不一样，Eclipse中保存文件即可引起classpath更新(注：需要打开自动编译)，从而触发重启。而IDEA则需要自己手动CTRL+F9重新编译一下（感觉IDEA这种更好，不然每修改一个地方就重启，好蛋疼） 排除静态资源文件静态资源文件在改变之后有时候没必要触发应用程序重启，例如thymeleaf模板文件就可以实时编辑，默认情况下，更改/META-INF/maven, /META-INF/resources ,/resources ,/static ,/public 或/templates下的资源不会触发重启，而是触发live reload（devtools内嵌了一个LiveReload server，当资源发生改变时，浏览器刷新,需要浏览器插件支持）。 可以使用spring.devtools.restart.exclude属性配置，例如1spring.devtools.restart.exclude=static/**,public/** 如果想保留默认配置，同时增加新的配置，则可使用spring.devtools.restart.additional-exclude属性 观察额外的路径如果你想观察不在classpath中的路径的文件变化并触发重启，则可以配置 spring.devtools.restart.additional-paths 属性。 不在classpath内的path可以配置spring.devtools.restart.additionalpaths属性来增加到监视中，同时配置spring.devtools.restart.exclude可以选择这些path的变化是导致restart还是live reload。 关闭自动重启设置 spring.devtools.restart.enabled 属性为false，可以关闭该特性。可以在application.properties中设置，也可以通过设置环境变量的方式。1234public static void main(String[] args) &#123; System.setProperty(&quot;spring.devtools.restart.enabled&quot;, &quot;false&quot;); SpringApplication.run(MyApp.class, args);&#125; 使用一个触发文件若不想每次修改都触发自动重启，可以设置spring.devtools.restart.trigger-file指向某个文件，只有更改这个文件时才触发自动重启。 自定义自动重启类加载器默认时，IDE中打开的项目都会由restart加载器加载，jar文件由Base加载器加载，但是若你使用multi-module的项目，并且不是所有模块都被导入到IDE中，此时会导致加载器不一致。这时你可以创建META-INF/spring-devtools.properties文件，并增加restart.exclude.XXX，restart.include.XXX来配置哪些jar被restart加载，哪些被base加载。如：12restart.include.companycommonlibs=/mycorp-common-[\\\\w-]+\\.jarrestart.include.projectcommon=/mycorp-myproj-[\\\\w-]+\\.jar 如果您不想在应用程序运行时启动LiveReload服务器，则可以将spring.devtools.livereload.enabled属性设置为false。一次只能运行一个LiveReload服务器。开始应用程序之前，请确保没有其他LiveReload服务器正在运行。如果你的IDE启动多个应用程序，则只有第一个应用程序将支持LiveReload。 3、JRebel插件方式 ：略 数据库迁移库支持Spring Boot为两款流行的数据库迁移库提供了自动配置支持。 Flyway（http://flywaydb.org） Liquibase（http://www.liquibase.org） 用Flyway定义数据库迁移过程 1234&lt;dependency&gt;&lt;groupId&gt;org.flywayfb&lt;/groupId&gt;&lt;artifactId&gt;flyway-core&lt;/artifactId&gt;&lt;/dependency&gt; Flyway是一个非常简单的开源数据库迁移库，使用SQL来定义迁移脚本。它的理念是，每个脚本都有一个版本号，Flyway会顺序执行这些脚本，让数据库达到期望的状态。它也会记录已执行的脚本状态，不会重复执行。，Flyway脚本就是SQL。让其发挥作用的是其在Classpath里的位置和文件名。Flyway脚本都遵循一个命名规范，V版本号描述.sql,如`V1initdb.sql`Flyway脚本需要放在src/main/resources/db/migration里。你还需要将spring.jpa.hibernate.ddl-auto设置为none，由此告知Hibernate不要创建数据表。 原理：在应用程序部署并运行起来后，Spring Boot会检测到Classpath里的Flyway，自动配置所需的Bean。Flyway会依次查看/db/migration里的脚本，如果没有执行过就运行这些脚本。每个脚本都执行过后，向schema_version表里写一条记录。应用程序下次启动时，Flyway会先看schema_version里的记录，跳过那些脚本。 用Liquibase定义数据库迁移过程相比Flyway的优点，数据库无关性，脚本不是用sql写，而是支持yaml,json,xml等格式。1234&lt;dependency&gt;&lt;groupId&gt;org.liquibase&lt;/groupId&gt;&lt;artifactId&gt;liquibase-core&lt;/artifactId&gt;&lt;/dependency&gt; 具体介绍：略。 Actuator监控应用程序状态运行中的应用程序就像礼物盒。你可以刺探它，作出合理的推测，猜测它的运行情况。但如何了解真实的情况呢？有没有一种办法能让你深入应用程序内部一窥究竟，了解它的行为，检查它的健康状况，甚至触发一些操作来影响应用程序呢？Spring Boot的Actuator。它提供了很多生产级的特性，比如监控和度量Spring Boot应用程序。Actuator的这些特性可以通过众多REST端点、远程shell和JMX获得。 1234&lt;dependency&gt;&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 1、Actuator的Web端点端点可以分为三大类：配置端点、度量端点和其他端点 GET /autoconfig 提供了一份自动配置报告，记录哪些自动配置条件通过了，哪些没通过 GET /configprops 描述配置属性（包含默认值）如何注入Bean GET /beans 描述应用程序上下文里全部的Bean，以及它们的关系 GET /dump 获取线程活动的快照 GET /env 获取全部环境属性 GET /env/{name} 根据名称获取特定的环境属性值 GET /health 报告应用程序的健康指标，这些值由HealthIndicator的实现类提供 GET /info 获取应用程序的定制信息，这些信息由info打头的属性提供 GET /mappings 描述全部的URI路径，以及它们和控制器（包含Actuator端点）的映射关系 GET /metrics 报告各种应用程序度量信息，比如内存用量和HTTP请求计数 GET /metrics/{name} 报告指定名称的应用程序度量值 POST /shutdown 关闭应用程序，要求endpoints.shutdown.enabled设置为true GET /trace 提供基本的HTTP请求跟踪信息（时间戳、HTTP头等） /beans端点产生的报告能告诉你Spring应用程序上下文里都有哪些Bean。/autoconfig端点能告诉你为什么会有这个Bean，或者为什么没有这个Bean。Spring Boot自动配置构建于Spring的条件化配置之上。它提供了众多带有@Conditional注解的配置类，根据条件决定是否要自动配置这些Bean。/autoconfig端点提供了一个报告，列出了计算过的所有条件，根据条件是否通过进行分组。 /env端点会生成应用程序可用的所有环境属性的列表，无论这些属性是否用到。这其中包括环境变量、JVM属性、命令行参数，以及applicaition.properties或application.yml文件提供的属性。 /metrics端点提供了一些针对Web请求的基本计数器和计时器，但那些度量值缺少详细信息。知道所处理请求的更多信息是很有帮助的，尤其是在调试时，所以就有了/trace这个端点。/trace端点能报告所有Web请求的详细信息，包括请求方法、路径、时间戳以及请求和响应的头信息 2、使用:CRaSH shell 3、通过JMX 监控应用程序 参考：Book: Spring-Boot In Action嘟嘟独立博客https://github.com/tengj/SpringBootDemo","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringBoot","slug":"读书笔记/SpringBoot","permalink":"http://xbynet.top/categories/读书笔记/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://xbynet.top/tags/SpringBoot/"}]},{"title":"[editor]vscode快捷键","slug":"editor-vscode快捷键","date":"2017-12-19T09:23:32.000Z","updated":"2017-12-19T11:23:20.041Z","comments":true,"path":"2017/12/19/editor-vscode快捷键/","link":"","permalink":"http://xbynet.top/2017/12/19/editor-vscode快捷键/","excerpt":"最近从Sublime3切换到VScode，总结下快捷键。 官方地址：https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf 简单的配置 12345678&#123; &quot;files.autoSave&quot;: &quot;off&quot;, //禁用自动保存 &quot;workbench.iconTheme&quot;: &quot;vs-minimal&quot;, &quot;explorer.autoReveal&quot;: false, //禁止资源管理器在打开文件时自动显示并选择它们,类似于禁用Eclipse的link editor &quot;workbench.editor.enablePreviewFromQuickOpen&quot;: false, //使Ctrl+P打开的文件使用新的tab页，而不是替换已有的 &quot;workbench.editor.enablePreview&quot;: false //使得鼠标左键打开的文件使用新的tab页，而不是替换已有的&#125;","text":"最近从Sublime3切换到VScode，总结下快捷键。 官方地址：https://code.visualstudio.com/shortcuts/keyboard-shortcuts-windows.pdf 简单的配置 12345678&#123; &quot;files.autoSave&quot;: &quot;off&quot;, //禁用自动保存 &quot;workbench.iconTheme&quot;: &quot;vs-minimal&quot;, &quot;explorer.autoReveal&quot;: false, //禁止资源管理器在打开文件时自动显示并选择它们,类似于禁用Eclipse的link editor &quot;workbench.editor.enablePreviewFromQuickOpen&quot;: false, //使Ctrl+P打开的文件使用新的tab页，而不是替换已有的 &quot;workbench.editor.enablePreview&quot;: false //使得鼠标左键打开的文件使用新的tab页，而不是替换已有的&#125; 1、通用Ctrl+Shif+P , F1 打开命令面板 Ctrl+P 快速打开Ctrl+Shift+N 打开新实例窗口 Ctrl+Shift+W 关闭窗口实例 2、基础编辑Ctrl+X 剪切 Ctrl+C 复制Alt+下/上 移动行 shift+Alt+上/下 复制行Ctrl+Shift+K 删除行 ,改成Ctrl+DCtrl+(Shift)+Enter 插入行Ctrl+Shift+\\ 跳转到匹配的括号Ctrl+[/] 行缩进Ctrl+Shift+[/] 代码折叠Ctrl+/ 行注释，Shift+Alt+A 块注释 ,改成Ctrl+shif+/Alt+Z 是否换行(word wrap) Ctrl+空格键 智能提示 ,改成Alt+/Ctrl+Shift+Space 参数提示，Tab 自动补全Ctrl+K Ctrl+I 显示悬停(类似于鼠标hover悬停，一般用于触发提示)Shift+Alt+F 格式化文档(改成Ctrl+Shift+F)，Ctrl+K Ctrl+F 格式化选中代码F12 跳转定义，Alt+F12 查看定义 分别改成F3，Alt+F3Ctrl+K F12 在侧边打开定义Ctrl+. 快速修复Shift+F12 显示引用F2 重命名变量Ctrl+K M 更改文件语言类型 3、导航Ctrl+T 显示所有变量、函数名等 #Ctrl+G 跳转行Ctrl+P 打开文件Ctrl+Shift+O 跳转到变量、函数等@Ctrl+Shift+M 显示终端、错误等程序面板F8 跳转到下一个错误或警告,改成Ctrl+,Shift+F8 跳转到上一个错误或警告, 改成ctrl+shift+,Ctrl+Shift+Tab 切换编辑器,我改成了Ctrl+EAlt+左/右 向前/后Ctrl+M 切换tab焦点 4、搜索和替换Ctrl+F , Ctrl+H , F3/SHift+F3Alt+Enter 选中所有匹配搜索的 5、多光标，选择，多行编辑Ctrl+I 选中当前行Alt+Click 插入多个光标Ctrl+Alt+上/下 插入多个光标 ，改成Ctrl++Shift+Alt+上/下Ctrl+U 撤销上一次光标操作Shift+Alt+I 在选中的所有行末尾插入光标Ctrl+Shift+L , Ctrl+F2 都可以选中文中所有和当前的选择或单词同名的，重构重命名时很方便Shift+Alt+左/右 缩小、扩大选择区块Shift+Alt+鼠标拖拽 ， Ctrl+Shift+Alt+方向键 列选择Ctrl+Shift+Alt+PgUp/PgDown 列页选择 6、编辑器管理Ctrl+W, Ctrl+F4 关闭当前编辑器 , Ctrl+K Ctrl+W关闭所有Ctrl+Shift+T 重新打开上一次关闭的编辑器Ctrl+K F 关闭目录Ctrl+\\ 分割编辑器Ctrl+1/2/3 转移编辑器焦点到不同编辑组Ctrl+K (Ctrl+)左/右 转移编辑器焦点到左右组Shift+F10显示上下文菜单 7、文件管理Ctrl+N 新建文件，Ctrl+O 打开文件Ctrl+S , Ctrl+Shift+S , Ctrl+K S 保存，另存为，保存所有Ctrl+K P 复制文件路径Ctrl+K R 在资源管理器中打开文件Ctrl+K O 在新窗口打开文件 8、显示F11 全屏Shift+Alt+1 改变编辑器布局Ctrl+ =/- 放大或缩小Ctrl+B 开关侧边栏 Ctrl+Shift+E 焦点放到ExplorerCtrl+Shift+F 焦点放到搜索,改成ctrl+alt+fCtrl+Shift+G 焦点放GitCtrl+Shift+D 焦点放到DebugCtrl+Shift+X 焦点放到扩展Ctrl+Shift+H replace in files 9、调试F9 设置断点F5 开始/继续Shift+F5 停止F11/Shift+F11 step into/outF10 step overCtrl+K Ctrl+I show hover 10、终端集成Ctrl+显示集成的终端 Ctrl+Shift+ 创建新的终端Ctrl+Shift+C 复制选中Ctrl+Shift+V 粘贴到终端Ctrl+↑ / ↓ Scroll up/downShift+PgUp / PgDown Scroll page up/downCtrl+Home / End Scroll to top/bottom 针对Window快捷键冲突和Eclipse习惯改造自定义的部分12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 将键绑定放入此文件中以覆盖默认值[&#123; &quot;key&quot;: &quot;alt+/&quot;, &quot;command&quot;: &quot;editor.action.triggerSuggest&quot;, &quot;when&quot;: &quot;editorHasCompletionItemProvider &amp;&amp; editorTextFocus &amp;&amp; !editorReadonly&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+d&quot;, &quot;command&quot;: &quot;editor.action.deleteLines&quot;, &quot;when&quot;: &quot;editorTextFocus &amp;&amp; !editorReadonly&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+shift+/&quot;, &quot;command&quot;: &quot;editor.action.blockComment&quot;, &quot;when&quot;: &quot;editorTextFocus &amp;&amp; !editorReadonly&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+shift+f&quot;, &quot;command&quot;: &quot;editor.action.formatDocument&quot;, &quot;when&quot;: &quot;editorHasDocumentFormattingProvider &amp;&amp; editorTextFocus &amp;&amp; !editorReadonly&quot; &#125;, &#123; &quot;key&quot;: &quot;f3&quot;, &quot;command&quot;: &quot;editor.action.goToDeclaration&quot;, &quot;when&quot;: &quot;editorHasDefinitionProvider &amp;&amp; editorTextFocus &amp;&amp; !isInEmbeddedEditor&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+f3&quot;, &quot;command&quot;: &quot;editor.action.goToImplementation&quot;, &quot;when&quot;: &quot;editorHasImplementationProvider &amp;&amp; editorTextFocus &amp;&amp; !isInEmbeddedEditor&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+e&quot;, &quot;command&quot;: &quot;workbench.action.openPreviousRecentlyUsedEditorInGroup&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+,&quot;, &quot;command&quot;: &quot;editor.action.marker.next&quot;, &quot;when&quot;: &quot;editorFocus &amp;&amp; !editorReadonly&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+shift+,&quot;, &quot;command&quot;: &quot;editor.action.marker.prev&quot;, &quot;when&quot;: &quot;editorFocus &amp;&amp; !editorReadonly&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+shift+alt+up&quot;, &quot;command&quot;: &quot;editor.action.insertCursorAbove&quot;, &quot;when&quot;: &quot;editorTextFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+shift+alt+down&quot;, &quot;command&quot;: &quot;editor.action.insertCursorBelow&quot;, &quot;when&quot;: &quot;editorTextFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;ctrl+alt+f&quot;, &quot;command&quot;: &quot;search.action.focusActiveEditor&quot;, &quot;when&quot;: &quot;searchInputBoxFocus &amp;&amp; searchViewletVisible&quot; &#125;] 推荐插件：Auto Close TagBeautifyDebugger for chromeMarkdown All in OnenpmPaste Image - 用hexo写博客，自动粘贴写md文档特别爽vscode-hexo","categories":[{"name":"杂项","slug":"杂项","permalink":"http://xbynet.top/categories/杂项/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"http://xbynet.top/tags/vscode/"},{"name":"editor","slug":"editor","permalink":"http://xbynet.top/tags/editor/"}]},{"title":"[SpringCloud官文笔记]SpringCloud-Contract","slug":"SpringCloud官文笔记-SpringCloud-Contract","date":"2017-12-19T08:33:28.000Z","updated":"2017-12-19T11:38:02.363Z","comments":true,"path":"2017/12/19/SpringCloud官文笔记-SpringCloud-Contract/","link":"","permalink":"http://xbynet.top/2017/12/19/SpringCloud官文笔记-SpringCloud-Contract/","excerpt":"You need confidence when pushing new features to a new application or service in a distributed system. This project provides support for Consumer Driven Contracts and service schemas in Spring applications (for both HTTP and message-based interactions), covering a range of options for writing tests, publishing them as assets, and asserting that a contract is kept by producers and consumers. Spring Cloud Contract Verifier IntroductionSpring Cloud Contract Verifier enables Consumer Driven Contract (CDC) development of JVM-based applications. It moves TDD to the level of software architecture. Spring Cloud Contract Verifier ships with Contract Definition Language (CDL). Contract definitions are used to produce the following resources: JSON stub definitions to be used by WireMock when doing integration testing on the client code (client tests). Test code must still be written by hand, and test data is produced by Spring Cloud Contract Verifier. Messaging routes, if you’re using a messaging service. We integrate with Spring Integration, Spring Cloud Stream, Spring AMQP, and Apache Camel. You can also set your own integrations. Acceptance tests (in JUnit or Spock) are used to verify if server-side implementation of the API is compliant with the contract (server tests). A full test is generated by Spring Cloud Contract Verifier. Why a Contract Verifier?让我们设想如下场景，一个系统由很多微服务组成：那么如何测试其中的某个微服务呢。一般而言，有两种方式：1、部署所有的微服务，然后进行end-to-end测试优点：1、模拟生产环境；2、测试服务之间的真实交互缺点：必须全部部署，会化很长时间，反馈比较慢，难以debug。2、Mock其他的微服务进行单元/集成测试。优点：快速反馈，不需要基础设施。缺点：需要服务创建stubs，而一般地这是没有实际意义的；You can go to production with passing tests and failing production. Spring Cloud Contract Verifier with Stub Runner就是为了解决上述问题而创建的。","text":"You need confidence when pushing new features to a new application or service in a distributed system. This project provides support for Consumer Driven Contracts and service schemas in Spring applications (for both HTTP and message-based interactions), covering a range of options for writing tests, publishing them as assets, and asserting that a contract is kept by producers and consumers. Spring Cloud Contract Verifier IntroductionSpring Cloud Contract Verifier enables Consumer Driven Contract (CDC) development of JVM-based applications. It moves TDD to the level of software architecture. Spring Cloud Contract Verifier ships with Contract Definition Language (CDL). Contract definitions are used to produce the following resources: JSON stub definitions to be used by WireMock when doing integration testing on the client code (client tests). Test code must still be written by hand, and test data is produced by Spring Cloud Contract Verifier. Messaging routes, if you’re using a messaging service. We integrate with Spring Integration, Spring Cloud Stream, Spring AMQP, and Apache Camel. You can also set your own integrations. Acceptance tests (in JUnit or Spock) are used to verify if server-side implementation of the API is compliant with the contract (server tests). A full test is generated by Spring Cloud Contract Verifier. Why a Contract Verifier?让我们设想如下场景，一个系统由很多微服务组成：那么如何测试其中的某个微服务呢。一般而言，有两种方式：1、部署所有的微服务，然后进行end-to-end测试优点：1、模拟生产环境；2、测试服务之间的真实交互缺点：必须全部部署，会化很长时间，反馈比较慢，难以debug。2、Mock其他的微服务进行单元/集成测试。优点：快速反馈，不需要基础设施。缺点：需要服务创建stubs，而一般地这是没有实际意义的；You can go to production with passing tests and failing production. Spring Cloud Contract Verifier with Stub Runner就是为了解决上述问题而创建的。 官方例子:https://github.com/spring-cloud-samples/spring-cloud-contract-samples 通常我们开发中主要由服务提供方约定接口，虽然提供方架构调整或改变接口之前通常会通知消费者，但可能还存在上述风险，如果上线出现问题就GG了，而CDC则是以消费者提出接口契约，交由服务提供方实现，并以测试用例对契约进行产生约束，所以服务提供方在满足测试用例的情况下可以自行更改接口或架构实现而不影响消费者。 消费者驱动的契约测试（Consumer-Driven Contracts，简称CDC），是指从消费者业务实现的角度出发，驱动出契约，再基于契约，对提供者验证的一种测试方式。 服务端是基于消费端的契约来开发接口，而测试用例由ContractVerifier依据锲约生成，因此就形成了对契约的约束，也就是消费端对服务提供方的约束，如果服务端不能满足测试用例则就不能通过测试。在消费端，开发者也是基于功能而产生的符合自己需求的契约，并编写了单元测试，因此就形成了完整的开发测试流程，并且能更早的发现服务端接口变动，确保了服务的可用性。使用SpringCloudContracts可以满足CDC测试. Spring Cloud Contract Verifier with Stub Runner的目标: To ensure that WireMock/Messaging stubs (used when developing the client) do exactly what the actual server-side implementation does. To promote ATDD method and Microservices architectural style. To provide a way to publish changes in contracts that are immediately visible on both sides. To generate boilerplate test code to be used on the server side. How It Works1、Defining the contract：定义约束规则和我们的期望值Assume that you want to send a request containing the ID of a client company and the amount it wants to borrow from us. You also want to send it to the /fraudcheck url via the PUT method.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455org.springframework.cloud.contract.spec.Contract.make &#123; request &#123; // (1) method 'PUT' // (2) url '/fraudcheck' // (3) body([ // (4) \"client.id\": $(regex('[0-9]&#123;10&#125;')), loanAmount: 99999 ]) headers &#123; // (5) contentType('application/json') &#125; &#125; response &#123; // (6) status 200 // (7) body([ // (8) fraudCheckStatus: \"FRAUD\", \"rejection.reason\": \"Amount too high\" ]) headers &#123; // (9) contentType('application/json') &#125; &#125;&#125;/*From the Consumer perspective, when shooting a request in the integration test:(1) - If the consumer sends a request(2) - With the \"PUT\" method(3) - to the URL \"/fraudcheck\"(4) - with the JSON body that * has a field `clientId` that matches a regular expression `[0-9]&#123;10&#125;` * has a field `loanAmount` that is equal to `99999`(5) - with header `Content-Type` equal to `application/json`(6) - then the response will be sent with(7) - status equal `200`(8) - and JSON body equal to &#123; \"fraudCheckStatus\": \"FRAUD\", \"rejectionReason\": \"Amount too high\" &#125;(9) - with header `Content-Type` equal to `application/json`From the Producer perspective, in the autogenerated producer-side test:(1) - A request will be sent to the producer(2) - With the \"PUT\" method(3) - to the URL \"/fraudcheck\"(4) - with the JSON body that * has a field `clientId` that will have a generated value that matches a regular expression `[0-9]&#123;10&#125;` * has a field `loanAmount` that is equal to `99999`(5) - with header `Content-Type` equal to `application/json`(6) - then the test will assert if the response has been sent with(7) - status equal `200`(8) - and JSON body equal to &#123; \"fraudCheckStatus\": \"FRAUD\", \"rejectionReason\": \"Amount too high\" &#125;(9) - with header `Content-Type` matching `application/json.*` */ 2、Client Side Spring Cloud Contract generates stubs, which you can use during client-side testing. You get a running WireMock instance/Messaging route that simulates the service. You would like to feed that instance with a proper stub definition.At some point in time, you need to send a request to the Fraud Detection service.1234ResponseEntity&lt;FraudServiceResponse&gt; response = restTemplate.exchange(\"http://localhost:\" + port + \"/fraudcheck\", HttpMethod.PUT, new HttpEntity&lt;&gt;(request, httpHeaders), FraudServiceResponse.class); Annotate your test class with @AutoConfigureStubRunner. In the annotation provide the group id and artifact id for the Stub Runner to download stubs of your collaborators.12345@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment=WebEnvironment.NONE)@AutoConfigureStubRunner(ids = &#123;\"com.example:http-server-dsl:+:stubs:6565\"&#125;, workOffline = true)@DirtiesContextpublic class LoanApplicationServiceTests &#123; After that, during the tests, Spring Cloud Contract automatically finds the stubs (simulating the real service) in the Maven repository and exposes them on a configured (or random) port. 3、Server SideSince you are developing your stub, you need to be sure that it actually resembles your concrete implementation.To ensure that your application behaves the way you define in your stub, tests are generated from the stub you provide.The autogenerated test looks like this:12345678910111213141516171819@Testpublic void validate_shouldMarkClientAsFraud() throws Exception &#123; // given: MockMvcRequestSpecification request = given() .header(\"Content-Type\", \"application/vnd.fraud.v1+json\") .body(\"&#123;\\\"client.id\\\":\\\"1234567890\\\",\\\"loanAmount\\\":99999&#125;\"); // when: ResponseOptions response = given().spec(request) .put(\"/fraudcheck\"); // then: assertThat(response.statusCode()).isEqualTo(200); assertThat(response.header(\"Content-Type\")).matches(\"application/vnd.fraud.v1.json.*\"); // and: DocumentContext parsedJson = JsonPath.parse(response.getBody().asString()); assertThatJson(parsedJson).field(\"['fraudCheckStatus']\").matches(\"[A-Z]&#123;5&#125;\"); assertThatJson(parsedJson).field(\"['rejection.reason']\").isEqualTo(\"Amount too high\");&#125; 太过复杂，此处不作翻译，入门建议参考：http://blog.csdn.net/j3t9z7h/article/details/78590351http://www.infoq.com/cn/news/2017/04/spring-cloud-contracthttp://www.sohu.com/a/200331844_617676","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[SpringCloud官文笔记]SpringCloud-Security","slug":"SpringCloud官文笔记-SpringCloud-Security","date":"2017-12-19T08:19:41.000Z","updated":"2017-12-19T09:08:49.510Z","comments":true,"path":"2017/12/19/SpringCloud官文笔记-SpringCloud-Security/","link":"","permalink":"http://xbynet.top/2017/12/19/SpringCloud官文笔记-SpringCloud-Security/","excerpt":"Building on Spring Boot and Spring Security OAuth2 we can quickly create systems that implement common patterns like single sign on, token relay and token exchange.","text":"Building on Spring Boot and Spring Security OAuth2 we can quickly create systems that implement common patterns like single sign on, token relay and token exchange. Quickstart实例地址：https://github.com/spring-cloud-samples/sso/blob/master/src/main/java/demo/SsoApplication.java More Detail略。待细看","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[SpringCloud官文笔记]SpringCloud-Sleuth","slug":"SpringCloud官文笔记-SpringCloud-Sleuth","date":"2017-12-19T07:31:57.000Z","updated":"2017-12-19T09:09:12.068Z","comments":true,"path":"2017/12/19/SpringCloud官文笔记-SpringCloud-Sleuth/","link":"","permalink":"http://xbynet.top/2017/12/19/SpringCloud官文笔记-SpringCloud-Sleuth/","excerpt":"Spring Cloud Sleuth implements a distributed tracing solution for Spring Cloud.它是基于google的Dapper实现的。Span：基本工作单元，span通过一个64位ID唯一标识，trace以另一个64位ID表示，span还有其他数据信息，比如摘要、时间戳事件、键值对注释、span的ID、以及span父ID等span在不断的启动和停止，同时记录了时间信息，当你创建了一个span，你必须在未来的某个时刻停止它。初始化span称为”root span”,该span的id和trace的id相等。Trace：一系列spans组成的一个树状结构(root span为根共享),trace也用一个64位的id唯一标识，trace中的所有span都共享该trace id。Annotation：用来及时记录一个事件的存在，一些核心annotations用来定义一个请求的开始和结束 cs - Client Sent -客户端发起一个请求，这个annotion描述了这个span的开始 sr - Server Received -服务端获得请求并准备开始处理它，如果将其sr减去cs时间戳，便可得到网络延迟 ss - Server Sent -注解表明请求处理的完成(当请求返回客户端)，如果ss减去sr时间戳，便可得到服务端需要的处理请求所需的时间 cr - Client Received -表明span的结束，客户端成功接收到服务端的回复，如果cr减去cs时间戳，便可得到客户端从服务端获取回复的所有所需时间 Each color of a note signifies a span (7 spans - from A to G). If you have such information in the note:123Trace Id = XSpan Id = DClient Sent That means that the current span has Trace-Id set to X, Span-Id set to D. It also has emitted Client Sent event.span的父子关系如下：","text":"Spring Cloud Sleuth implements a distributed tracing solution for Spring Cloud.它是基于google的Dapper实现的。Span：基本工作单元，span通过一个64位ID唯一标识，trace以另一个64位ID表示，span还有其他数据信息，比如摘要、时间戳事件、键值对注释、span的ID、以及span父ID等span在不断的启动和停止，同时记录了时间信息，当你创建了一个span，你必须在未来的某个时刻停止它。初始化span称为”root span”,该span的id和trace的id相等。Trace：一系列spans组成的一个树状结构(root span为根共享),trace也用一个64位的id唯一标识，trace中的所有span都共享该trace id。Annotation：用来及时记录一个事件的存在，一些核心annotations用来定义一个请求的开始和结束 cs - Client Sent -客户端发起一个请求，这个annotion描述了这个span的开始 sr - Server Received -服务端获得请求并准备开始处理它，如果将其sr减去cs时间戳，便可得到网络延迟 ss - Server Sent -注解表明请求处理的完成(当请求返回客户端)，如果ss减去sr时间戳，便可得到服务端需要的处理请求所需的时间 cr - Client Received -表明span的结束，客户端成功接收到服务端的回复，如果cr减去cs时间戳，便可得到客户端从服务端获取回复的所有所需时间 Each color of a note signifies a span (7 spans - from A to G). If you have such information in the note:123Trace Id = XSpan Id = DClient Sent That means that the current span has Trace-Id set to X, Span-Id set to D. It also has emitted Client Sent event.span的父子关系如下： Distributed tracing with ZipkinAltogether there are 7 spans . If you go to traces in Zipkin you will see this number in the second trace:However if you pick a particular trace then you will see 4 spans:注意：When picking a particular trace you will see merged spans. That means that if there were 2 spans sent to Zipkin with Server Received and Server Sent / Client Received and Client Sent annotations then they will presented as a single span. Why is there a difference between the 7 and 4 spans in this case? 2 spans come from http:/start span. It has the Server Received (SR) and Server Sent (SS) annotations. 2 spans come from the RPC call from service1 to service2 to the http:/foo endpoint. It has the Client Sent (CS) and Client Received (CR) annotations on service1 side. It also has Server Received (SR) and Server Sent (SS) annotations on the service2 side. Physically there are 2 spans but they form 1 logical span related to an RPC call. 2 spans come from the RPC call from service2 to service3 to the http:/bar endpoint. It has the Client Sent (CS) and Client Received (CR) annotations on service2 side. It also has Server Received (SR) and Server Sent (SS) annotations on the service3 side. Physically there are 2 spans but they form 1 logical span related to an RPC call. 2 spans come from the RPC call from service2 to service4 to the http:/baz endpoint. It has the Client Sent (CS) and Client Received (CR) annotations on service2 side. It also has Server Received (SR) and Server Sent (SS) annotations on the service4 side. Physically there are 2 spans but they form 1 logical span related to an RPC call.So if we count the physical spans we have 1 from http:/start, 2 from service1 calling service2, 2 form service2 calling service3 and 2 from service2 calling service4. Altogether 7 spans. Logically we see the information of Total Spans: 4 because we have 1 span related to the incoming request to service1 and 3 spans related to RPC calls. Visualizing errorsThen if you click on one of the spans you’ll see the following Live examplesThe dependency graph in Zipkin would look like this: Log correlation：1234567service1.log:2016-02-26 11:15:47.561 INFO [service1,2485ec27856c56f4,2485ec27856c56f4,true] 68058 --- [nio-8081-exec-1] i.s.c.sleuth.docs.service1.Application : Hello from service1. Calling service2service2.log:2016-02-26 11:15:47.710 INFO [service2,2485ec27856c56f4,9aa10ee6fbde75fa,true] 68059 --- [nio-8082-exec-1] i.s.c.sleuth.docs.service2.Application : Hello from service2. Calling service3 and then service4service3.log:2016-02-26 11:15:47.895 INFO [service3,2485ec27856c56f4,1210be13194bfe5,true] 68060 --- [nio-8083-exec-1] i.s.c.sleuth.docs.service3.Application : Hello from service3service2.log:2016-02-26 11:15:47.924 INFO [service2,2485ec27856c56f4,9aa10ee6fbde75fa,true] 68059 --- [nio-8082-exec-1] i.s.c.sleuth.docs.service2.Application : Got response from service3 [Hello from service3]service4.log:2016-02-26 11:15:48.134 INFO [service4,2485ec27856c56f4,1b1845262ffba49d,true] 68061 --- [nio-8084-exec-1] i.s.c.sleuth.docs.service4.Application : Hello from service4service2.log:2016-02-26 11:15:48.156 INFO [service2,2485ec27856c56f4,9aa10ee6fbde75fa,true] 68059 --- [nio-8082-exec-1] i.s.c.sleuth.docs.service2.Application : Got response from service4 [Hello from service4]service1.log:2016-02-26 11:15:48.182 INFO [service1,2485ec27856c56f4,2485ec27856c56f4,true] 68058 --- [nio-8081-exec-1] i.s.c.sleuth.docs.service1.Application : Got response from service2 [Hello from service2, response from service3 [Hello from service3] and from service4 [Hello from service4]] If you’re using a log aggregating tool like Kibana, Splunk etc. you can order the events that took place. An example of Kibana would look like this: Logstash配置123456filter &#123; # pattern matching logback pattern grok &#123; match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:timestamp&#125;\\s+%&#123;LOGLEVEL:severity&#125;\\s+\\[%&#123;DATA:service&#125;,%&#123;DATA:trace&#125;,%&#123;DATA:span&#125;,%&#123;DATA:exportable&#125;\\]\\s+%&#123;DATA:pid&#125;\\s+---\\s+\\[%&#123;DATA:thread&#125;\\]\\s+%&#123;DATA:class&#125;\\s+:\\s+%&#123;GREEDYDATA:rest&#125;&quot; &#125; &#125;&#125; JSON Logback with Logstash:添加依赖：net.logstash.logback:logstash-logback-encoder:4.6，12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;include resource=\"org/springframework/boot/logging/logback/defaults.xml\"/&gt; ​ &lt;springProperty scope=\"context\" name=\"springAppName\" source=\"spring.application.name\"/&gt; &lt;!-- Example for logging into the build folder of your project --&gt; &lt;property name=\"LOG_FILE\" value=\"$&#123;BUILD_FOLDER:-build&#125;/$&#123;springAppName&#125;\"/&gt;​ &lt;!-- You can override this to have a custom pattern --&gt; &lt;property name=\"CONSOLE_LOG_PATTERN\" value=\"%clr(%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;)&#123;faint&#125; %clr($&#123;LOG_LEVEL_PATTERN:-%5p&#125;) %clr($&#123;PID:- &#125;)&#123;magenta&#125; %clr(---)&#123;faint&#125; %clr([%15.15t])&#123;faint&#125; %clr(%-40.40logger&#123;39&#125;)&#123;cyan&#125; %clr(:)&#123;faint&#125; %m%n$&#123;LOG_EXCEPTION_CONVERSION_WORD:-%wEx&#125;\"/&gt; &lt;!-- Appender to log to console --&gt; &lt;appender name=\"console\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;!-- Minimum logging level to be presented in the console logs--&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- Appender to log to file --&gt;​ &lt;appender name=\"flatfile\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;$&#123;LOG_FILE&#125;&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;.%d&#123;yyyy-MM-dd&#125;.gz&lt;/fileNamePattern&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;CONSOLE_LOG_PATTERN&#125;&lt;/pattern&gt; &lt;charset&gt;utf8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; ​ &lt;!-- Appender to log to file in a JSON format --&gt; &lt;appender name=\"logstash\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;file&gt;$&#123;LOG_FILE&#125;.json&lt;/file&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;$&#123;LOG_FILE&#125;.json.%d&#123;yyyy-MM-dd&#125;.gz&lt;/fileNamePattern&gt; &lt;maxHistory&gt;7&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class=\"net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder\"&gt; &lt;providers&gt; &lt;timestamp&gt; &lt;timeZone&gt;UTC&lt;/timeZone&gt; &lt;/timestamp&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; \"severity\": \"%level\", \"service\": \"$&#123;springAppName:-&#125;\", \"trace\": \"%X&#123;X-B3-TraceId:-&#125;\", \"span\": \"%X&#123;X-B3-SpanId:-&#125;\", \"parent\": \"%X&#123;X-B3-ParentSpanId:-&#125;\", \"exportable\": \"%X&#123;X-Span-Export:-&#125;\", \"pid\": \"$&#123;PID:-&#125;\", \"thread\": \"%thread\", \"class\": \"%logger&#123;40&#125;\", \"rest\": \"%message\" &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; ​ &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"console\"/&gt; &lt;!-- uncomment this to have also JSON logs --&gt; &lt;!--&lt;appender-ref ref=\"logstash\"/&gt;--&gt; &lt;!--&lt;appender-ref ref=\"flatfile\"/&gt;--&gt; &lt;/root&gt;&lt;/configuration&gt; Adding to the project注意：你需要在 bootstrap.yml中配置spring.application.name，这样才能在Zipkin中正确显示出来。几种配置方式：1、Sleuth with Zipkin via HTTP1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 它默认包含了spring-cloud-starter-sleuth依赖。 2、Sleuth with Zipkin via RabbitMQ or KafkaIf you want to use RabbitMQ or Kafka instead of http, add the spring-rabbit or spring-kafka dependencies. The default destination name is zipkin. 注意: spring-cloud-sleuth-stream已经被废弃 and incompatible with these destinations12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.amqp&lt;/groupId&gt; &lt;artifactId&gt;spring-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; 注意：通过spring.sleuth.sampler.percentage (default 0.1, i.e. 10%).配置采样比率，如果你的访问量不大，采样比率太低，可能会导致你在Zipkin中看不到结果。 注意：the SLF4J MDC is always set and logback users will immediately see the trace and span ids in logs per the example above. Other logging systems have to configure their own formatter to get the same result. The default is logging.pattern.level set to1%5p [$&#123;spring.zipkin.service.name:$&#123;spring.application.name:-&#125;&#125;,%X&#123;X-B3-TraceId:-&#125;,%X&#123;X-B3-SpanId:-&#125;,%X&#123;X-Span-Export:-&#125;] (this is a Spring Boot feature for logback users). This means that if you’re not using SLF4J this pattern WILL NOT be automatically applied. Example logs:1232016-02-02 15:30:57.902 INFO [bar,6bfd228dc00d216b,6bfd228dc00d216b,false] 23030 --- [nio-8081-exec-3] ...2016-02-02 15:30:58.372 ERROR [bar,6bfd228dc00d216b,6bfd228dc00d216b,false] 23030 --- [nio-8081-exec-3] ...2016-02-02 15:31:01.936 INFO [bar,46ab0d418373cbc9,46ab0d418373cbc9,false] 23030 --- [nio-8081-exec-4] ... notice the [appname,traceId,spanId,exportable] entries from the MDC: spanId - the id of a specific operation that took place appname - the name of the application that logged the span traceId - the id of the latency graph that contains the span exportable - whether the log should be exported to Zipkin or not. When would you like the span not to be exportable? In the case in which you want to wrap some operation in a Span and have it written to the logs only. Sampling自定义采样器：1234@Beanpublic Sampler defaultSampler() &#123; return new AlwaysSampler();&#125; You can set the HTTP header X-B3-Flags to 1 or when doing messaging you can set spanFlags header to 1. Then the current span will be forced to be exportable regardless of the sampling decision. InstrumentationSpring Cloud Sleuth instruments all your Spring application automatically, so you shouldn’t have to do anything to activate it. The instrumentation is added using a variety of technologies according to the stack that is available, e.g. for a servlet web application we use a Filter, and for Spring Integration we use ChannelInterceptors. Span lifecycle略 Customizations略 Sending spans to ZipkinBy default if you add spring-cloud-starter-zipkin as a dependency to your project, when the span is closed, it will be sent to Zipkin over HTTP. The communication is asynchronous. You can configure the URL by setting the spring.zipkin.baseUrl property as follows:1spring.zipkin.baseUrl: http://192.168.99.100:9411/ If you want to find Zipkin via service discovery it’s enough to pass the Zipkin’s service id inside the URL (example for zipkinserver service id)1spring.zipkin.baseUrl: http://zipkinserver/ Span Data as Messages略 Metrics略。 Integrations略","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[SpringCloud官文笔记]SpringCloud-Bus","slug":"SpringCloud官文笔记-SpringCloud-Bus","date":"2017-12-19T07:15:16.000Z","updated":"2017-12-19T09:09:35.669Z","comments":true,"path":"2017/12/19/SpringCloud官文笔记-SpringCloud-Bus/","link":"","permalink":"http://xbynet.top/2017/12/19/SpringCloud官文笔记-SpringCloud-Bus/","excerpt":"This can then be used to broadcast state changes (e.g. configuration changes) or other management instructions. A key idea is that the Bus is like a distributed Actuator for a Spring Boot application that is scaled out, but it can also be used as a communication channel between apps.","text":"This can then be used to broadcast state changes (e.g. configuration changes) or other management instructions. A key idea is that the Bus is like a distributed Actuator for a Spring Boot application that is scaled out, but it can also be used as a communication channel between apps. 依赖：spring-cloud-starter-bus-amqp or spring-cloud-starter-bus-kafka application.yml.123456spring: rabbitmq: host: mybroker.com port: 5672 username: user password: secret The bus currently supports sending messages to all nodes listening or all nodes for a particular service (as defined by Eureka).There are also some http endpoints under the /bus/ actuator namespace.:/bus/env, sends key/value pairs to update each node’s Spring Environment./bus/refresh, will reload each application’s configuration, just as if they had all been pinged on their /refresh endpoint. 它还支持指定destination参数./bus/refresh?destination=customers:9000,不过这里的destination指的是ApplcationConext Id，这个id是由SpingBoot在ContextIdApplicationContextInitializer中配置的，由spring.application.name, active profiles and server.port组成destination参数还支持PathMatcher的写法，如 “`/bus/refresh?destination=customers:*`” will target all instances of the “customers” service regardless of the profiles and ports set as the ApplicationContext ID. Tracing Bus Events通过spring.cloud.bus.trace.enabled=true来启用/trace端点。 Broadcasting Your Own Events事件类型必须为RemoteApplicationEvent的实现。注册自定义事件类型，两种方式：1、将事件类型放在org.springframework.cloud.bus.event包下；2、@RemoteApplicationEventScan扫描。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[SpringCloud官文笔记]SpringCloud-Stream","slug":"SpringCloud官文笔记-SpringCloud-Stream","date":"2017-12-19T03:23:18.000Z","updated":"2017-12-19T07:14:48.986Z","comments":true,"path":"2017/12/19/SpringCloud官文笔记-SpringCloud-Stream/","link":"","permalink":"http://xbynet.top/2017/12/19/SpringCloud官文笔记-SpringCloud-Stream/","excerpt":"Spring Cloud Stream is a framework for building message-driven microservice applications.使用SpringBoot作为独立应用，使用Spring Integration 来提供对message brokers的连接。支持几种代理中间件。核心观念:发布-订阅机制，消费组，分区通过@EnableBinding来使应用程序立马连接到message broker,通过@StreamListener来定义消费者。下面的例子定义了一个用来处理接收外部消息的应用。 注意：@EnableBinding只能注解the application’s configuration classes. 不要将其注解在普通的bean上面。 官方例子见：https://github.com/spring-cloud/spring-cloud-stream-samples 12345678910111213@SpringBootApplication@EnableBinding(Sink.class) //Source, Sink, and Processor,An interface declares input and/or output channels.public class VoteRecordingSinkApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(VoteRecordingSinkApplication.class, args); &#125; @StreamListener(Sink.INPUT) public void processVote(Vote vote) &#123; votingService.recordVote(vote); &#125;&#125; Sink接口如下：123456public interface Sink &#123; String INPUT = \"input\"; @Input(Sink.INPUT)//An interface declares input and/or output channels.@Input,@Output SubscribableChannel input();&#125; SpringCloud Stream会为你创建接口实现，在使用时，你只需要简单地通过bean注入即可1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = VoteRecordingSinkApplication.class)@WebAppConfiguration@DirtiesContextpublic class StreamApplicationTests &#123; @Autowired private Sink sink; @Test public void contextLoads() &#123; assertNotNull(this.sink.input()); &#125;&#125;","text":"Spring Cloud Stream is a framework for building message-driven microservice applications.使用SpringBoot作为独立应用，使用Spring Integration 来提供对message brokers的连接。支持几种代理中间件。核心观念:发布-订阅机制，消费组，分区通过@EnableBinding来使应用程序立马连接到message broker,通过@StreamListener来定义消费者。下面的例子定义了一个用来处理接收外部消息的应用。 注意：@EnableBinding只能注解the application’s configuration classes. 不要将其注解在普通的bean上面。 官方例子见：https://github.com/spring-cloud/spring-cloud-stream-samples 12345678910111213@SpringBootApplication@EnableBinding(Sink.class) //Source, Sink, and Processor,An interface declares input and/or output channels.public class VoteRecordingSinkApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(VoteRecordingSinkApplication.class, args); &#125; @StreamListener(Sink.INPUT) public void processVote(Vote vote) &#123; votingService.recordVote(vote); &#125;&#125; Sink接口如下：123456public interface Sink &#123; String INPUT = \"input\"; @Input(Sink.INPUT)//An interface declares input and/or output channels.@Input,@Output SubscribableChannel input();&#125; SpringCloud Stream会为你创建接口实现，在使用时，你只需要简单地通过bean注入即可1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = VoteRecordingSinkApplication.class)@WebAppConfiguration@DirtiesContextpublic class StreamApplicationTests &#123; @Autowired private Sink sink; @Test public void contextLoads() &#123; assertNotNull(this.sink.input()); &#125;&#125; Main Concepts Spring Cloud Stream’s application model The Binder abstraction 实现支持Kafka and Rabbit MQ以及测试用的TestSupportBinder Persistent publish-subscribe support Consumer group support Partitioning support A pluggable Binder API The application communicates with the outside world through input and output channels injected into it by Spring Cloud Stream. Channels are connected to external brokers through middleware-specific Binder implementations. Stream的broker默认提供了两个实现以支持Kafka and Rabbit MQ，具体用哪个，是通过检测classpath。采用 publish-subscribe model定义消息来源：spring.cloud.stream.bindings.input.destination 消费者分组：(该分组下仅有一个消费者能消费到消息)spring.cloud.stream.bindings.&lt; channelName&gt;.group=组名All groups which subscribe to a given destination receive a copy of published data, but only one member of each group receives a given message from that destination. 消息持久性： That is, a binder implementation ensures that group subscriptions are persistent, and once at least one subscription for a group has been created, the group will receive messages, even if they are sent while all applications in the group are stopped. Anonymous subscriptions are non-durable by nature.所以，建议指定消息目的地的时候指定好分组。 主题分区：Stream提供对一个应用多个实例情况下的数据分区支持，在这种场景下，the broker topic会被视为拥有很多分区的结构，这样确保含有特定标识的数据总是会被同一个消费者实例消费。不管中间件是否原生支持，由于Stream的通用抽象，都可以使用这一特性。 To set up a partitioned processing scenario, you must configure both the data-producing and the data-consuming ends. Programming Model注解:@EnableBinding(仅可用于配置类中)支持多个channels的绑定声明，@Input,@Output定义不同通道.123456789101112131415161718public interface Barista &#123; @Input SubscribableChannel orders(); @Output MessageChannel hotDrinks(); @Input(\"inboundOrders\") SubscribableChannel myorders();&#125;@EnableBinding(Barista.class)public class CafeConfiguration &#123; ...&#125; Source, Sink, and Processor:For easy addressing of the most common use cases, which involve either an input channel, an output channel, or both, Spring Cloud Stream provides three predefined interfaces out of the box. 访问绑定的channelsInjecting the Bound Interfaces1234567891011121314@Componentpublic class SendingBean &#123; private Source source; @Autowired public SendingBean(Source source) &#123; this.source = source; &#125; public void sayHello(String name) &#123; source.output().send(MessageBuilder.withPayload(name).build()); &#125;&#125; Injecting Channels Directly1234567891011121314@Componentpublic class SendingBean &#123; private MessageChannel output; @Autowired public SendingBean(MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; output.send(MessageBuilder.withPayload(name).build()); &#125;&#125; 如果你自定义了channelname,那么需要修改为：1234567891011121314151617181920public interface CustomSource &#123; ... @Output(\"customOutput\") MessageChannel output();&#125;@Componentpublic class SendingBean &#123; private MessageChannel output; @Autowired public SendingBean(@Qualifier(\"customOutput\") MessageChannel output) &#123; this.output = output; &#125; public void sayHello(String name) &#123; this.output.send(MessageBuilder.withPayload(name).build()); &#125;&#125; Producing and Consuming Messages @StreamListener 可以自动进行类型转换1234567891011@EnableBinding(Sink.class)public class VoteHandler &#123; @Autowired VotingService votingService; @StreamListener(Sink.INPUT) public void handle(Vote vote) &#123; votingService.record(vote); &#125;&#125; 同时参数可以用@Payload, @Headers and @Header标注如果方法同时需要接收和发送消息：还需要加入@SendTo标注123456789101112@EnableBinding(Processor.class)public class TransformProcessor &#123; @Autowired VotingService votingService; @StreamListener(Processor.INPUT) @SendTo(Processor.OUTPUT) public VoteResult handle(Vote vote) &#123; return votingService.record(vote); &#125;&#125; 利用@StreamListener分发消息到多个满足不同condition的方法，要满足支持条件派发，使之生效，那么被派发的方法必须满足：1、返回值为void，2、必须是一个独立的消息处理方法(reactive API方式不被支持)同时，condition的写法是满足SpEL表达式的。如下：1234567891011121314@EnableBinding(Sink.class)@EnableAutoConfigurationpublic static class TestPojoWithAnnotatedArguments &#123; @StreamListener(target = Sink.INPUT, condition = \"headers['type']=='foo'\") public void receiveFoo(@Payload FooPojo fooPojo) &#123; // handle the message &#125; @StreamListener(target = Sink.INPUT, condition = \"headers['type']=='bar'\") public void receiveBar(@Payload BarPojo barPojo) &#123; // handle the message &#125;&#125; AggregationStream支持聚合多个application，并直接连接它们的input和output而不需要通过message broker。注意aggregation仅支持以下类型的applications: sources - applications with a single output channel named output, typically having a single binding of the type org.springframework.cloud.stream.messaging.Source sinks - applications with a single input channel named input, typically having a single binding of the type org.springframework.cloud.stream.messaging.Sink processors - applications with a single input channel named input and a single output channel named output, typically having a single binding of the type org.springframework.cloud.stream.messaging.Processor. 例如：12345678910@SpringBootApplicationpublic class SampleAggregateApplication &#123; public static void main(String[] args) &#123; new AggregateApplicationBuilder() .from(SourceApplication.class).args(\"--fixedDelay=5000\") .via(ProcessorApplication.class) .to(SinkApplication.class).args(\"--debug=true\").run(args); &#125;&#125; BindersbindProducer() 方法的第三个参数 contains properties (such as a partition key expression) to be used within the adapter that is created for that channel.bindConsumer()方法的第一个参数为 destination name,第二个参数为消费者组名. Binder SPI提供一些系列接口，优秀得到工具类，插件化连接中间件的自动发现策略。关键接口:Binder12345public interface Binder&lt;T, C extends ConsumerProperties, P extends ProducerProperties&gt; &#123; Binding&lt;T&gt; bindConsumer(String name, String group, T inboundBindTarget, C consumerProperties); Binding&lt;T&gt; bindProducer(String name, T outboundBindTarget, P producerProperties);&#125; A typical binder implementation consists of the following 实现Binder接口 a Spring @Configuration class that creates a bean of the type above along with the middleware connection infrastructure; a META-INF/spring.binders file found on the classpath containing one or more binder definitions, e.g.12kafka:\\org.springframework.cloud.stream.binder.kafka.config.KafkaBinderConfiguration Binder DetectionClasspath Detection,比如1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 会导致自动绑定到rabbitmq Multiple Binders on the Classpath:在META-INF/spring.binders中指定, which is a simple properties file:12rabbit:\\org.springframework.cloud.stream.binder.rabbit.config.RabbitServiceAutoConfiguration 除了上述的方式外也可以通过spring.cloud.stream.defaultBinder=rabbit来指定全局默认的实现，也可以指定到channel，如：12spring.cloud.stream.bindings.input.binder=kafkaspring.cloud.stream.bindings.output.binder=rabbit Connecting to Multiple Systems:1234567891011121314151617181920212223spring: cloud: stream: bindings: input: destination: foo binder: rabbit1 output: destination: bar binder: rabbit2 binders: rabbit1: type: rabbit environment: spring: rabbitmq: host: &lt;host1&gt; rabbit2: type: rabbit environment: spring: rabbitmq: host: &lt;host2&gt; Binder configuration properties前缀spring.cloud.stream.binders.&lt; configurationName&gt;.略。 Configuration Options1、Spring Cloud Stream Properties2、Binding Propertiesspring.cloud.stream.bindings.&lt; channelName&gt;.&lt; property&gt;=&lt; value&gt;spring.cloud.stream.default.&lt; property&gt;=&lt; value&gt;如:12spring.cloud.stream.bindings.input.destination=ticktockspring.cloud.stream.default.contentType=application/json 除了上面设置的destination,contentType外，还可以设置group，binder 还有一些关于消费者和生产者特定的配置，请参考官文。 Using dynamically bound destinations BinderAwareChannelResolver bean，当然也可以用spring.cloud.stream.dynamicDestinations来配destination的可选范围，否则所有的destination都是可选的。 123456789101112131415161718192021222324 @EnableBinding@Controllerpublic class SourceWithDynamicDestination &#123; @Autowired private BinderAwareChannelResolver resolver; @RequestMapping(path = \"/&#123;target&#125;\", method = POST, consumes = \"*/*\") @ResponseStatus(HttpStatus.ACCEPTED) public void handleRequest(@RequestBody String body, @PathVariable(\"target\") target, @RequestHeader(HttpHeaders.CONTENT_TYPE) Object contentType) &#123; sendMessage(body, target, contentType); &#125; private void sendMessage(String body, String target, Object contentType) &#123; resolver.resolveDestination(target).send(MessageBuilder.createMessage(body, new MessageHeaders(Collections.singletonMap(MessageHeaders.CONTENT_TYPE, contentType)))); &#125;&#125;curl -H \"Content-Type: application/json\" -X POST -d \"customer-1\" http://localhost:8080/customerscurl -H \"Content-Type: application/json\" -X POST -d \"order-1\" http://localhost:8080/orders 类型转换支持 JSON to/from POJO JSON to/from org.springframework.tuple.Tuple Object to/from byte[] : Either the raw bytes serialized for remote transport, bytes emitted by an application, or converted to bytes using Java serialization(requires the object to be Serializable) String to/from byte[] Object to plain text (invokes the object’s toString() method) Spring Cloud Stream can handle messages based on this information in two ways: Through its contentType settings on inbound and outbound channels，通过spring.cloud.stream.bindings.&lt; channelName&gt;.content-type来配置 Through its argument mapping performed for methods annotated with @StreamListener 注意：If no content-type property is set on an outbound channel, Spring Cloud Stream will serialize the payload using a serializer based on the Kryo serialization framework.因此反序列化的时候需要保证消费端有payload class在classpath中。 MIME types：详细介绍见官文 Customizing message conversion1234567891011121314151617181920212223242526272829@EnableBinding(Sink.class)@SpringBootApplicationpublic static class SinkApplication &#123; ... @Bean public MessageConverter customMessageConverter() &#123; return new MyCustomMessageConverter(); &#125;&#125;public class MyCustomMessageConverter extends AbstractMessageConverter &#123; public MyCustomMessageConverter() &#123; super(new MimeType(\"application\", \"bar\")); &#125; @Override protected boolean supports(Class&lt;?&gt; clazz) &#123; return (Bar.class == clazz); &#125; @Override protected Object convertFromInternal(Message&lt;?&gt; message, Class&lt;?&gt; targetClass, Object conversionHint) &#123; Object payload = message.getPayload(); return (payload instanceof Bar ? payload : new Bar((byte[]) payload)); &#125;&#125; Schema evolution support略 Inter-Application Communication略 Binder ImplementationsApache Kafka Binder1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 或者1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt;&lt;/dependency&gt; 具体见官文 RabbitMQ Binder1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 或1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; 具体见官文","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[SpringCloud官文笔记]SpringCloud-Netflix","slug":"SpringCloud官文笔记-SpringCloud-Netflix","date":"2017-12-18T06:38:52.000Z","updated":"2017-12-18T10:55:17.887Z","comments":true,"path":"2017/12/18/SpringCloud官文笔记-SpringCloud-Netflix/","link":"","permalink":"http://xbynet.top/2017/12/18/SpringCloud官文笔记-SpringCloud-Netflix/","excerpt":"SpringCloud Netflix提供Netflix OSS的集成。如Service Discovery (Eureka), Circuit Breaker (Hystrix), Intelligent Routing (Zuul) and Client Side Load Balancing (Ribbon). Service Discovery: Eureka Clients首先添加spring-cloud-starter-netflix-eureka-client依赖。当一个client注册到Eureka server时，它提供关于自身的一些元数据如host,porthealth indicatorURL,home page etc.12345678910111213141516@Configuration@ComponentScan@EnableAutoConfiguration@RestControllerpublic class Application &#123; @RequestMapping(\"/\") public String home() &#123; return \"Hello world\"; &#125; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125; 配置application.yml.指定eureka地址。一旦检测到classpath中含有eureka client的依赖，那么就会自动把自己注册到eureka server中。1234eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 关于认证，略。","text":"SpringCloud Netflix提供Netflix OSS的集成。如Service Discovery (Eureka), Circuit Breaker (Hystrix), Intelligent Routing (Zuul) and Client Side Load Balancing (Ribbon). Service Discovery: Eureka Clients首先添加spring-cloud-starter-netflix-eureka-client依赖。当一个client注册到Eureka server时，它提供关于自身的一些元数据如host,porthealth indicatorURL,home page etc.12345678910111213141516@Configuration@ComponentScan@EnableAutoConfiguration@RestControllerpublic class Application &#123; @RequestMapping(\"/\") public String home() &#123; return \"Hello world\"; &#125; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125; 配置application.yml.指定eureka地址。一旦检测到classpath中含有eureka client的依赖，那么就会自动把自己注册到eureka server中。1234eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 关于认证，略。 状态和健康检查：端点：”/info” and “/health”默认情况下，Eureka使用client heartbeat来决定客户端是否处于up状态。但是在默认情况中，Discovery Client不会发送目前的健康检查状态给Eureka，所以一旦client注册了，Eureka就会永远显示为up状态。所以我们需要启用 health checks功能：application.yml.1234eureka: client: healthcheck: enabled: true 需要注意的时，不要在bootstrap.yml中进行这样的配置,否则会导致UNKNOWN状态。 Eureka Metadata for Instances and Clients：metadata包含:hostname,ip,port,status page,health check. 额外的metadata可以配置eureka.instance.metadataMap Using the EurekaClient默认情况下EurekaClient使用Jersey作为Http交互工具，如果你不想引入它，可以排除掉，然后SpringCLoud会自动使用RestTemplate来代替。123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-client&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jersey&lt;/groupId&gt; &lt;artifactId&gt;jersey-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;com.sun.jersey.contribs&lt;/groupId&gt; &lt;artifactId&gt;jersey-apache-client4&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; Why is it so Slow to Register a Service?默认的心跳周期为30s，在经历3次心跳前，一个service对于discovery client是不可用的。原文如下：A service is not available for discovery by clients until the instance, the server and the client all have the same metadata in their local cache (so it could take 3 heartbeats).在开发、测试中，我们可以改变这一行为：eureka.instance.leaseRenewalIntervalInSeconds但在生产环境中最好不要这样做，因为内部有些计算规则，可以对租约续期作出假设。 Service Discovery: Eureka Server添加依赖：spring-cloud-starter-netflix-eureka-server123456789@SpringBootApplication@EnableEurekaServerpublic class Application &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125; server提供web ui监控界面，以及HTTP API endpoints per the normal Eureka functionality under /eureka/*. High Availability不管是Eureka Server还是client，都是将注册数据存储在内存中的。默认情况下Eureka Server也是一个Eureka client(通过互相注册来达到高可用)，需要配置至少一个别的EurekaServer的URL(作为peer，这是Eureka中的名词)。 Peer Awareness多个Eureka实例通过相互注册来达到高可用：123456789101112131415161718192021application.yml (Two Peer Aware Eureka Servers). ---spring: profiles: peer1eureka: instance: hostname: peer1 client: serviceUrl: defaultZone: http://peer2/eureka/---spring: profiles: peer2eureka: instance: hostname: peer2 client: serviceUrl: defaultZone: http://peer1/eureka/ Ip优先：默认情况下，注册到Eureka的时候使用hostname优先策略，如果想用ip优先，请配置eureka.instance.preferIpAddress=true Circuit Breaker: Hystrix ClientsHystrix是微服务中的circuit breaker pattern的实现.三个关键参数：circuitBreaker.requestVolumeThreshold (default: 20 requests) and failue percentage is greater than circuitBreaker.errorThresholdPercentage (default: &gt;50%) in a rolling window defined by metrics.rollingStats.timeInMilliseconds (default: 10 seconds), the circuit opens and the call is not made.In cases of error and an open circuit a fallback can be provided by the developer. 首先添加：spring-cloud-starter-netflix-hystrix依赖12345678910111213141516171819202122@SpringBootApplication@EnableCircuitBreakerpublic class Application &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125;@Componentpublic class StoreIntegration &#123; @HystrixCommand(fallbackMethod = \"defaultStores\") public Object getStores(Map&lt;String, Object&gt; parameters) &#123; //do stuff that might fail &#125; public Object defaultStores(Map&lt;String, Object&gt; parameters) &#123; return /* something useful */; &#125;&#125; 如果你需要对HystrixCommand作出一些配置，如超时，连接池大小等。可以参考这里和Hystrix Wiki Propagating the Security Context or using Spring ScopesHystrix默认对请求进行隔离，有两种隔离模式：thread pool or SEMAPHORE。前者在单独的线程池中执行(默认)，后者在当前线程中执行。如果你向使用相关上下文，那么可以采用后面的模式：12345@HystrixCommand(fallbackMethod = \"stubMyService\", commandProperties = &#123; @HystrixProperty(name=\"execution.isolation.strategy\", value=\"SEMAPHORE\") &#125;) 如果你只想使用SecurityContext，那么你可以配置hystrix.shareSecurityContext=true。当然你也可以自定义一个HystrixConcurrencyStrategy 策略(见文档)。 Health Indicator &amp;&amp; Hystrix Metrics StreamHealth Indicator:在/health端点可以看到Hystrix Metrics Stream:添加spring-boot-starter-actuator依赖，然后会启用端点/hystrix.stream作为一个manager端点 Hystrix Timeouts And Ribbon Clients当使用HystrixCommand，内嵌Ribbon时，我们需要确保Hystrix timemout比Ribbon timeout要长，同时还需要考虑到Ribbon的重试机制。比如： if your Ribbon connection timeout is one second and the Ribbon client might retry the request three times, than your Hystrix timeout should be slightly more than three seconds. Hystrix DashBoarddashboard展示了所有的断路器状态。首先添加spring-cloud-starter-hystrix-netflix-dashboard依赖，然后在SpringBoot main class中添加@EnableHystrixDashboard，之后便可以使用/Hystrix端点访问了。但此时只是展示了单个实例的Hystrix数据。我们需要展示所有系统的数据，此时我们需要用到Turbine.Turbine：用来为Hystrix Dashboard聚集所有的/hystrix.stream到/turbin.stream的一个工具.启用Turbine server with Stream需要添加spring-cloud-starter-netflix-turbine-stream 依赖，并配置@EnableTurbineStream.默认端口8989然后为所有需要采集的客户端，包括Turbine Server本身，添加spring-cloud-starter-stream-rabbit依赖(如果你使用rabbitmq的话)一般地，可以把Turbin Server与Hystrix-dashboard合并成一个服务。 Client Side Load Balancer: Ribbon注意：Feign已经使用了Ribbon，如果你使用@FeignClient，那么Ribbon会自动起作用。内部使用RibbonClientConfiguration来与Spring集成，同时包含ILoadBalancer,RestClient,ServerListFilter依赖：spring-cloud-starter-netflix-ribbon 定制Ribbon Client外部属性配置项&lt; client&gt;.ribbon.*所有配置项定义都在CommonClientConfigKey类中，作为static fieldSpringCloud提供注解式配置，如下：1234@Configuration@RibbonClient(name = \"foo\", configuration = FooConfiguration.class)public class TestConfiguration &#123;&#125; 注意FooConfiguration需要被@Comfiguration配置，但不要将它放在@ComponentScan扫描的范围内，否则会被所有的@RibbonClients共享。 SpringCloud还为Ribbon提供很多bean，均可自定义，具体见文档。 全局默认配置，适用于所有的RibbonClient，例如下：1234567891011121314151617181920212223242526272829303132333435@RibbonClients(defaultConfiguration = DefaultRibbonConfig.class)public class RibbonClientDefaultConfigurationTestsConfig &#123; public static class BazServiceList extends ConfigurationBasedServerList &#123; public BazServiceList(IClientConfig config) &#123; super.initWithNiwsConfig(config); &#125; &#125;&#125;@Configurationclass DefaultRibbonConfig &#123; @Bean public IRule ribbonRule() &#123; return new BestAvailableRule(); &#125; @Bean public IPing ribbonPing() &#123; return new PingUrl(); &#125; @Bean public ServerList&lt;Server&gt; ribbonServerList(IClientConfig config) &#123; return new RibbonClientDefaultConfigurationTestsConfig.BazServiceList(config); &#125; @Bean public ServerListSubsetFilter serverListFilter() &#123; ServerListSubsetFilter filter = new ServerListSubsetFilter(); return filter; &#125;&#125; 通过属性来自定义从1.2.0开始，提供属性配置：前缀为&lt; clientName&gt;.ribbon.: NFLoadBalancerClassName: should implement ILoadBalancer NFLoadBalancerRuleClassName: should implement IRule NFLoadBalancerPingClassName: should implement IPing NIWSServerListClassName: should implement ServerList NIWSServerListFilterClassName should implement ServerListFilter 属性配置的好处：运行你在不同环境下改变这些行为。 与Eureka结合When Eureka is used in conjunction with Ribbon (i.e., both are on the classpath) the ribbonServerList is overridden with an extension of DiscoveryEnabledNIWSServerList which populates the list of servers from Eureka. It also replaces the IPing interface with NIWSDiscoveryPing which delegates to Eureka to determine if a server is up. The ServerList that is installed by default is a DomainExtractingServerList and the purpose of this is to make physical metadata available to the load balancer without using AWS AMI metadata (which is what Netflix relies on). By default the server list will be constructed with “zone” information as provided in the instance metadata (so on the remote clients set eureka.instance.metadataMap.zone), and if that is missing it can use the domain name from the server hostname as a proxy for zone (if the flag approximateZoneFromHostname is set). Once the zone information is available it can be used in a ServerListFilter. By default it will be used to locate a server in the same zone as the client because the default is a ZonePreferenceServerListFilter. The zone of the client is determined the same way as the remote instances by default, i.e. via eureka.instance.metadataMap.zone. How to Use Ribbon Without Eureka? 略。Using the Ribbon API Directly：12345678910public class MyClass &#123; @Autowired private LoadBalancerClient loadBalancer; public void doStuff() &#123; ServiceInstance instance = loadBalancer.choose(\"stores\"); URI storesUri = URI.create(String.format(\"http://%s:%s\", instance.getHost(), instance.getPort())); // ... do something with the URI &#125;&#125; 一般通过Feign来使用，很少直接用的。 Caching of Ribbon Configuration每个Ribbon named client都有对应的child Application Context，它是懒加载的，直到第一个请求到来时才会加载至named client，这会导致第一次请求时间较长，我们可以通过配置来让它启动时加载，如下:application.yml.1234ribbon: eager-load: enabled: true clients: client1, client2, client3 How to Configure Hystrix thread poolsIf you change zuul.ribbonIsolationStrategy to THREAD, the thread isolation strategy for Hystrix will be used for all routes. In this case, the HystrixThreadPoolKey is set to “RibbonCommand” as default.这意味着HystrixCommands for all routes会在同一个Hystrix thread pool中执行. 我们可以通过以下配置来让 HystrixCommands being executed in the Hystrix thread pool for each route.application.yml.123zuul: threadPool: useSeparateThreadPools: true How to Provide a Key to Ribbon’s IRule你可以提供自定义的IRule实现，来处理特殊的routing，比如canary test中。12public interface IRule&#123; public Server choose(Object key); 通过如下方式设置的key，会被传送到IRule的choose方法中,12RequestContext.getCurrentContext() .set(FilterConstants.LOAD_BALANCER_KEY, \"canary-test\"); 那么这段代码方哪里呢，它必须在RibbonRoutingFilter之前执行，放在Zuul的pre filter之中是最佳位置。 Declarative REST Client: FeignFeign is a declarative web service client. It makes writing web service clients easier. To use Feign create an interface and annotate it.风格上类似于Retrofit.Feign also supports pluggable encoders and decoders.Spring Cloud adds support for Spring MVC annotations and for using the same HttpMessageConverters used by default in Spring Web. Spring Cloud integrates Ribbon and Eureka to provide a load balanced http client when using Feign. 首先添加依赖spring-cloud-starter-openfeign1234567891011121314151617181920@Configuration@ComponentScan@EnableAutoConfiguration@EnableFeignClientspublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125;@FeignClient(\"stores\")public interface StoreClient &#123; @RequestMapping(method = RequestMethod.GET, value = \"/stores\") List&lt;Store&gt; getStores(); @RequestMapping(method = RequestMethod.POST, value = \"/stores/&#123;storeId&#125;\", consumes = \"application/json\") Store update(@PathVariable(\"storeId\") Long storeId, Store store);&#125; 注意：@FeignClient(“stores”)中指定的名字stores是远程的serviceId. Overriding Feign Defaults基于FeignClientsConfiguration中的配置项来进行自定义配置1234@FeignClient(name = \"stores\", configuration = FooConfiguration.class)public interface StoreClient &#123; //..&#125; 注意FooConfiguration需要被@Comfiguration配置，但不要将它放在@ComponentScan扫描的范围内，否则会被所有的共享。 默认提供的bean有： Decoder feignDecoder: ResponseEntityDecoder (which wraps a SpringDecoder) Encoder feignEncoder: SpringEncoder Logger feignLogger: Slf4jLogger Contract feignContract: SpringMvcContract Feign.Builder feignBuilder: HystrixFeign.Builder Client feignClient: if Ribbon is enabled it is a LoadBalancerFeignClient, otherwise the default feign client is used.使用的Http请求工具配置：feign.okhttp.enabled or feign.httpclient.enabled to true 没有提供，但支持注入的bean: Logger.Level Retryer ErrorDecoder Request.Options Collection SetterFactory如：123456789101112@Configurationpublic class FooConfiguration &#123; @Bean public Contract feignContract() &#123; return new feign.Contract.Default(); &#125; @Bean public BasicAuthRequestInterceptor basicAuthRequestInterceptor() &#123; return new BasicAuthRequestInterceptor(\"user\", \"password\"); &#125;&#125; This replaces the SpringMvcContract with feign.Contract.Default and adds a RequestInterceptor to the collection of RequestInterceptor. 现在还支持通过配置文件来配置@FeignClient：application.yml12345678910111213feign: client: config: feignName: connectTimeout: 5000 readTimeout: 5000 loggerLevel: full errorDecoder: com.example.SimpleErrorDecoder retryer: com.example.SimpleRetryer requestInterceptors: - com.example.FooRequestInterceptor - com.example.BarRequestInterceptor decode404: false 注意上述feignName需要你替换为自己的名字，如果需要全局默认，可以使用default作为名字。注意：相比于前面的@Configuration bean，属性文件拥有更高的优先级。注意：如果你需要在RequestInterceptor中使用ThreadLocal，你有两种选择：1、禁用Hystrix,这个比较极端，2、set the thread isolation strategy for Hystrix to `SEMAPHOREapplication.yml123456789101112# To disable Hystrix in Feignfeign: hystrix: enabled: false# To set thread isolation to SEMAPHOREhystrix: command: default: execution: isolation: strategy: SEMAPHORE Creating Feign Clients Manually12345678910111213141516171819202122@Import(FeignClientsConfiguration.class)class FooController &#123; private FooClient fooClient; private FooClient adminClient; @Autowired public FooController( Decoder decoder, Encoder encoder, Client client) &#123; this.fooClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(\"user\", \"user\")) .target(FooClient.class, \"http://PROD-SVC\"); this.adminClient = Feign.builder().client(client) .encoder(encoder) .decoder(decoder) .requestInterceptor(new BasicAuthRequestInterceptor(\"admin\", \"admin\")) .target(FooClient.class, \"http://PROD-SVC\"); &#125;&#125; Feign Hystrix Support1、确保Hystrix在classpath中，2、feign.hystrix.enabled=true这样Feign会将所有方法包含在断路器中，然后返回com.netflix.hystrix.HystrixCommand,它支持reactive pattern,(采用RxJava)。 Feign Hystrix Fallbacks12345678910111213@FeignClient(name = \"hello\", fallback = HystrixClientFallback.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = \"/hello\") Hello iFailSometimes();&#125;@Bean //官方文档没有加，但是有这句话:You also need to declare your implementation as a Spring bean.具体使用时，再测试下static class HystrixClientFallback implements HystrixClient &#123; @Override public Hello iFailSometimes() &#123; return new Hello(\"fallback\"); &#125;&#125; fallbackFactory方式：123456789101112131415161718@FeignClient(name = \"hello\", fallbackFactory = HystrixClientFallbackFactory.class)protected interface HystrixClient &#123; @RequestMapping(method = RequestMethod.GET, value = \"/hello\") Hello iFailSometimes();&#125;@Componentstatic class HystrixClientFallbackFactory implements FallbackFactory&lt;HystrixClient&gt; &#123; @Override public HystrixClient create(Throwable cause) &#123; return new HystrixClient() &#123; @Override public Hello iFailSometimes() &#123; return new Hello(\"fallback; reason was: \" + cause.getMessage()); &#125; &#125;; &#125;&#125; Feign and @Primary注意上述定义fallback时，导致了一个新问题，那就是很多同类型的beans，使得@Autowired无法工作，那么SpringCloudNetflix怎么解决的呢，那就是因为它默认给@FeignClient生成的bean加上了@Primary，如果不想使用这个特性，可以关闭，如下:1234@FeignClient(name = \"hello\", primary = false)public interface HelloClient &#123; // methods here&#125; Feign Inheritance Support支持继承来实现模版化通用UserService.java.12345public interface UserService &#123; @RequestMapping(method = RequestMethod.GET, value =\"/users/&#123;id&#125;\") User getUser(@PathVariable(\"id\") long id);&#125; UserClient.java.123456package project.user;@FeignClient(\"users\")public interface UserClient extends UserService &#123;&#125; Feign request/response compression启用压缩123456feign.compression.request.enabled=truefeign.compression.response.enabled=true#高级配法feign.compression.request.enabled=truefeign.compression.request.mime-types=text/xml,application/xml,application/jsonfeign.compression.request.min-request-size=2048 Feign loggingA logger is created for each Feign client created. By default the name of the logger is the full class name of the interface used to create the Feign client. Feign logging only responds to the DEBUG level. application.yml.1logging.level.project.user.UserClient: DEBUG The Logger.Level object that you may configure per client, tells Feign how much to log. Choices are: NONE, No logging (DEFAULT). BASIC, Log only the request method and URL and the response status code and execution time. HEADERS, Log the basic information along with request and response headers. FULL, Log the headers, body, and metadata for both requests and responses.1234567@Configurationpublic class FooConfiguration &#123; @Bean Logger.Level feignLoggerLevel() &#123; return Logger.Level.FULL; &#125;&#125; Router and Filter: Zuul Zuul is a JVM based router and server side load balancer by Netflix.sNetflix uses Zuul for the following: Authentication Insights Stress Testing Canary Testing Dynamic Routing Service Migration Load Shedding Security Static Response handling Active/Active traffic management 注意：zuul.max.host.connections属性已经被废弃，代之以两个新属性：zuul.host.maxTotalConnections and zuul.host.maxPerRouteConnections which default to 200 and 20 respectively. 注意：Default Hystrix isolation pattern (ExecutionIsolationStrategy) for all routes is SEMAPHORE. zuul.ribbonIsolationStrategy can be changed to THREAD if this isolation pattern is preferred. 首先添加依赖：spring-cloud-starter-netflix-zuul和spring-cloud-starter-netflix-eureka-client依赖 Embedded Zuul Reverse Proxy提供反向代理来解决CORS跨域问题及权限集中处理。通过@EnableZuulProxy来启用此处发现代理以serveiceId作为前缀标识，如/users，代理到serviceId为users的服务。同时proxy使用Ribbon来进行负载均衡，使用Hystrix来进行断路控制。 路由包含与排除：application.yml.1234zuul: ignoredServices: &apos;*&apos; routes: users: /myusers/** In this example, all services are ignored except “users”. 改变路由规则application.yml.123zuul: routes: users: /myusers/** This means that http calls to “/myusers” get forwarded to the “users” service 更为细粒度的控制：1234567application.yml. zuul: routes: users: path: /myusers/** serviceId: users_service 配置样例：1234567891011121314151617181920212223zuul: routes: echo: path: /myusers/** serviceId: myusers-service stripPrefix: truehystrix: command: myusers-service: execution: isolation: thread: timeoutInMilliseconds: ...myusers-service: ribbon: NIWSServerListClassName: com.netflix.loadbalancer.ConfigurationBasedServerList ListOfServers: http://example1.com,http://example2.com ConnectTimeout: 1000 ReadTimeout: 3000 MaxTotalHttpConnections: 500 MaxConnectionsPerHost: 100 你也可以通过正则表达式定义复杂的路由规则：123456@Beanpublic PatternServiceRouteMapper serviceRouteMapper() &#123; return new PatternServiceRouteMapper( \"(?&lt;name&gt;^.+)-(?&lt;version&gt;v.+$)\", \"$&#123;version&#125;/$&#123;name&#125;\");&#125; This means that a serviceId “myusers-v1” will be mapped to route “/v1/myusers/**”. Any regular expression is accepted but all named groups must be present in both servicePattern and routePattern. If servicePattern does not match a serviceId, the default behavior is used. In the example above, a serviceId “myusers” will be mapped to route “/myusers/**” (no version detected) To add a prefix to all mappings, set zuul.prefix to a value, such as /api. The proxy prefix is stripped from the request before the request is forwarded by default (switch this behaviour off with zuul.stripPrefix=false). You can also switch off the stripping of the service-specific prefix from individual routes, e.g.1234567application.yml. zuul: routes: users: path: /myusers/** stripPrefix: false In this example, requests to “/myusers/101” will be forwarded to “/myusers/101” on the “users” service.(默认行为是到”users” service的/101) The zuul.routes entries actually bind to an object of type ZuulProperties.所以你可以使用其中的属性来配置其他项。 The X-Forwarded-Host header is added to the forwarded requests by default. To turn it off set zuul.addProxyHeaders = false. The prefix path is stripped by default, and the request to the backend picks up a header &quot;X-Forwarded-Prefix&quot; (&quot;/myusers&quot; in the examples above). An application with @EnableZuulProxy could act as a standalone server if you set a default route (&quot;/&quot;), for example zuul.route.home: / would route all traffic (i.e. “/**”) to the “home” service. 指定需要忽略的路由：1234zuul: ignoredPatterns: /**/admin/** routes: users: /myusers/** This means that all calls such as “/myusers/101” will be forwarded to “/101” on the “users” service. But calls including “/admin/“ will not resolve. Zuul Http Client默认使用Apache HttpClient，如果你想使用OkHttp3,那么配置ribbon.okhttp.enabled=true Cookies and Sensitive Headers123456zuul: routes: users: path: /myusers/** sensitiveHeaders: Cookie,Set-Cookie,Authorization url: https://downstream this is the default value for sensitiveHeaders, so you don’t need to set it unless you want it to be different. 配置所有header都保留application.yml.123456zuul: routes: users: path: /myusers/** sensitiveHeaders: url: https://downstream 全局配置：zuul.sensitiveHeaders. Ignored Headerszuul.ignoredHeaders：来配置需要去除的头， (both request and response)默认情况下为空，但是如果Spring Security在classpath中，那么值为”security”,也就是说此时会忽略security头。如果你像禁用Spring Security的这一行为，请配置:zuul.ignoreSecurityHeaders=false Management Endpoints使用@EnableZuulProxy会启用两个endpoints:/routes/filters如下:1234567891011121314151617181920GET /routes. &#123; /stores/**: &quot;http://localhost:8081&quot;&#125;GET /routes?format=details. &#123; &quot;/stores/**&quot;: &#123; &quot;id&quot;: &quot;stores&quot;, &quot;fullPath&quot;: &quot;/stores/**&quot;, &quot;location&quot;: &quot;http://localhost:8081&quot;, &quot;path&quot;: &quot;/**&quot;, &quot;prefix&quot;: &quot;/stores&quot;, &quot;retryable&quot;: false, &quot;customSensitiveHeaders&quot;: false, &quot;prefixStripped&quot;: true &#125;&#125; A GET to the filters endpoint at /filters will return a map of Zuul filters by type. For each filter type in the map, you will find a list of all the filters of that type, along with their details. Strangulation Patterns and Local Forwards用于集成已有应用1234567891011121314zuul: routes: first: path: /first/** url: http://first.example.com second: path: /second/** url: forward:/second third: path: /third/** url: forward:/3rd legacy: path: /** url: http://legacy.example.com In this example we are strangling the “legacy” app which is mapped to all requests that do not match one of the other patterns. Paths in /first/ have been extracted into a new service with an external URL. And paths in /second/ are forwarded so they can be handled locally, e.g. with a normal Spring @RequestMapping. Paths in /third/** are also forwarded, but with a different prefix (i.e. /third/foo is forwarded to /3rd/foo). Uploading Files through Zuul默认情况下，小文件没有问题，如果是大文件呢？我们需要使用/zuul/前缀，例如：zuul.routes.customers=/customers/** then you can POST large files to “/zuul/customers/“.同时需要对大文件的超时配置，以免被Ribbon和hystrix超时。1234hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds: 60000ribbon: ConnectTimeout: 3000 ReadTimeout: 60000 Note that for streaming to work with large files, you need to use chunked encoding in the request12$ curl -v -H &quot;Transfer-Encoding: chunked&quot; \\ -F &quot;file=@mylarge.iso&quot; localhost:9999/zuul/simple/file Query String Encoding略 Plain Embedded ZuulYou can also run a Zuul server without the proxying, or switch on parts of the proxying platform selectively, if you use @EnableZuulServer (instead of @EnableZuulProxy). Any beans that you add to the application of type ZuulFilter will be installed automatically, as they are with @EnableZuulProxy, but without any of the proxy filters being added automatically. Disable Zuul Filterszuul.&lt; SimpleClassName&gt;.&lt; filterType&gt;.disable=trueFor example to disable org.springframework.cloud.netflix.zuul.filters.post.SendResponseFilter set zuul.SendResponseFilter.post.disable=true Providing Hystrix Fallbacks For Routes123zuul: routes: customers: /customers/** 12345678910111213141516171819202122232425262728293031323334353637383940414243class MyFallbackProvider implements ZuulFallbackProvider &#123; @Override public String getRoute() &#123; return \"customers\"; &#125; @Override public ClientHttpResponse fallbackResponse() &#123; return new ClientHttpResponse() &#123; @Override public HttpStatus getStatusCode() throws IOException &#123; return HttpStatus.OK; &#125; @Override public int getRawStatusCode() throws IOException &#123; return 200; &#125; @Override public String getStatusText() throws IOException &#123; return \"OK\"; &#125; @Override public void close() &#123; &#125; @Override public InputStream getBody() throws IOException &#123; return new ByteArrayInputStream(\"fallback\".getBytes()); &#125; @Override public HttpHeaders getHeaders() &#123; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; &#125; &#125;; &#125;&#125; 你也可以配置全局默认fallback:1234567891011class MyFallbackProvider implements ZuulFallbackProvider &#123; @Override public String getRoute() &#123; return \"*\"; &#125; @Override public ClientHttpResponse fallbackResponse() &#123; .... &#125;&#125; 如果你想知道异常信息，请使用FallbackProvider代替ZuulFallbackProvder .12345678910111213141516171819202122232425class MyFallbackProvider implements FallbackProvider &#123; @Override public String getRoute() &#123; return \"*\"; &#125; @Override public ClientHttpResponse fallbackResponse(final Throwable cause) &#123; if (cause instanceof HystrixTimeoutException) &#123; return response(HttpStatus.GATEWAY_TIMEOUT); &#125; else &#123; return fallbackResponse(); &#125; &#125; @Override public ClientHttpResponse fallbackResponse() &#123; return response(HttpStatus.INTERNAL_SERVER_ERROR); &#125; private ClientHttpResponse response(final HttpStatus status) &#123; ... &#125;&#125; Zuul TimeoutsIf you want to configure the socket timeouts and read timeouts for requests proxied through Zuul .If Zuul is using service discovery than you need to configure these timeouts via Ribbon properties, ribbon.ReadTimeout and ribbon.SocketTimeout. If you have configured Zuul routes by specifying URLs than you will need to use zuul.host.connect-timeout-millis and zuul.host.socket-timeout-millis. Zuul Developer GuideZuul is implemented as a Servlet. For the general cases, Zuul is embedded into the Spring Dispatch mechanism. This allows Spring MVC to be in control of the routing. In this case, Zuul is configured to buffer requests.If there is a need to go through Zuul without buffering requests (e.g. for large file uploads), the Servlet is also installed outside of the Spring Dispatcher. By default, this is located at /zuul. This path can be changed with the zuul.servlet-path property. RequestContext用于在filters中共享信息，采用ThreadLocal变量。同时包含HttpServletRequest and HttpServletResponse.而FilterConstants包含所有filters需要用到的常量。 @EnableZuulProxy vs. @EnableZuulServer:@EnableZuulProxy is a superset of @EnableZuulServer. In other words, @EnableZuulProxy contains all filters installed by @EnableZuulServer. The additional filters in the “proxy” enable routing functionality.各自的filters见官文 Custom Zuul Filter examples例如：write a pre filter:12345678910111213141516171819202122232425262728public class QueryParamPreFilter extends ZuulFilter &#123; @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER - 1; // run before PreDecoration &#125; @Override public String filterType() &#123; return PRE_TYPE; &#125; @Override public boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); return !ctx.containsKey(FORWARD_TO_KEY) // a filter has already forwarded &amp;&amp; !ctx.containsKey(SERVICE_ID_KEY); // a filter has already determined serviceId &#125; @Override public Object run() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); if (request.getParameter(\"foo\") != null) &#123; // put the serviceId in `RequestContext` ctx.put(SERVICE_ID_KEY, request.getParameter(\"foo\")); &#125; return null; &#125;&#125; 其他例子请参考官文。此处不作过多介绍。 How Zuul Errors WorkThe SendErrorFilter is only run if RequestContext.getThrowable() is not null. It then sets specific javax.servlet.error.* attributes in the request and forwards the request to the Spring Boot error page. Zuul Eager Application Context LoadingZuul internally uses Ribbon for calling the remote url’s and Ribbon clients are by default lazily loaded up by Spring Cloud on first call. This behavior can be changed for Zuul using the following configuration and will result in the child Ribbon related Application contexts being eagerly loaded up at application startup time. application.yml.1234zuul: ribbon: eager-load: enabled: true Polyglot support with Sidecar集成非jvm语言的系统。Do you have non-jvm languages you want to take advantage of Eureka, Ribbon and Config Server?首先添加依赖：spring-cloud-netflix-sidecar添加@EnableSidecar. This annotation includes @EnableCircuitBreaker, @EnableDiscoveryClient, and @EnableZuulProxy The sidecar.health-uri is a uri accessible on the non-jvm app that mimicks a Spring Boot health indicator. It should return a json document like the following: health-uri-document.123&#123; &quot;status&quot;:&quot;UP&quot;&#125; Here is an example application.yml for a Sidecar application: application.yml.123456789server: port: 5678spring: application: name: sidecarsidecar: port: 8000 health-uri: http://localhost:8000/health.json RxJava with Spring MVCRxJava is a Java VM implementation of Reactive Extensions: a library for composing asynchronous and event-based programs by using observable sequences. Spring Cloud Netflix provides support for returning rx.Single objects from Spring MVC Controllers. It also supports using rx.Observable objects for Server-sent events (SSE). This can be very convenient if your internal APIs are already built using RxJava (see Section 17.4, “Feign Hystrix Support” for examples). 具体见官文。 Metrics: Spectator, Servo, and AtlasServo已经废弃了，推荐使用Spectator.Spectator+Atlas提供近实时的系统监控功能。其中Spectator用于收集元数据metrics, atlas用于存储metrics，并管理多个维度的时序数据。除了官方文档外，建议参考：Atlas+Spectator+Grafana搭建实时监控平台和spring cloud atlas使用","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[SpringCloud官文笔记]SpringCloudConfig","slug":"SpringCloud官文笔记-SpringCloudConfig","date":"2017-12-18T03:37:47.000Z","updated":"2017-12-18T10:56:38.564Z","comments":true,"path":"2017/12/18/SpringCloud官文笔记-SpringCloudConfig/","link":"","permalink":"http://xbynet.top/2017/12/18/SpringCloud官文笔记-SpringCloudConfig/","excerpt":"SpringCloud提供分布式系统中的外部化、多环境、版本化、跨语言的配置管理。概念上与Spring的Environment和PropertySource等同映射。它基于git作为配置存储实现。","text":"SpringCloud提供分布式系统中的外部化、多环境、版本化、跨语言的配置管理。概念上与Spring的Environment和PropertySource等同映射。它基于git作为配置存储实现。 QuickStart1234567$ cd spring-cloud-config-server$ ../mvnw spring-boot:run$ curl localhost:8888/foo/development&#123;&quot;name&quot;:&quot;foo&quot;,&quot;label&quot;:&quot;master&quot;,&quot;propertySources&quot;:[ &#123;&quot;name&quot;:&quot;https://github.com/scratches/config-repo/foo-development.properties&quot;,&quot;source&quot;:&#123;&quot;bar&quot;:&quot;spam&quot;&#125;&#125;, &#123;&quot;name&quot;:&quot;https://github.com/scratches/config-repo/foo.properties&quot;,&quot;source&quot;:&#123;&quot;foo&quot;:&quot;bar&quot;&#125;&#125;]&#125; 请求url的格式： /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.propertiesapplication代表你配置的spring.config.name,profile不解释，label是git的分支，默认是master. 配置git地址：123456spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo 客户端使用需要添加spring-cloud-starter-config依赖：1234567891011121314151617181920212223242526272829303132333435363738394041 &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.3.5.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Brixton.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; &lt;!-- repositories also needed for snapshots and milestones --&gt; 然后在bootstrap.properties中配置config server的地址：1spring.cloud.config.uri: http://myconfigserver.com 然后通过/env端点检测：12345678$ curl localhost:8080/env&#123; &quot;profiles&quot;:[], &quot;configService:https://github.com/spring-cloud-samples/config-repo/bar.properties&quot;:&#123;&quot;foo&quot;:&quot;bar&quot;&#125;, &quot;servletContextInitParams&quot;:&#123;&#125;, &quot;systemProperties&quot;:&#123;...&#125;, ...&#125; Spring Cloud Config Server支持的backend：git,svn,file-base,Vault,jdbc。推荐git。@EnableConfigServer1234567@SpringBootApplication@EnableConfigServerpublic class ConfigServer &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigServer.class, args); &#125;&#125; application.properties.12server.port: 8888spring.cloud.config.server.git.uri: file://$&#123;user.home&#125;/config-repo #windows下:file:/// 本地测试：1234567$ cd $HOME$ mkdir config-repo$ cd config-repo$ git init .$ echo info.foo: bar &gt; application.properties$ git add -A .$ git commit -m &quot;Add application.properties&quot; Environment Repository不作过多介绍，默认采用git作为backend.提一下里面介绍的类：EnvironmentRepository Environment复杂配置支持：1234567891011121314spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo repos: simple: https://github.com/simple/config-repo special: pattern: special*/dev*,*special*/dev* uri: https://github.com/special/config-repo local: pattern: local* uri: file:/home/configsvc/config-repo git认证方式及配置：1、如果git仓库需要用户名和密码认证：12345678spring: cloud: config: server: git: uri: https://github.com/spring-cloud-samples/config-repo username: trolley password: strongpassword 2、如果你向采用私钥公钥免密的方式：1、确保你的私钥在~/.ssh中，2、确保url使用git@开头，3、确保你git server的地址在~/.ssh/know_hosts中。3、通过配置文件直接配置ssh私钥：略 关于从git仓库pull：config server会在第一次被请求时从git仓库拉取配置文件，并缓存在本地。但是当git仓库配置文件发生改变后，config server无法知晓，所以此时数据为dirty。我们可以通过force-pull属性来开启改变后自动刷新本地缓存的功能：如果有多个，需要对每个都配置12345678910111213141516171819spring: cloud: config: server: git: uri: https://git/common/config-repo.git force-pull: true repos: team-a: pattern: team-a-* uri: http://git/team-a/config-repo.git force-pull: true team-b: pattern: team-b-* uri: http://git/team-b/config-repo.git force-pull: true team-c: pattern: team-c-* uri: http://git/team-a/config-repo.git Push Notifications and Spring Cloud Bus：利用git(github,gitlab等)的webhook功能。添加spring-cloud-config-monitor及SpringCloud Bus则会在config server中启用Sping Cloud Bus，此时会激活/monitor端点。当webhook配置为config server地址/monitor后，一旦发生改变，webhook通知config server，configserver之后会根据定义的PropertyPathNotificationExtractor通知策略发送RefreshRemoteApplicationEvent事件给相关客户端(客户端需要添加依赖SpringCloud Bus)。当然，你也可以手动POST /monitor端点，并附上form-encoded body parameters path={name}，那么也会触发更新。 需要注意的是：拉取git仓库配置后默认的缓存目录是放在操作系统的temp目录下，以config-repo-开头，比如linux下/tmp/config-repo-&lt; randomid&gt;，如果你需要改变这一行为，比如有些操作系统会不定时删除temp目录下的内容。那么可以通过配置：spring.cloud.config.server.git.basedir or spring.cloud.config.server.svn.basedir来改变. 健康检查：检查EnvironmentRepository是否处于工作状态，默认情况下只检查名为app，默认profile和默认label的，不过你可以配置如下：1234567891011spring: cloud: config: server: health: repositories: myservice: label: mylabel myservice-dev: name: myservice profiles: development Encryption and Decryption当属性名是:{cipher}开头时，如{cipher}*，就代表它是加密过的。config server在获取该属性发送到客户端之前是会进行解密，前提条件：1、添加Spring Security RSA依赖，2、确保JCE在JDK中；3、确保有效的公钥在应用中。application.yml.1234spring: datasource: username: dbuser password: '&#123;cipher&#125;FKSAJDFGYOS8F7GLHAKERGFHLSAJ' 同时config server提供方便的/encrypt and /decrypt端点，1234$ curl localhost:8888/encrypt -d mysecret682bc583f4641835fa2db009355293665d2647dade3375c0ee201de2a49f7bda$ curl localhost:8888/decrypt -d 682bc583f4641835fa2db009355293665d2647dade3375c0ee201de2a49f7bdamysecret 加密Key的管理config server可以使用对称symmetric ，非对称asymmetric (RSA)加密。如果仅使用对称加密,只需要把key配置在bootstrap.properties的encrypt.key中。如果使用非对称加密，有两种配置方式：1、直接用私钥内容配置在encrypt.key中，2、如果使用keystore，那么需要配置的项有:encrypt.keyStore.location/password/alias Spring Cloud Config Client1、Config Server的发现模式：”Config First” mode or Discovery First Bootstrap:在Config First mode中，你需要在bootstrap.yml配置死spring.cloud.config.uri (defaults to “http://localhost:8888&quot;).如果config server的ip发生改变，那就失去了灵活性。如果指派别人去一个一个改客户端配置，估计会fuck you。2、Discovery First Bootstrap:可以充分利用服务注册与发现的优势。而无需客户端绑死config server的ip or hostname。可以在bootstrap.yml配置spring.cloud.config.discovery.enabled=true (default “false”)启用。同时需要引入eureka client的客户端依赖，并配置eureka的地址：eureka.client.serviceUrl.defaultZone默认情况下configserverId为：configserver,如果你的configserver是你自己嵌入的微服务，那么该serviceId就是spring.application.name,在客户端你需要通过spring.cloud.config.discovery.serviceId来指定关于fastfail，及失败重试，密码认证、自定义请求RestTemplate请看文档，这里不作具体介绍。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[SpringCloud官文笔记]SpringCloudContext与Commons","slug":"SpringCloud官文笔记-SpringCloudContext与Commons","date":"2017-12-18T03:26:49.000Z","updated":"2017-12-18T10:52:43.444Z","comments":true,"path":"2017/12/18/SpringCloud官文笔记-SpringCloudContext与Commons/","link":"","permalink":"http://xbynet.top/2017/12/18/SpringCloud官文笔记-SpringCloudContext与Commons/","excerpt":"基于Edgware版本，此篇为SpringCloud官方文档学习笔记的开篇。笔记就是散乱，还望各位看官见谅。http://cloud.spring.io/spring-cloud-static/Edgware.RELEASE/single/spring-cloud.html Spring Cloud Context为Spring Cloud应用程序（引导上下文，加密，刷新范围和环境端点）的ApplicationContext提供实用程序和特殊服务。Spring Cloud Commons是一组在不同的Spring Cloud实现中使用的抽象和常用类","text":"基于Edgware版本，此篇为SpringCloud官方文档学习笔记的开篇。笔记就是散乱，还望各位看官见谅。http://cloud.spring.io/spring-cloud-static/Edgware.RELEASE/single/spring-cloud.html Spring Cloud Context为Spring Cloud应用程序（引导上下文，加密，刷新范围和环境端点）的ApplicationContext提供实用程序和特殊服务。Spring Cloud Commons是一组在不同的Spring Cloud实现中使用的抽象和常用类 SpringCloud ContextBootstrap ApplicationContext：这个上下文是主应用程序的父上下文。Bootstrap属性的优先级高，因此默认情况下不能被本地配置覆盖。这两个上下文共享一个Environment。引导上下文使用与主应用程序上下文不同的外部配置约定，因此使用bootstrap.yml application.yml（或.properties）代替引导和主上下文的外部配置。SpringApplicationBuilder，SpringApplication bootstrap.yml.123456spring: application: name: foo cloud: config: uri: $&#123;SPRING_CONFIG_URI:http://localhost:8888&#125; boostrap.yml支持profiles:通过指定spring.profiles.active的值来指定不同环境下的配置文件:bootstrap-development.properties一般实际场景中boostrap context中的property source都来自于远程，如Config Server，默认情况下是无法被本地环境覆盖的(除非通过命令行)。不过你可以通过在远程的属性源中配置:spring.cloud.config.allowOverride=true来授权(在本地配置无效)，然后在远程的配置中可配置spring.cloud.config.overrideNone=true(可覆盖所有)或者spring.cloud.config.overrideSystemProperties=false(仅可覆盖环境变量) bootstrap configuration配置方式是通过在/META-INF/spring.factories下的org.springframework.cloud.bootstrap.BootstrapConfiguration添加条目。bootstrap context首先会被来自spring.factories的类创建 ，然后所有的 @Beans of type ApplicationContextInitializer are added to the main SpringApplication before it is started.默认的来自外部配置的property source是Config Server,如果你向添加其他外部源如database，可以通过添加一个继承PropertySourceLocator的bean，然后配置到/META-INF/spring.factories来实现.如下：12345678910@Configurationpublic class CustomPropertySourceLocator implements PropertySourceLocator &#123; @Override public PropertySource&lt;?&gt; locate(Environment environment) &#123; return new MapPropertySource(\"customProperty\", Collections.&lt;String, Object&gt;singletonMap(\"property.from.sample.custom.source\", \"worked as intended\")); &#125;&#125; Environment Changes：应用会通过监听EnvironmentChangeEvent来响应环境变量的改变，用户也可以通过添加ApplicationListerner的bean来实现。一旦环境变量改变，应用会 Re-bind any @ConfigurationProperties beans in the context Set the logger levels for any properties in logging.level.* Refresh Scope：@Bean被标记为@RefreshScope时，当属性改变时，可以进行改变响应。注意：不要将@RefreshScope放到@Configuration上 属性加解密：当属性名是:{cipher}开头时，如{cipher}*，就代表它是加密过的。config server在获取该属性发送到客户端之前是会进行解密，但有几个前提条件：1、添加Spring Security RSA依赖，2、确保JCE在JDK中；3、确保有效的公钥在应用中。 Spring Boot Actuator Endpoints： POST to /env to update the Environment and rebind @ConfigurationProperties and log levels /refresh for re-loading the boot strap context and refreshing the @RefreshScope beans /restart for closing the ApplicationContext and restarting it (disabled by default) /pause and /resume for calling the Lifecycle methods (stop() and start() on the ApplicationContext) Spring Cloud Commons@EnableDiscoveryClient:它会在/META-INF/spring.factories的org.springframework.cloud.client.discovery.EnableDiscoveryClient键中查找DiscoveryClient 的实现，如Spring Cloud Netflix Eureka, Spring Cloud Consul Discovery and Spring Cloud Zookeeper Discovery.但该注解不是必须的，因为如果在classpath中存在DiscoveryClient 的实现，会自动启用。 HealthIndicator：一般被DiscoveryClient实现DiscoveryHealthIndicator,用来支持健康检查。 ServiceRegistry:默认会自动注册到注册中心。 A /service-registry actuator endpoint is provided by Commons. This endpoint relys on a Registration bean in the Spring Application Context. Calling /service-registry/instance-status via a GET will return the status of the Registration. A POST to the same endpoint with a String body will change the status of the current Registration to the new value. Spring RestTemplate as a Load Balancer Client：RestTemplate can be automatically configured to use ribbon. To create a load balanced RestTemplate create a RestTemplate @Bean and use the @LoadBalanced qualifier.如下：123456789101112131415161718@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;public class MyClass &#123; @Autowired private RestTemplate restTemplate; public String doOtherStuff() &#123; String results = restTemplate.getForObject(\"http://stores/stores\", String.class); return results; &#125;&#125; 注意，此处url需要使用server name,而不是hostname或者ip，否则就无法实现负载均衡了。具体实现见：https://github.com/spring-cloud/spring-cloud-netflix/blob/master/spring-cloud-netflix-core/src/main/java/org/springframework/cloud/netflix/ribbon/RibbonAutoConfiguration.java Retrying Failed Requests：负载均衡RestTemplate可以配置请求失败重试，默认是禁用的，如果在classpath中发现Spring Retry依赖，它会自动启用，如果你想禁用该行为：spring.cloud.loadbalancer.retry.enabled=false。 或者，你只是想自定义重试次数：client.ribbon.MaxAutoRetries, client.ribbon.MaxAutoRetriesNextServer, and client.ribbon.OkToRetryOnAllOperations。注意：这里的client需要替换为你的 Ribbon client’s name.详情见：https://github.com/Netflix/ribbon/wiki/Getting-Started#the-properties-file-sample-clientproperties%E3%80%82 如果你想自定义降级策略,可以实现BackOffPolicy接口，然后创建LoadBalancedBackOffPolicyFactory来返回它，如下:123456789101112@Configurationpublic class MyConfiguration &#123; @Bean LoadBalancedBackOffPolicyFactory backOffPolciyFactory() &#123; return new LoadBalancedBackOffPolicyFactory() &#123; @Override public BackOffPolicy createBackOffPolicy(String service) &#123; return new ExponentialBackOffPolicy(); &#125; &#125;; &#125;&#125; 多个RestTemplate Objects:123456789101112131415@Configurationpublic class MyConfiguration &#123; @LoadBalanced @Bean RestTemplate loadBalanced() &#123; return new RestTemplate(); &#125; @Primary //为了消除歧义，此bean为非负载均衡的普通的restTemplate bean @Bean RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125; Ignore Network Interfaces:有个时候，在Service Discovery registration时，你需要忽略特定的网卡application.yml.123456spring: cloud: inetutils: ignoredInterfaces: - docker0 - veth.* 或者直接指定123456spring: cloud: inetutils: preferredNetworks: - 192.168 - 10.0 或者直接这样1234spring: cloud: inetutils: useOnlySiteLocalInterfaces: true HTTP Client Factories：支持ApachenHttpClientFactory/ApacheHttpClientConnectionManagerFactory和OkHttpClientFactory/OkHttpClientConnectionPoolFactory.启用哪个，取决于jar是否在classpath中，当然也可以通过配置来禁用。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"SpringCloud","slug":"读书笔记/SpringCloud","permalink":"http://xbynet.top/categories/读书笔记/SpringCloud/"}],"tags":[{"name":"springcloud","slug":"springcloud","permalink":"http://xbynet.top/tags/springcloud/"}]},{"title":"[杂记]有趣的句子","slug":"杂记-有趣的句子","date":"2017-12-18T01:28:20.000Z","updated":"2017-12-18T01:32:10.514Z","comments":true,"path":"2017/12/18/杂记-有趣的句子/","link":"","permalink":"http://xbynet.top/2017/12/18/杂记-有趣的句子/","excerpt":"微服务的定义：In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. 康威定律：Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure.","text":"微服务的定义：In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. 康威定律：Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure. Of course, just because you can do something, doesn’t mean you should - but partitioning your system in this way means you have the option.你可以做什么事，并不意味着你必须做这些事，但如果将系统通过微服务的方式拆分，意味着你有这个选择。-灵活性。 Being woken up at 3am every night by your pager is certainly a powerful incentive to focus on quality when writing your code.被凌晨3点的传输机吵醒无疑对你写代码时关注质量是一个很大的激励(毕竟谁都不想在凌晨3点被吵醒) Change control doesn’t necessarily mean change reduction - with the right attitudes and tools you can make frequent, fast, and well-controlled changes to software.关于控制改变的 We can’t say for sure where we’ll end up, but one of the challenges of software development is that you can only make decisions based on the imperfect information that you currently have to hand.关于软件设计的 You can’t control what you can’t measure Should you measure something be sure what you really measure otherwise the results can keep you far from reality. Always validate your assumptions and RTFM! 一大波有趣的短语：RTFM/RTM：RTFM是一组缩写，Unix程序员的一种习惯，意思是：去读他妈的手册，Read the fucking manual！这句话通常用在回复那些只要查阅文件就可以解决，拿出来提问只是浪费别人时间的问题。延伸：RTFSC/RTFS(Reading The Fucking Source Code)UTFH (“Use The Fucking Help”)STFW (“Search The Fucking Web”)STFG (“Search The Fucking Google” or “Search The Fantastic Google”)GIYF (“Google Is Your Friend”)JFGI (“Just Fucking Google It”)JGIYN (“Just Google It You Noob”)UTSL (“Use The Source Luke”—alternately, RTFS)RTFA (“Read The Fucking Article”—common on news forums such as Fark.com[3] and Slashdot)RTFE (“Read The Fucking Email”)RTFC (“Read The Fucking Code,” or “Reboot The Fucking Computer”)RTFSC (“Read The Fucking Source Code”)RTFQ (“Read The Fucking Question”)RTFFAQ (“Read The Fucking Frequently Asked Questions”)LMGTFY (“Let Me Google That For You”)WIDGI (“When In Doubt Google It”—also occasionally “WIDGIT”)FIOTI (“Find It On The Internet”)","categories":[{"name":"杂记","slug":"杂记","permalink":"http://xbynet.top/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"http://xbynet.top/tags/杂记/"}]},{"title":"限流令牌桶算法","slug":"限流令牌桶算法","date":"2017-12-17T05:53:52.000Z","updated":"2017-12-17T06:38:27.036Z","comments":true,"path":"2017/12/17/限流令牌桶算法/","link":"","permalink":"http://xbynet.top/2017/12/17/限流令牌桶算法/","excerpt":"缓存(Caching)，限流(Throttling)和降级(BackOff)是系统的三把利剑。 原理做限流(Rate Limiting/Throttling)的时候，除了简单的控制并发，如果要准确的控制TPS，简单的做法是维护一个单位时间内的Counter，如判断单位时间已经过去，则将Counter重置零。此做法被认为没有很好的处理单位时间的边界，比如在前一秒的最后一毫秒里和下一秒的第一毫秒都触发了最大的请求数，将目光移动一下，就看到在两毫秒内发生了两倍的TPS。因此更平滑的算法如Leaky Bucket–漏桶算法，又或者将原来单位时间内单一的Counter拆分为单位时间内的多个Buckets并滑动计算。","text":"缓存(Caching)，限流(Throttling)和降级(BackOff)是系统的三把利剑。 原理做限流(Rate Limiting/Throttling)的时候，除了简单的控制并发，如果要准确的控制TPS，简单的做法是维护一个单位时间内的Counter，如判断单位时间已经过去，则将Counter重置零。此做法被认为没有很好的处理单位时间的边界，比如在前一秒的最后一毫秒里和下一秒的第一毫秒都触发了最大的请求数，将目光移动一下，就看到在两毫秒内发生了两倍的TPS。因此更平滑的算法如Leaky Bucket–漏桶算法，又或者将原来单位时间内单一的Counter拆分为单位时间内的多个Buckets并滑动计算。 Leaky Bucket 与 Token Bucket 算法 漏桶算法简单的想象有一个木桶，有新请求就是不断的倒水进来，然后桶底下有个洞，按照固定的速率把水漏走，如果水进来的速度比漏走的快，桶可能就会满了，然后就拒绝请求。可见这里有两个变量，一个是桶的大小，支持流量突发增多时可以存多少的水(burst)，另一个是水桶漏洞的大小(rate)，可以简单的让burst等于rate，也可以让burst更大接收更多突发请求，伪代码如下：123456789101112131415161718192021double rate; // leak rate in calls/sdouble burst; // bucket size in callslong refreshTime; // time for last water refreshdouble water; // water count at refreshTimerefreshWater() &#123; long now = getTimeOfDay(); water = max(0, water- (now - refreshTime)*rate); // 水随着时间流逝，不断流走，最多就流干到0. refreshTime = now;&#125;bool permissionGranted() &#123; refreshWater(); if (water &lt; burst) &#123; // 水桶还没满，继续加1 water ++; return true; &#125; else &#123; return false; &#125;&#125; 但是对于很多情况下，除了要求能够限制平均处理速度外，还要求能允许一定程度的的突发情况。这样的话，漏桶算法就不合适了，用令牌桶算法更合适。Token Bucket 是与 Leaky Bucket 效果一样但方向相反的算法，更加容易理解。随着时间流逝，系统会按速率 1/rate 的时间间隔(如果rate=100，则间隔是10ms)往桶里加入Token(想象和漏洞漏水相反，有个水龙头在不断的加水)，如果桶已经满了就不再加了。新请求来临时，会各自拿走一个Token，如果没有Token可拿了就拒绝服务。 Google Guava中的RateLimiter，实际上就实现了Token Bucket的算法。它支持两种获取permits接口，一种是如果拿不到立刻返回false，一种会阻塞等待一段时间看能不能拿到。Leacky Bucket算法默认一开始水桶是空的，可以立即就接收最多burst的请求，而Token Bucket就要设置初始Token的数量。RateLimiter有两个子类，一个是WarmingUp，一个是Bursty。 WarmingUp，burst = warmUp时间/固定token添加间隔(即上例那个10ms)，初始token数量 = burst，有算法保证系统总是相对平滑。 Bursty， burst = rate或另外的参数设置，初始token数量 = 0 ，当系统冷了一段时间，支持突发到burst。Guava以micros为时间单位，计算token的变化。 guava RateLimiter123456789101112131415161718192021222324252627private static RateLimiter one=RateLimiter.create(2);//每秒2个 private static RateLimiter two=RateLimiter.create(2);//每秒2个 private RateLimitUtil()&#123;&#125;; public static void acquire(RateLimiter r,int num)&#123; double time =r.acquire(num); System.out.println(\"wait time=\"+time); &#125; public static void main(String[] args) throws InterruptedException &#123; acquire(one,1); acquire(one,1); acquire(one,1); System.out.println(\"-----\"); acquire(two,10); acquire(two,1); &#125; 输出:wait time=0.0wait time=0.499163wait time=0.489308-----wait time=0.0wait time=4.497819 Guava RateLimiter在Web应用中的使用一般Web系统的访问限制都可以用容器本身来实现，比如tomcat就可以在connector上面配置connection数目的限制，servlet thread限制。有时候系统复杂后希望对不同服务提供不同的RateLimiter，例如对数据库操作要求比较大的速率小些，在内存可以处理的速率大写，还有可能对集群提供rate limiter服务。 这里记录下实践过程中系统如何使用RateLimiter来限制所有spring访问的访问速率。1234567891011121314151617181920212223242526272829public class RateLimiterFilter implements Filter &#123; private static Logger logger = Logger.getLogger(RateLimiterFilter.class); private RateLimiter limiter = null; public void init(FilterConfig config) throws ServletException &#123; limiter = RateLimiter.create(100); //100 request per second &#125; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse res = (HttpServletResponse) response; if(limiter.tryAcquire()) &#123; if(logger.isTraceEnabled())&#123; logger.trace(\"get access: \"); &#125; chain.doFilter(request, response) &#125; else &#123; logger.info(\"system limitation reached!\"); req.getRequestDispatcher(\"/WEB-INF/jsp/error/429.jsp\").forward(req,res); &#125; &#125;&#125; 源码解析guava的限流算法有2种模式，一种是稳定速度，还有一种是生成令牌的速度慢慢提升直到维持在一个稳定的速度。2种模式原理类似，只是在具体等待多久的时间计算上有区别。以下就专门指稳定速度的模式。 先来看看它的acquire()方法：12345public double acquire(int permits) &#123; long microsToWait = reserve(permits);//先计算获取这些请求需要让线程等待多长时间 stopwatch.sleepMicrosUninterruptibly(microsToWait);//让线程阻塞microTowait微秒长的时间 return 1.0 * microsToWait / SECONDS.toMicros(1L);//返回阻塞的时间 &#125; 主要分3步： 1. 根据limiter创建时传入的参数，计算出生成这些数量的令牌需要多长的时间。 2. 让线程阻塞microTowait这么长的时间（单位：微秒） 3. 再返回阻塞了多久，单位：秒 具体它是怎么计算需要多长时间的呢？让我们来看看reserve(permits)方法。 12345678910111213141516171819202122232425262728final long reserve(int permits) &#123; checkPermits(permits);//检查参数是否合法 synchronized (mutex()) &#123; return reserveAndGetWaitLength(permits, stopwatch.readMicros()); &#125; &#125; ↓ ↓ ↓final long reserveAndGetWaitLength(int permits, long nowMicros) &#123; long momentAvailable = reserveEarliestAvailable(permits, nowMicros); return max(momentAvailable - nowMicros, 0); &#125; ↓ ↓ ↓final long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; resync(nowMicros);//here long returnValue = nextFreeTicketMicros; double storedPermitsToSpend = min(requiredPermits, this.storedPermits); double freshPermits = requiredPermits - storedPermitsToSpend; long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros; this.storedPermits -= storedPermitsToSpend; return returnValue; 最终调用的是reserveEarliestAvailable方法。先看看resync(nowMicros)方法。 12345678private void resync(long nowMicros) &#123; // if nextFreeTicket is in the past, resync to now if (nowMicros &gt; nextFreeTicketMicros) &#123; storedPermits = min(maxPermits, storedPermits + (nowMicros - nextFreeTicketMicros) / stableIntervalMicros); nextFreeTicketMicros = nowMicros; &#125; &#125; nextFreeTicketMicros的意思是：下次获取的时候需要减去的时间。如果是第一次调用accquire()方法，那nowMicros - nextFreeTicketMicros 就是从初始化（初始化的时候会给nextFreeTicketMicros 赋值一次,具体可以看RateLimiter的构造器）到第一次请求，这中间发生的时间。 这个方法的意思，如果当前时间比上一轮设置的下次获取的时间大（因为存在提前获取的情况，比如上次直接获取了10个，那上轮设置的nextFreeTicketMicros就是上一轮的时间+5s。后面会提到），那就计算这个中间理论上能生成多少的令牌。比如这中间隔了1秒钟，然后stableIntervalMicros=5000（稳定生成速度的情况下）,那么，就这中间就可以生成2个令牌。再加上它原先存储的storedPermits个，如果比maxPermits大，那最大也只能存maxPermits这么多。如果比maxPermits小，那就是storedPermits=原先存的+这中间生成的数量。同时记录下下次获取的时候需要减去的时间，也就是当前时间 （nextFreeTicketMicros ）。接下来继续看reserveEarliestAvailable方法： 12345678910111213final long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; //1 resync(nowMicros); //2 long returnValue = nextFreeTicketMicros;//3 double storedPermitsToSpend = min(requiredPermits, this.storedPermits);//4 double freshPermits = requiredPermits - storedPermitsToSpend;//5 long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros);//6 this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros;//7 this.storedPermits -= storedPermitsToSpend;//8 return returnValue;//9 &#125; 我们一行一行来看： 第二行设置好之后。第3行中将下次获取的时候需要减去的时间作为返回值（这点很重要）。 第4行是从存储的许可数量和请求的数量中获取小的那个值，第5行是获取这个值和请求的值的差。 这2句是什么意思呢？ 其实这2句就是使得RateLimiter能一定程度的突发请求的原因。假设requiredPermits=10，而我们能存的storedPermits=2，那么freshPermits=8，也就是多取了8个。而第6行就是计算这多取的8个需要多长时间才能生成？需要3秒。那么，就将这3秒钟加到我们前面赋值的“下次获取的时候需要减去的时间 ”。 比如在05秒的时候一次性获取了10个，那么，第7行的意思就是nextFreeTicketMicros=13S对应的系统的毫秒数。然后storedPermits就是-8。当过了1秒钟，下一次请求来调用acquire(1)的时候，resync方法中由于nowMicros1234final long reserveAndGetWaitLength(int permits, long nowMicros) &#123; long momentAvailable = reserveEarliestAvailable(permits, nowMicros); return max(momentAvailable - nowMicros, 0);//取较大的值 &#125; 也就是说，reserveAndGetWaitLength会返回max(13-6,0)，也就是7。而该方法的返回值又是用于sleep线程的，也就是我们在一开始看到的：12345public double acquire(int permits) &#123; long microsToWait = reserve(permits); stopwatch.sleepMicrosUninterruptibly(microsToWait); return 1.0 * microsToWait / SECONDS.toMicros(1L); &#125; 总结起来，最主要的是nowMicros,nextFreeTicketMicros这2个值。nextFreeTicketMicros在一开始构造器执行的时候会赋值一次为构造器执行的时间。当第一次调用accquire()的时候，resync会被执行，然后在accquire()中将nextFreeTicketMicros设置为当前时间。但是，需要注意的是，在reserveEarliestAvailable中会根据请求的令牌数和当前存储的令牌数进行比较。如果请求的令牌数很大，则会计算出生成这些多余的令牌需要的时间，并加在nextFreeTicketMicros上，从而保证下次调用accquire()的时候，根据nextFreeTicketMicros和当时的nowMicros相减，若&gt;0，则需要等到对应的时间。也就能应对流量的突增情况了。 所以最重要的是nextFreeTicketMicros，它记录了你这次获取的时候，能够开始生成令牌的时间。比如当前是05S，那若nextFreeTicketMicros=10，表示它要到10S才能开始生成令牌，谁叫前面的多拿了这么多呢。至于它这次是多拿了还是只是拿一个令牌，等待时间都是这么多。如果这次又多拿了，那下次就等待更久！ 123456789101112131415private static RateLimiter too=RateLimiter.create(2);//每秒2个 private RateLimitUtil()&#123;&#125;; public static void acquire(RateLimiter r,int num)&#123; double time =r.acquire(num); System.out.println(\"wait time=\"+time); &#125; public static void main(String[] args) throws InterruptedException &#123; acquire(too,1); acquire(too,10);//只等待了0.5秒就获取了10个 acquire(too,10);//等待了5秒就获取了10个 acquire(too,1);//虽然只获取1个，也是等待5秒 &#125; 参考:https://github.com/springside/springside4/wiki/Rate-Limiterhttp://blog.csdn.net/FoolishAndStupid/article/details/76285690http://blog.csdn.net/jiesa/article/details/50412027http://ifeve.com/guava-ratelimiter/https://github.com/google/guava/blob/fd919e54a55ba169dc7d9f54b7b3485aa7fa0970/guava/src/com/google/common/util/concurrent/RateLimiter.javahttps://github.com/google/guava/blob/fd919e54a55ba169dc7d9f54b7b3485aa7fa0970/guava-tests/test/com/google/common/util/concurrent/RateLimiterTest.java","categories":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/tags/算法/"}]},{"title":"Consistent-Hash一致性哈希算法","slug":"Consistent-Hash一致性哈希算法","date":"2017-12-17T05:53:21.000Z","updated":"2017-12-17T06:38:27.032Z","comments":true,"path":"2017/12/17/Consistent-Hash一致性哈希算法/","link":"","permalink":"http://xbynet.top/2017/12/17/Consistent-Hash一致性哈希算法/","excerpt":"理论部分一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题。一致性哈希修正了简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。","text":"理论部分一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题。一致性哈希修正了简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 场景描述：在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景。假设，我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为0号、1号、2号，现在，有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务上，以便它们能够分摊缓存的压力。原始的做法是对缓存项的键进行哈希，将hash后的结果对缓存器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上，我们仍然以刚才描述的场景为例，假设我们使用名称作为访问图片的key，假设图片名称是不重复的，那么，我们可以使用如下公式，计算出图片应该存放在哪台服务器上。hash（图片名称）% N,我们暂时称上述算ASH算法或者取模算法。 但是，使用上述HASH算法进行缓存时，会出现一些缺陷，试想一下，如果3台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？没错，很简单，多增加两存服务器不就行了，假设，我们增加了一台缓存服务器，那么缓存服务器的数量就由3台变成了4台，此时，如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，被除数不变的情况下，余数肯定不同，这种情况带来的结果就是当服务器数量变动时，所有的位置都要发生改变，换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据，同理，假设3存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从3台变为2台，如果想要访张图片，这张图片的缓存位置必定会发生改变，以前缓存的图片也会失去缓存的作用与意义， 由于大量缓存在同一时间失效，造成了缓存的雪崩，此时前端缓存已经无法起到部分压力的作用，后端服务器将会承受巨大的压力，整个系统很有可能被压垮，所以，我们应该想办法不让这种情况发生，但是由于上述HASH算法本身的缘故，使用取模法缓存时，这种情况是无法避免的，为了解决这些问题，一致性哈希算法诞生了。 我们来回顾一下使用上述算法会出现的问题。问题1：当缓存服务器数量发生变化时，会引起缓存的雪崩，可能会引起整体系统压力过大而崩溃（大量缓存同一时间失效）。问题2：当缓存服务器数量发生变化时，几乎所有缓存的位置都会发生改变，怎样才能尽量减少受影响的缓存呢？ 其实，一致性哈希算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性哈希算法是对2^32取模.首先，我们把二的三十二次方想象成一个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个点组成的圆,称为Hash环.仍然以之前描述的场景为例，假设我们有3台缓存服务器，服务器A、服务器B、服务器C，那么，在生产中，这三台服务器肯定有自己的IP地址，我们使用它们各自的IP地址进行哈希计算，使用哈希后的结果对2^32取模，可以使用如下公式示意。hash（服务器A的IP地址） % 2^32通过上述公式算出的结果一定是一个0到2^32-1之间的一个整数，我们就用算出的这个整数，代表服务器A，既然这个整数肯定处于0到2^32-1之间，那么，上图中的hash环定有一个点与这个整数对应，而我们刚才已经说明，使用这个整数代表服务器A，那么，服务器A就可以映射到这个环上,以此类推。 好了，到目前为止，我们已经把缓存服务器与hash环联系在了一起，我们通过上述方法，把缓存服务器映射到了hash环上，那么使用同样的方法，我们也可以将需要缓存的映射到hash环上。假设，我们需要使用缓存服务器缓存图片，而且我们仍然使用图片的名称作为找到图片的key，那么我们使用如下公式可以将图片映射到上图中的hash环上。hash（图片名称） % 2^32 现在服务器与图片都被映射到了hash环上，那么这个图片到底应该被缓存到哪一台服务器上呢？从图位置开始，沿顺时针方向遇到的第一个服务器就是需要缓存该图片的服务器。节点机器的失效删除：节点机器的添加：总结一下：1、与简单哈希不同，一致性hash有个hash环，同时会对服务器和需要换乘的对象进行hash，最终所有结果都会落到这个hash环上。然后根据顺时针规则找到最近的服务器进行缓存的存取。2、基于第1点,一致性hash无论是新增主机还是删除主机,需要改变位置的都是离那台主机最近的那些缓存,其他换成不需要改变位置。从而避免当服务器数量发生变化时，会产生缓存的雪崩。(如果使用之前的算法，服务器数量发生改变时，所有服务器的所有缓存在同一时间失效了，而使用一致性哈希算法时，服务器的数量如果发生改变，并不是所有缓存都会失效，而是只有部分会失效，而不至于所有压力都在同一时间集中到后端服务器上。) hash环的偏斜在介绍一致性哈希的概念时，我们理想化的将3台服务器均匀的映射到了hash环上但是，理想很丰满，现实很骨感，我们想象的与实际情况往往不一样。在实际的映射中，服务器可能会被映射成如下模样。如果服务器被映射成上图中的模样，那么被缓存的对象很有可能大部分集中缓存在某一台服务器上。如果出现上图中的情况，A、B、台服务器并没有被合理的平均的充分利用，缓存分布的极度不均匀，而且，如果此时服务器A出现故障，那么失效缓存的数量也将达到最大值，在极端情况下，仍然有可能引统的崩溃，上图中的情况则被称之为hash环的偏斜，那么，我们应该怎样防止hash环的偏斜呢？一致性hash算法中使用”虚拟节点“解决了这个问题 虚拟节点如果想要均衡的将缓存分布到3台服务器上，最好能让这3台服务器尽量多的、均匀的出现在hash环上，但是，真实的服务器资源只有3台，我样凭空的让它们多起来呢，没错，就是凭空的让服务器节点多起来，既然没有多余的真正的物理服务器节点，我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由节点虚拟复制而来的节点被称为”虚拟节点”。加入虚拟节点以后的hash环如下。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。“虚拟节点(virtual node )”是实际节点（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。从上图可以看出，A、B、C三台服务器分别虚拟出了一个虚拟节点，当然，如果你需要，也可以虚拟出更多的虚拟节点。引入虚拟节点的概念后，缓存的分布就均衡多了，上中，1号、3号图片被缓存在服务器A中，5号、4号图片被缓存在服务器B中，6号、2号图片被缓存在服务器C中，如果你还不放心，可以虚拟出更多的虚拟节点，以便减小hash偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。 通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图：“虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值：Hash(“192.168.1.100”);引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：Hash(“192.168.1.100#1”); // NODE1-1Hash(“192.168.1.100#2”); // NODE1-2 Java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import java.util.Collection;import java.util.HashSet;import java.util.Iterator;import java.util.Set;import java.util.SortedMap;import java.util.SortedSet;import java.util.TreeMap;import java.util.TreeSet;public class ConsistentHash&lt;T&gt; &#123; private final HashFunction hashFunction; private final int numberOfReplicas;// 节点的复制因子(100左右比较合理),实际节点个数 * numberOfReplicas =虚拟节点个数 private final SortedMap&lt;Long, T&gt; circle = new TreeMap&lt;Long, T&gt;();// 存储虚拟节点的hash值到真实节点的映射,server节点分布圆 public ConsistentHash(HashFunction hashFunction, int numberOfReplicas, Collection&lt;T&gt; nodes) &#123; this.hashFunction = hashFunction; this.numberOfReplicas = numberOfReplicas; for (T node : nodes) add(node); &#125; public void add(T node) &#123; for (int i = 0; i &lt; numberOfReplicas; i++) // 对于一个实际机器节点 node, 对应 numberOfReplicas 个虚拟节点 /* * 不同的虚拟节点(i不同)有不同的hash值,但都对应同一个实际机器node * 虚拟node一般是均衡分布在环上的,数据存储在顺时针方向的虚拟node上 */ circle.put(hashFunction.hash(node.toString() + i), node); &#125; public void remove(T node) &#123; for (int i = 0; i &lt; numberOfReplicas; i++) circle.remove(hashFunction.hash(node.toString() + i)); &#125; /* * 获得一个最近的顺时针节点,根据给定的key 取Hash * 然后再取得顺时针方向上最近的一个虚拟节点对应的实际节点 * 再从实际节点中取得 数据 */ public T get(Object key) &#123; if (circle.isEmpty()) return null; long hash = hashFunction.hash((String) key);// node 用String来表示,获得node在哈希环中的hashCode if (!circle.containsKey(hash)) &#123;//数据映射在两台虚拟机器所在环之间,就需要按顺时针方向寻找机器 SortedMap&lt;Long, T&gt; tailMap = circle.tailMap(hash); hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey(); &#125; return circle.get(hash); &#125; public long getSize() &#123; return circle.size(); &#125; /* * 查看MD5算法生成的hashCode值---表示整个哈希环中各个虚拟节点位置 */ public void testBalance()&#123; Set&lt;Long&gt; sets = circle.keySet();//获得TreeMap中所有的Key SortedSet&lt;Long&gt; sortedSets= new TreeSet&lt;Long&gt;(sets);//将获得的Key集合排序 for(Long hashCode : sortedSets)&#123; System.out.println(hashCode); &#125; System.out.println(\"----each location 's distance are follows: ----\"); /* * 查看用MD5算法生成的long hashCode 相邻两个hashCode的差值 */ Iterator&lt;Long&gt; it = sortedSets.iterator(); Iterator&lt;Long&gt; it2 = sortedSets.iterator(); if(it2.hasNext()) it2.next(); long keyPre, keyAfter; while(it.hasNext() &amp;&amp; it2.hasNext())&#123; keyPre = it.next(); keyAfter = it2.next(); System.out.println(keyAfter - keyPre); &#125; &#125; public static void main(String[] args) &#123; Set&lt;String&gt; nodes = new HashSet&lt;String&gt;(); nodes.add(\"A\"); nodes.add(\"B\"); nodes.add(\"C\"); ConsistentHash&lt;String&gt; consistentHash = new ConsistentHash&lt;String&gt;(new HashFunction(), 100, nodes); consistentHash.add(\"D\"); System.out.println(\"hash circle size: \" + consistentHash.getSize()); System.out.println(\"location of each node are follows: \"); consistentHash.testBalance(); //根据一致性hash算法获取客户端对应的服务器节点 System.out.println(consistentHash.get(RandomStringUtils.random(12))); &#125; &#125; 哈希函数如下：12345678910111213141516171819202122232425262728import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;/* * 实现一致性哈希算法中使用的哈希函数,使用MD5算法来保证一致性哈希的平衡性 */public class HashFunction &#123; private MessageDigest md5 = null; public long hash(String key) &#123; if (md5 == null) &#123; try &#123; md5 = MessageDigest.getInstance(\"MD5\"); &#125; catch (NoSuchAlgorithmException e) &#123; throw new IllegalStateException(\"no md5 algrithm found\"); &#125; &#125; md5.reset(); md5.update(key.getBytes()); byte[] bKey = md5.digest(); //具体的哈希函数实现细节--每个字节 &amp; 0xFF 再移位 long result = ((long) (bKey[3] &amp; 0xFF) &lt;&lt; 24) | ((long) (bKey[2] &amp; 0xFF) &lt;&lt; 16 | ((long) (bKey[1] &amp; 0xFF) &lt;&lt; 8) | (long) (bKey[0] &amp; 0xFF)); return result &amp; 0xffffffffL; &#125;&#125; 代码片段解释:在具体JAVA实现代码中，定义了一个TreeMap&lt; k, V&gt;用来保存虚拟机器节点到实际的物理机器的映射。机器以字符串形式来标识，故hash函数的参数为String而对于 数据的存储而言，逻辑上是按顺时针方向存储在虚拟机器节点中，虚拟机器节点通过TreeMap知道它实际需要将数据存储在哪台物理机器上。此外，TreeMap中的Key是有序的，而环也是顺时针有序的，这样才能当数据被映射到两台虚拟机器之间的弧上时，通过TreeMap的 tailMap()来寻找顺时针方向上的下一台虚拟机。1234if (!circle.containsKey(hash)) &#123;//数据映射在两台虚拟机器所在环之间,就需要按顺时针方向寻找机器 SortedMap&lt;Long, T&gt; tailMap = circle.tailMap(hash); hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey(); &#125; 参考:https://www.codeproject.com/Articles/56138/Consistent-hashinghttp://blog.csdn.net/cywosp/article/details/23397179http://www.zsythink.net/archives/1182http://blog.csdn.net/zhangskd/article/details/50256111https://www.cnblogs.com/hapjin/p/4737207.htmlhttp://langyu.iteye.com/blog/684087http://afghl.github.io/2016/11/19/implement-consistent-hashing.htmlhttps://gist.github.com/meigesir/1bf6338787946c18b47d","categories":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/tags/算法/"}]},{"title":"[读书笔记]chapter4-系统稳定性-大型网站分布式架构与设计实践","slug":"读书笔记-chapter4-系统稳定性-大型网站分布式架构与设计实践","date":"2017-12-17T05:17:13.000Z","updated":"2017-12-18T01:18:47.136Z","comments":true,"path":"2017/12/17/读书笔记-chapter4-系统稳定性-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter4-系统稳定性-大型网站分布式架构与设计实践/","excerpt":"主要内容:常用的日志分析命令，如cat,grep,wc,less,sed,awk等如何进行集群的监控，包括监控指标的定义、心跳检测、容量评估等如何保障高并发系统的稳定运行，如采用流量控制、依赖管理、服务分级、开关等策略。如何优化应用的性能，包括前端优化、Java程序优化、数据库查询优化等如何进行Java应用故障的在线排查，包括一系列排查工具的使用，及案例。 “You can’t control what you can’t measure”“Should you measure something be sure what you really measure otherwise the results can keep you far from reality. Always validate your assumptions and RTFM”“Don’t assumptions base on lack of understanding of used terminology or it’s ambiguity can be accounted for it”","text":"主要内容:常用的日志分析命令，如cat,grep,wc,less,sed,awk等如何进行集群的监控，包括监控指标的定义、心跳检测、容量评估等如何保障高并发系统的稳定运行，如采用流量控制、依赖管理、服务分级、开关等策略。如何优化应用的性能，包括前端优化、Java程序优化、数据库查询优化等如何进行Java应用故障的在线排查，包括一系列排查工具的使用，及案例。 “You can’t control what you can’t measure”“Should you measure something be sure what you really measure otherwise the results can keep you far from reality. Always validate your assumptions and RTFM”“Don’t assumptions base on lack of understanding of used terminology or it’s ambiguity can be accounted for it” 在线日志分析日志包含信息：异常堆栈信息，访问ip，请求url，应用响应时间，内存垃圾回收信息，及程序日志信息。通过对异常堆栈信息分析定位程序bug；对访问ip及url，参数的分析排查是否遭到攻击，及攻击的形式；通过应用的响应时间、垃圾回收及系统load来判断系统负载；通过线程dump，判断是否死锁及现场阻塞的原因；通过应用的GC(Garbage Collection)日志，对系统代码和JVM内存参数今夕优化，减少GC次数与stop the world时间，优化响应时间。 1、日志分析常用命令1234567891011cat 查看文件内容， -n 显示行号；分页查看的有:more/less; head/tail 显示文件头/尾多少行， -n指定行数， 对于tail -f可以实时持续显示最新的行。 sort:对列进行排序，默认按字符排序，-n指定按数字，-r逆序，-k指定列(从1开始)，-t指定列间分隔符(默认空格) wc:字符统计，-l 行数，-c字节数，-L最长行的长度 ，-w单词数 uniq:连续行去重,通常与sort联合使用。-c 显示重复次数，-u只显示不重复的，-d只显示重复的行 grep:字符串查找，-c显示行数, grep支持正则表达式。 find:文件查找 find path -name [filename|print] whereis:定位可执行文件的位置 expr:表达式求值，*需要转义 tar:归档文件 curl:URL访问工具 cut:过滤指定列，-f指定列号，-d指定列分隔符 例子:nginx为例，查看请求的访问量，访问量排名前10的ip地址。这样可以定位是否存在HTTP flood攻击(也称CC攻击).1cat access.log | cut -f1 -d &quot; &quot; | sort | uniq -c | sort -k 1 -n -r |head -10 例子:页面访问量排名前10的url1cat access.log | cut -f4 -d &quot; &quot; | sort | uniq -c | sort -k 1 -n -r |head -10 例子:查看最耗时页面(响应时间最长的url)1cat access.log | sort -k 2 -n -r |head -10 例子:统计404请求的占比(404请求过多，要么就是有恶意攻击者在进行扫描，要么就是系统出问题了，500也是如此。)1export total_line=`wc -l access.log | cut -f1 -d &quot; &quot;` &amp;&amp; export not_found_line=`awk &apos;$6==&apos;404&apos;&#123;print $6&#125;&apos; access.log|wc -l` &amp;&amp; expr $not_found_line \\* 100 / $total_line 2、日志分析脚本sed：流编辑器，一行一行读取，面向行，不会修改文件本身。 set [options] ‘command’ files 将日志中的xxx替换成yahoo输出: sed ‘s/xxx/yahoo/‘ access.log | head -10筛选日志中指定的行输出: sed -n ‘2,6p’ access.log根据正则表达式删除日志中指定的行 sed ‘/qq/d’ access.log支持将command写到文件里再加载执行: sed [options] -f scriptfile files awk:提供一个类似于编程的开放环境，可以自定义文本处理规则，修改和重新组织文件中的内容。awk [option] ‘pattern {action}’ fileawk ‘/google/{print $5,$6}’ access.log | head -10awk ‘length($0)&gt;40{print $3}’ access.log | head -10 $0表示当前行awk ‘{line = sprintf(“method:%s,response:%s”,$3,$7);print line}’ access.log | head -10支持将command写到文件里再加载执行: awk [options] -f scriptfile files 集群监控1、监控指标系统运行的繁忙程度、健康状态，反映在一系列的运行期指标上。理论基础：木桶原理。指标如CPU负载，磁盘IO，内存占用，FullGC，请求QPS过高，网络繁忙，丢包率等。 load: load即特定时间间隔内运行队列中的平均线程数。如果一个线程没有处于IO等待、等待wait、终止等状态时，那么该线程就会处于运行队列中。每个CPU的核都维护了一个运行队列，系统的load主要由运行队列来决定。load值越大说明系统CPU越繁忙。一般来说，只要每个CPU当前的活动现场数不大于3，其负载就可以认为是正常的，如果大于5，则表示负载挺高了，需要采取措施来降低系统负载。top和uptime可以查看系统的load值。执行uptime将会显示出系统的当前时间、上线时间、当前的用户数量以及过去1、5、15分钟内的系统负载。12$ uptime10:52 PM up 1337 days, 7:45, 3 users, load averages: 0.21, 0.24, 0.23 CPU利用率： CPU消耗主要在这几个方面:用户进程，内核进程，中断处理，I/O等待，Nice时间(优先级处理)，丢失时间，空闲等。CPU利用率就是这些时间所占总时间的百分比。top命令查看:123456789top | grep Cpu us — 用户空间占用CPU的百分比。sy — 内核空间占用CPU的百分比。ni — 改变过优先级的进程占用CPU的百分比id — 空闲CPU百分比wa — IO等待占用CPU的百分比hi — 硬中断（Hardware IRQ）占用CPU的百分比si — 软中断（Software Interrupts）占用CPU的百分比 st — 丢失时间(Steal Time),是在硬件虚拟化开始流行后新增的，表示被强制等待虚拟CPU的时间，此时hypervisor正在为另一个虚拟处理器服务。如果st占比较高，则表示当前虚拟机与宿主上的其他虚拟机间的CPU争用较为频繁。 若 %iowait 的值过高，表示硬盘存在I/O瓶颈 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量 若 %idle 的值持续低于 10，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU。 对于多U多核CPU监控，在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况。如果按Shift+H键，则可以按线程来查看CPU消耗情况。这一点对java应用来说很有用。 Linux查看物理CPU个数、核数、逻辑CPU个数123456789# 总核数 = 物理CPU个数 X 每颗物理CPU的核数# 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数# 查看物理CPU个数cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l# 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq# 查看逻辑CPU的个数cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l 磁盘剩余空间: df -h 查看磁盘剩余空间du 查看目录和文件的大小，如du -d 1 -h /home/xby , -d指定递归深度 网络traffic: 对于进行负载均衡和反向代理的节点，或作为集群master的节点，对网卡和带宽的要求更高。在某些突发大流量情况下有可能会成为瓶颈。因此关注网络的流量，清楚各节点的阀值和水位也很重要。sar -n DEV 1 1 查看系统网络状态。-n 汇报网络状态，DEV表示查看各个网卡的流量，1表示抽样间隔为1秒1次，后面的1表示抽样总次数。 12345678IFACE：就是网络设备的名称；rxpck/s：每秒钟接收到的包数目txpck/s：每秒钟发送出去的包数目rxbyt/s：每秒钟接收到的字节数txbyt/s：每秒钟发送出去的字节数rxcmp/s：每秒钟接收到的压缩包数目txcmp/s：每秒钟发送出去的压缩包数目txmcst/s：每秒钟接收到的多播包的包数目 如果你使用SOCK关键字，则会针对socket连接进行汇报，例如：123456$ sar -n SOCK 1 3tcpsck：当前正在被使用于TCP的socket数目udpsck：当前正在被使用于UDP的socket数目rawsck：当前正在被使用于RAW的socket数目ip-frag：当前的IP分片的数目如果你使用FULL关键字，相当于DEV、EDEV和SOCK三者的综合。 让sar在某个特定时间结束12sar 1 0 -e 15:00:00 &gt; data.txt //每隔1秒记录CPU的使用情况，直到15点，数据将保存到data.txt文件中。(-e 参数表示结束时间，注意时间格式：必须为hh:mm:ss格式) 磁盘I/O iostat -d -k 查看系统的I/O状况，-d表示查看磁盘使用情况 -k表示kb单位。12345678tps：该设备每秒的传输次数（transfers per second）。kB_read/s：每秒从设备（drive expressed）读取的数据量；kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。 await表示平均每次设备I/O操作的等待时间（以毫秒为单位）。 svctm表示平均每次设备I/O操作的服务时间（以毫秒为单位）。%util表示一秒中有百分之几的时间用于I/O操作。 对以磁盘IO性能，一般有如下评判标准：正常情况下svctm应该是小于await值的，而svctm的大小和磁盘性能有关，CPU、内存的负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。await值的大小一般取决与svctm的值和I/O队列长度以及I/O请求模式，如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。%util项的值也是衡量磁盘I/O的一个重要指标，如果%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷的在工作，该磁盘可能存在瓶颈。长期下去，势必影响系统的性能，可以通过优化程序或者通过更换更高、更快的磁盘来解决此问题。 内存使用:free -m 可用内存=free+buffers+cached123456789101112131415161718[root@nonamelinux ~]# free total used free shared buffers cachedMem: 386024 377116 8908 0 21280 155468-/+ buffers/cache: 200368 185656Swap: 393552 0 393552第二行(mem)：total:总计物理内存的大小。used:已使用多大。free:可用有多少。Shared:多个进程共享的内存总额。Buffers/cached:缓存的大小。第三行(-/+ buffers/cached):used:已使用多大。free:可用有多少。第二行(mem)的used/free与第三行(-/+ buffers/cache) used/free的区别。这两个的区别在于使用的角度来看，第一行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是8908KB,已用内存是377116KB,其中包括，内核（OS）使用+Application(X,oracle,etc)使用的+buffers+cached.第三行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。所以从应用程序的角度来说，可用内存=free+buffers+cached 使用vmstat查看swap I/O的情况,确保swap I/O较低。否则会严重影响系统性能。 QPS-query per second. 每秒的查询数： qps在很大程度上代表了系统在业务上的繁忙程度，而每次请求的背后，可能对应着多次磁盘io，多次网络请求，以及多个cpu时间片。通过关注qps是否超过阀值，来决定是否进行扩容，以避免压力过大而宕机。 RT-response time 响应时间: rt是一个非常关键的指标，直接关系到前端用户的体验。因此需要尽可能降低rt。例如，通过CDN缩短用户请求的物理路径，通过内容压缩来减少传输的字节数，使用缓存来减少磁盘io和网络请求等。而通过nginx的access log ，便可以得知每个请求的响应时间。不过需要在访问日志的输出格式中加上$request_time变量。 数据库相关指标select/ps,update/ps,delete/ps. 措施:增加读库，分库分表等。 GC:对于Java应用而言，不得不关注GC。GC又分为Minor GC与Full GC.在JVM内存分代回收的情况下，对象在JVM内存的新生代Eden区中分配。当Eden区没有足够的空间时虚拟机将发起一次MinorGC，该GC发生在新生代，而且也会比较频繁，回收速度也很快。而Major GC,也称Full GC,是发生在年老代的，速度比MinorGC慢得多，因此导致应用停顿时间(stop the world)也就更长。可以对JVM的一些内存参数进行调整和优化，以降低GC时应用停止响应的时间。如果一个应用频繁进行Full GC，那么它的性能肯定是有问题的。这时候就需要我们实时获取GC情况。 2、心跳检测对于集群服务器和部署于其上的应用的心跳检测是必不可少的，因为这可以帮助我们及时感知问题。对于自治的分布式系统而言，一般都有一整套的集群心跳检测机制，能够实时地移除掉宕机的Slave，避免路由规则再次分配到它。如果是Master宕机，集群也能够自动进行Master选举。如Zookeeper.也有一部分系统如MySQL,Nginx，可以通过外部干预，使备份机器stand by，或是双机互为备份，以实现故障切换，避免单点故障。ping 是最常用的心跳检测方法。 -c 指定执行次数应用层检测：虽然ping可以检测网络是否畅通，但是对于应用层而言，即使网络畅通，也有可能出现问题，如频繁FullGC导致应用不能响应等。应用可以开放一个自检接口，我们可以通过脚本curl去请求自检接口，来达到心跳检测的目的。 curl -s选项为静默模式。 3、容量评估和应用水位 新系统上线之前或者已上线运行的系统上需要做一些推广活动时，相关的业务方需要对系统的访问量进行评估。业务方给出PV,UV预估，然后我们再逐一细化，推导出落到每一个独立的系统，接口上的流量大概是多少，这样一来，每个子系统所承载的量也就清晰了。然后再评估机器的数量，网络的带宽和技术实现方式。压力测试最关系的是qps和rt两个指标在进行系统峰值评估时，一般会遵循80/20原则。我们也可以通过水位图来了解系统的压力。当前水位=当前总qps/(单台机器极限qpsx机器数)x100% 流量控制为了防止某些热点事件或者推广活动导致的访问量激增的情况，需要做好流量控制，在流量到来之前，指定相应的应急预案，以避免系统被激增的流量压垮。流量控制可以从多个维度来进行，如系统的总并发请求数限制，或者限制单位时间内的请求次数(如限制qps)，或者通过白名单机制来限制每一个接入系统调用的频率等。流控实现，最简单的是基于java的信号量Semaphore,更高级点的是采用漏桶或令牌桶算法，guava中有个RetaLimiter实现了令牌桶算法。还有种方式，就是将消息异步化，扔到消息队列后不管，直接返回响应给用户。如基于ActiveMQ,不过需要考虑消息积压，事务消息，重复投递去重等问题。 服务稳定性：分布式SOA环境下系统的依赖错综复杂。如何控制由于第三方服务不稳定而形成的多米诺骨牌效应。1、依赖管理：分布式系统由于高度解耦，最终形成一个网状的依赖关系。对于服务提供者而言，它必须轻蹙，谁调用了自己，调用的频次怎样，这样才能知道当前系统的压力和水位在一个怎样的层次上，是否需要进行扩容。同时，服务提供者也需要对自己依赖的服务了然于胸，哪些是核心链路所依赖的服务，哪些是非核心链路的依赖，以便依赖的系统出现问题时，及时进行服务降级,避免因非核心依赖导致的故障传导，影响当前系统的稳定性。分布式依赖管理的依据：通过调用日志的收集和整理，将其中的调用关系，频次统计分析出来. 2、优雅降级通过依赖管理，我们知道了服务间的调用关系。接下来，我们便可以根据当前系统所依赖的服务及系统流程，来判断依赖的服务是否会影响应用的主流程，以此来决定当前应用依赖的优先级。当依赖的服务出现不稳定，响应缓慢或者掉调用超时，宕机等时，当前系统需要能够及时感知并进行相应处理，否则大量超时的调用，有可能将当前系统的线程和可用连接数用完，导致新的请求进不来，服务僵死，这便是故障传递。最终形成多米诺骨牌效应。使得整个集群都不能对外提供服务。这时服务调用优雅降级的重要性便体现出来了。对于调用超时的非核心服务，可以设定一个阀值，如果调用超时的次数超过这个阀值，便自动将该服务降级。此时跳过对该服务的调用，并指定一个休眠的时间点进行重试。 3、服务分级服务提供者需要对服务消费者的优先级进行区分，哪些调用将影响核心链路，哪些调用是非核心链路，当系统压力过大时，必须确保等级高的应用、核心的调用链路优先畅通，而其他的可以暂时”丢车保帅”。 4、开关系统需要预先定义一些开关来控制程序的服务提供策略。 5、应急方案应急方案需要明确地规定服务的级别，梳理清楚核心应用的调用链路，对于每一种故障，都做出合理的假设，并且要有针对性的处理方法。对于级别低的调用和功能，事先应准备好屏蔽的开关和接口。服务的级别决定哪些调用者是”车”，哪些调用者是”帅”，必要时候要丢车保帅。备用扩容，开关，验证码，流控，负载均衡策略动态修改，多机房部署，异地容灾等 高并发系统设计高并发系统设计与普通系统设计的区别在于，既要保障系统的可用性和可扩展性，又要兼顾数据的一致性。还要处理多线程同步的问题。任何细微问题，都有可能在高并发环境下被无限放大，直至系统宕机。 1、操作原子性：线程锁，CAS(CompareAndSet) Atomic类,数据库事务操作(ACID,Atomic,Consistency,Isolation,Durability)2、数据一致性:分布式系统常常通过复制数据来提高系统的可靠性和容错性，并且将数据的副本放到不同的机器上。由于多个副本的存在，使得维护副本一致性的代价很高。因此许多分布式系统都采用弱一致性或者是最终一致性，来提高系统的性能和吞吐能力，所以出现了不同的一致性模型和算法。 强一致性要求无论数据的更新操作是在哪个副本上执行，之后所有的读操作都要能够获取到更新的最新数据。这种情况下需要通过分布式事务来保证操作的原子性，并且外界无法读到系统的中间状态。 弱一致性指的是系统的某个数据被更新后，后续对该数据的读取操作取到的可能是更新前的值，也可能是更新后的值。全部用户完全读取到更新后的数据需要经过一段时间，这段时间称为”不一致性窗口”。 最终一致性是弱一致性的特殊形式，与弱一致性的区别就是”不一致性窗口”的时间依赖于网络的延迟、系统的负载、副本的个数。 分布式系统采用最终一致性的例子很多，如MySQL的主从数据同步，ZooKeeper的Leader election和Atomic broadcast等。 3、系统可扩展性/可伸缩性 是一种对软件系统计算处理能力的评价指标。高可扩展性意味着系统只要经过很少的改动，甚至只需要添加硬件设备，便能够实现整个系统处理能力的线性增长。由于单台机器硬件受制于科技发展水平和成本，因此，可扩展性更加侧重于系统的水平扩展。设计好的系统可以限制扩展。系统的可扩展性也会受到一些因素的制约，CAP理论(Consistency,Availability,Tolerance of network Partition)指出，系统的一致性、可用性和可扩展性这三个要素对于分布式系统来说，很难同时满足。因此在设计过程中需要进行一些取舍。某些情况下可以放宽对于一致性的严格要求，以使得系统更易于扩展，可靠性更高。 4、例子：并发减库存采用图像验证码防止机器请求(现在图像识别，打码平台的出现，对验证码的要求更高了，不然很容易被绕过)对于高并发访问的浏览型系统来说，单机数据库如不进行扩展，往往很难支撑。因此常常会采用分库技术来提高数据库的并发能力，并通过分布式缓存技术，降低磁盘io及数据库压力，加快后端的响应速度，qps也就越高。使用分库和缓存技术，吞吐量的确是上去了，但是却带来了跨数据库或者是分布式缓存与数据库之间难以进行事务操作。(分布式事务实现所需付出的性能代价太高)为了避免数据不一致的情况发生，可采用实际库存和浏览库存分离的方式。浏览库存取缓存数据。MySQL的myisam对写操作采用表锁，innodb则是行锁。但即便是行锁缩小了粒度，仍然在高并发修改某一行的情况下可能会出现性能瓶颈，此时我们需要拆行，将原本一行的存储，放在多行上，路由策略可以采用用户id取模等方式。 性能优化如何找到性能瓶颈Web的性能优化涉及前端优化、服务端优化、操作系统优化、数据库查询优化、JVM调优等。对于性能优化来说，第一步也是最重要的一步，便是寻找可以优化的点，即性能瓶颈。根据木桶原理，性能瓶颈就是那块最短的木板。 1、前端优化工具-YSlow：网页性能分析2、页面响应时间：这个受影响因素会很多，不能作为最终的依据。我们更关注服务端的RT(response time)时间。3、方法响应时间：定位到响应慢的请求以后，接下来需要深入发掘导致请求响应慢的原因，并且定位到具体的代码。通过对代码的检查分析，能够定位到具体的方法和代码行。不过我们一般借助于btrace——java动态跟踪工具来快速定位和发现耗时的方法。首先，编写一段测试代码：12345678910@Overrideprotected void doPost(HttpServletRequest req,HttpServletResponse resp) throws ServletException,IOException&#123; PrintWriter out=resp.getWriter(); try&#123; Thread.sleep(500L);//通过休眠模拟执行时间较长的方法 &#125;catch(InterruptException e)&#123; &#125; out.write(\"success\");&#125; 然后，编写计算方法响应的btrace脚本123456789101112131415161718192021import com.sun.btrace.annotations.*;import static com.sun.btrace.BTraceUtils.*;@BTracepublic class MethodTimeCost&#123; @TLS private static long starttime; @OnMethod(clazz=\"/com\\\\.http\\\\.testbtrace\\\\..*/\",method=\"/.+/\",location=@Location(Kind.ENTRY)) public static void startExecute()&#123; starttime=timeMillis(); &#125; @OnMethod(clazz=\"/com\\\\.http\\\\.testbtrace\\\\..*/\",method=\"/.+/\",location=@Location(Kind.RETURN)) public static void endExecute()&#123; long timecost=timeMillis()-starttime; if(timecost&gt;50)&#123; print(strcat(strcat(name(probeClass()),\".\"),probeMethod())); print(\" [\"); print(strcat(\"Time taken: \",str(timecost))); println(\"] \"); &#125; &#125;&#125; 启动需要跟踪的java程序，然后执行jps获取该进程的id，最后执行这段btrace脚本。如id为3683。1btrace -cp build 3683 MethodTimeCost.java 当然btrace的使用并不局限于此，它的功能十分强大，特别是在Java应用在线故障排查方面，是不可或缺的利器。 4、GC日志分析GC日志能够反映出Java应用执行内存回收详细情况，如Minor GC,Full GC的频繁程度、GC所导致应用停止响应的时间，引起GC的原因等。根据程序吞吐量优先还是响应时间优先的不同，sun HotSpot虚拟机1.6版在服务器端提供Parallel Scavenge/Parallel Old与ParNew/CMS两种垃圾收集器组合，其中Parallel Scavenge和ParNew为新生代的垃圾收集器，而Parallel Old和CMS为老年带的垃圾收集器。在JVM启动时加上下面几个参数：-verbose:gc -Xloggc:/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps其他GC日志相关参数有-XX:+PrintGC 输出GC日志 -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息日志示例：1234560.756: [Full GC (System) 0.756: [CMS: 0K-&gt;1696K(204800K), 0.0347096 secs] 11488K-&gt;1696K(252608K), [CMS Perm : 10328K-&gt;10320K(131072K)], 0.0347949 secs] [Times: user=0.06 sys=0.00, real=0.05 secs] 1.728: [GC 1.728: [ParNew: 38272K-&gt;2323K(47808K), 0.0092276 secs] 39968K-&gt;4019K(252608K), 0.0093169 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 2.642: [GC 2.643: [ParNew: 40595K-&gt;3685K(47808K), 0.0075343 secs] 42291K-&gt;5381K(252608K), 0.0075972 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 4.349: [GC 4.349: [ParNew: 41957K-&gt;5024K(47808K), 0.0106558 secs] 43653K-&gt;6720K(252608K), 0.0107390 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 5.617: [GC 5.617: [ParNew: 43296K-&gt;7006K(47808K), 0.0136826 secs] 44992K-&gt;8702K(252608K), 0.0137904 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 7.429: [GC 7.429: [ParNew: 45278K-&gt;6723K(47808K), 0.0251993 secs] 46974K-&gt;10551K(252608K), 0.0252421 secs] 我们取倒数第二条记录分析一下各个字段都代表了什么含义15.617（时间戳）: [ GC（Young GC） 5.617（时间戳）: [ParNew（使用ParNew作为年轻代的垃圾回收期）: 43296K（年轻代垃圾回收前的大小）- &gt;7006K（年轻代垃圾回收以后的大小）(47808K)（年轻代的总大小）, 0.0136826 secs（回收时间）] 44992K（堆区垃圾回收前的大小）-&gt;8702K（堆区垃圾回收后的大小）(252608K)（堆区总大小）, 0.0137904 secs（回收时间）] [ Times: user=0.03（Young GC用户耗时） sys=0.00（Young GC系统耗时）, real=0.02 secs（Young GC实际耗时）] 我们再对数据做一个简单的分析从最后一条GC记录中我们可以看到 Young GC回收了 45278-6723=38555K的内存Heap区通过这次回收总共减少了 46974-10551=36423K的内存。38555-36423=2132K说明通过该次Young GC有2132K的内存被移动到了Old Gen， 我们来验证一下在最后一次Young GC的回收以前 Old Gen的大小为8702-7006=1696回收以后Old Gen的内存使用为10551-6723=3828Old Gen在该次Young GC以后内存增加了3828-1696=2132K 与预计的相符 CMS(Concurrent Mark-Sweep)是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上-XX:+UseConcMarkSweepGC (默认HotSpot JVM使用的是并行收集器)，这个参数表示对于老年代的回收采用CMS。CMS采用的基础算法是：标记—清除。整个过程大致分为4步： 初始标记 (CMS initial mark):会STW(Stop The World),为了收集应用程序的对象引用需要暂停应用程序线程,该阶段完成后，应用程序线程再次启动 并发标记 (CMS concurrent mark):从第一阶段收集到的对象引用开始，遍历所有其他的对象引用 重新标记 (CMS remark) :会STW,由于对象引用可能会发生进一步改变，因此应用程序线程会再一次被暂停以更新这些变化,并且在进行实际的清理之前确保一个正确的对象引用视图 并发清理 (CMS concurrent sweep) :所有不再被引用的对象将从堆里清除掉整个过程中，1、3会stw，但是2、4是最耗时的。所以可以减少stw的时间。 注意：一次CMS至少会给Full GC的次数 + 2，因为Full GC的次数是按照老年代GC时stop the world的次数而定的。一般CMS引起的GC时间会很短如ms级，如果达到秒级，那么就需要注意了，很可能是CMS发生了concurrent mode fail之后会退化成Serial Old收集器，它是单线程的标记-压缩收集器，所以耗时会非常的长。查看日志时需要注意是否存在concurrent mode fail 123456789101112132014-12-08T17:24:18.514+0800: 77443.326: [GC [1 CMS-initial-mark: 1382782K(1843200K)] 1978934K(4710400K), 0.0702700 secs] [Times: user=0.07 sys=0.00, real=0.07 secs]2014-12-08T17:24:18.586+0800: 77443.398: [CMS-concurrent-mark-start] 2014-12-08T17:24:19.890+0800: 77444.702: [CMS-concurrent-mark: 1.206/1.303 secs] [Times: user=2.80 sys=0.07, real=1.30 secs] 2014-12-08T17:24:19.890+0800: 77444.702: [CMS-concurrent-preclean-start] 2014-12-08T17:24:19.906+0800: 77444.718: [CMS-concurrent-preclean: 0.015/0.015 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] 2014-12-08T17:24:19.906+0800: 77444.718: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2014-12-08T17:24:25.181+0800: 77449.993: [CMS-concurrent-abortable-preclean: 5.241/5.275 secs] [Times: user=6.03 sys=0.09, real=5.27 secs] 2014-12-08T17:24:25.187+0800: 77449.999: [GC[YG occupancy: 749244 K (2867200 K)]77450.000: [Rescan (parallel) , 0.0276780 secs]77450.028: [weak refs processing, 0.2029030 secs] [1 CMS-remark: 1382782K(1843200K)] 2132027K(4710400K), 0.2340660 secs] [Times: user=0.43 sys=0.00, real=0.23 secs2014-12-08T17:24:25.424+0800: 77450.236: [CMS-concurrent-sweep-start] 2014-12-08T17:24:27.420+0800: 77452.232: [CMS-concurrent-sweep: 1.918/1.996 secs] [Times: user=2.61 sys=0.05, real=2.00 secs] 2014-12-08T17:24:27.421+0800: 77452.233: [CMS-concurrent-reset-start] 2014-12-08T17:24:27.430+0800: 77452.242: [CMS-concurrent-reset: 0.010/0.010 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 我们可以看到Full GC的次数应该是2,(因为Full GC的次数是按照老年代GC时stop the world的次数而定的):0.07 secs(initial mark),0.23 secs(remark).可以用jstat -gc得到的时间Full GC的次数和时间。 最后再次强调一下: Full GC == Major GC指的是对老年代/永久代的stop the world的GC Full GC的次数 = 老年代GC时 stop the world的次数 Full GC的时间 = 老年代GC时 stop the world的总时间 CMS 不等于Full GC，我们可以看到CMS分为多个阶段，只有stop the world的阶段被计算到了Full GC的次数和时间，而和业务线程并发的GC的次数和时间则不被认为是Full GC Full GC本身不会先进行Minor GC，我们可以配置，让Full GC之前先进行一次Minor GC，因为老年代很多对象都会引用到新生代的对象，先进行一次Minor GC可以提高老年代GC的速度。比如老年代使用CMS时，设置CMSScavengeBeforeRemark优化，让CMS remark之前先进行一次Minor GC。 最后要重点注意的是：jstat命令的man-pages说FGC代表的是Full GC事件，而我们通常认为那就是是Full GC的次数。CMS GC参考:https://kamilszymanski.github.io/interpreting-jstats-number-of-full-gc-events/http://blog.csdn.net/iter_zc/article/details/41825395http://www.iteye.com/topic/1119491 CMS缺点:CMS回收器采用的基础算法是Mark-Sweep。所有CMS不会整理、压缩堆空间。这样就会有一个问题：经过CMS收集的堆会产生空间碎片。CMS不对堆空间整理压缩节约了垃圾回收的停顿时间，但也带来的堆空间的浪费。为了解决堆空间浪费问题，CMS回收器不再采用简单的指针指向一块可用堆空间来为下次对象分配使用。而是把一些未分配的空间汇总成一个列表，当JVM分配对象空间的时候，会搜索这个列表找到足够大的空间来hold住这个对象。 需要更多的CPU资源。从上面的图可以看到，为了让应用程序不停顿，CMS线程和应用程序线程并发执行，这样就需要有更多的CPU，单纯靠线程切 换是不靠谱的。并且，重新标记阶段，为空保证STW快速完成，也要用到更多的甚至所有的CPU资源。当然，多核多CPU也是未来的趋势！ CMS的另一个缺点是它需要更大的堆空间。因为CMS标记阶段应用程序的线程还是在执行的，那么就会有堆空间继续分配的情况，为了保证在CMS回 收完堆之前还有空间分配给正在运行的应用程序，必须预留一部分空间。也就是说，CMS不会在老年代满的时候才开始收集。相反，它会尝试更早的开始收集，已 避免上面提到的情况：在回收完成之前，堆没有足够空间分配！默认当老年代使用68%的时候，CMS就开始行动了。 – XX:CMSInitiatingOccupancyFraction =n 来设置这个阀值。但是如果在CMS运行期间，预留的内存无法满足程序需要时，则会出现concurrent mode fail之后会退化成Serial Old收集器，它是单线程的标记-压缩收集器，所以耗时会非常的长.总得来说，CMS回收器减少了回收的停顿时间，但是降低了堆空间的利用率。 啥时候用CMS:如果你的应用程序对停顿比较敏感，并且在应用程序运行的时候可以提供更大的内存和更多的CPU(也就是硬件牛逼)，那么使用CMS来收集会给你带来好处。还有，如果在JVM中，有相对较多存活时间较长的对象(老年代比较大)会更适合使用CMS。 问题：minor GC是否也会导致STW呢? https://www.zhihu.com/question/29114369?sort=createdhttps://blogs.oracle.com/jonthecollector/our-collectorshttps://www.zhihu.com/question/21535747/answer/144884632目前所有的新生代gc都是需要STW的，STW总会发生 不管是新生代还是老年代 就算是CMS也有STW的时候。重点是 时间长短Serial：单线程STW，复制算法ParNew：多线程并行STW，复制算法Parallel Scavange：多线程并行STW，吞吐量优先，复制算法G1：多线程并发，可以精确控制STW时间，整理算法因为full gc耗时远高于minor gc，所以通常忽略minor gc几十毫秒的停顿。 GC收集器分类与常见组合：按线程：单线程：Serial、SerialOld多线程：ParNew、Parallel Scavenge、Parallel Old、CMS、G1按适用代：新生代: Serial、ParNew、Parallel Scavenge老年代: SerialOld、CMS 、Parallel OldG1可以在新生代和老年代使用常见的组合ParNew+CMS ； Parallel Scavenge+Parallel Old HotSpot JVM支持哪些垃圾收集器？Hotspot JVM实现包括了Serial GC, Parallel GC, CMS, G1 GC 4套算法组合。下面来讲一讲这些算法组合分别包括了哪些算法。 Serial GC算法：Serial Young GC ＋ Serial Old GC （实际上它是全局范围的Full GC），适用于小程序或低配置计算机系统； Parallel GC算法：（并行的）Parallel Young GC ＋ PS MarkSweep GC / （并行的）Parallel Old GC（全局范围的Full GC），选PS MarkSweep GC 还是 Parallel Old GC 由参数UseParallelOldGC来控制，适用于对吞吐量敏感的应用； CMS算法：（并行的）ParNew（Young）GC + （并发的）CMS（Old）GC （piggyback on ParNew的结果／老生代存活下来的object只做记录，不做compaction）＋ Full GC for CMS算法（应对核心的CMS GC某些时候的不赶趟，开销很大），适用于对延时敏感的应用； G1 GC：（并行的）Young GC ＋（并行的）mixed GC（新生代，再加上部分老生代）＋ Full GC for G1 GC算法（应对G1 GC算法某些时候的不赶趟，开销很大）。G1 GC中开销较大的object marking算法部分是跟applicaiton一起并发的，其开始到结束时间上甚至可以跨越好几次Young GC。适用于延时和吞吐量都有要求的应用，调教相对前述3中GC算法组合为烦。 上述组合描述已特别指出并行（parallel）还是并发（concurrent）。Hotspot JVM语境下，这两个概念是严格区分的。并行是指STW（stop-the-world）状态下的GC算法或部分算法的多线程运行；并发是指非STW状态下GC算法或部分算法跟applicaiton一起分享多个线程来运行。关于G1，可参考:http://www.importnew.com/15311.html http://blog.csdn.net/qq_34280276/article/details/52863551 https://blogs.oracle.com/jonthecollector/our-collectors http://ivywang.iteye.com/blog/2146645 5、数据库查询许多请求响应速度慢的原因，最终都是由于糟糕的数据库查询语句所导致的。如何定位到这些糟糕的查询语句呢？MySQL提供慢查询日志的功能。能够记录下响应时间超过一定阀值(默认10秒)的SQL查询.查看是否启用慢日志: show variables like ‘log_slow_queries’; 查看慢于多少秒的SQL会记录到慢日志中:show variables like ‘long_query_time’;通过配置my.cnf，可以修改满日志的相关配置: 123456[mysqld]port= 3306slow-query-log=ON # 慢查询：确认开启slow-query-log-file=&quot;/var/log/mysql/mysql-slow.log&quot; # 慢查询：日志文件及路径long_query_time = 1 # 慢查询：指定超过1s仍未完成的语句，为执行过慢的语句.默认是10s 测试： 123451.执行一条慢查询SQL语句mysql&gt; select sleep(2);2.查看是否生成慢查询日志ls /usr/local/mysql/data/slow.log如果日志存在，MySQL开启慢查询设置成功！ 6、系统资源的使用：查看CPU当前的利用率和系统的load，查看网卡的流量，查看磁盘IO的密集程度，查看内存的使用等。通过硬件指标来判断资源是否已经达到瓶颈。通过这些指标可以将应用分为CPU密集型、网络密集型、磁盘IO密集型、内存使用密集型等。根据应用的特征来进行机器配置的选型，以便使资源的利用达到最大化。 性能测试工具性能测试是指通过一些自动化的测试工具模拟多种正常、峰值，以及异常负载的条件来对系统的各项性能指标进行测试。在系统上线之前，需要经过一系列的性能测试，以确定系统在各种负载下的性能指标变化，发现系统潜在的一些瓶颈和问题。 1、ab-apache bench，内置于apache http server中。是一款专门用来对HTTP服务器进行性能测试的工具，可以模拟多个并发请求来对服务器进行压力测试，得出服务器在高负载下能够支持的qps及应用的响应时间。 2、Apache JMeter ：功能比ab更强大。在执行性能测试的同时，可以通过一些工具，如jsconsole,VisualVM,来远程实时查看测试机的负载，内存使用，GC等情况。以Tomcat为例，配置JAVA_OPTS： 12CATALINA_OPTS=&quot;$CATALINA_OPTS -Djava.rmi.server.hostname=172.16.18.155 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=18081 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false&quot; 3、HP LoadRunner -商业性能测试工具 4、反向代理引流在分布式环境下，流量真正到达服务器之前，一般会经过负载均衡设备进行转发，通过改变负载均衡的策略，可以改变后端服务器所承受的压力。在新版本发布之前，可以先对少部分机器进行灰度发布，以验证程序的正确性和稳定性，并且通过修改负载均衡策略，可以改变机器所承受的负载，达到对在线机器进行性能基准测试的目的。 5、TCPCopyTCPCopy是网易开源的，它是一款请求复制工具，能够将在线请求复制到测试机器，模拟真实环境，达到程序在不上线的情况下承担线上真是流量的效果。TCPCopy分为client与server，client运行在真实环境的线上服务器之上，用来捕获在线请求数据包，而server运行在测试机上，用来截获响应包，并将响应包的头部信息传递给client，已完成TCP交互。 性能优化措施通过上述方法找到性能瓶颈点之后，就需要对找到的性能瓶颈点进行优化。可以从多个方面入手，如:前端的资源文件，后端的Java程序，数据传输，结果缓存，数据库，JVM的GC，服务器硬件等。1、前端性能优化指标：页面造成的HTTP请求数量，是否使用CDN网络，是否使用压缩。2、Java程序优化单例模式，Future模式，线程池，服务端网络IO模型，减少线程上下文切换，降低锁竞争(使用原子变量，减小锁范围，将独占锁改为读写锁等)，压缩，结果缓存，数据库查询性能优化(合理使用索引，explain分析SQL，反范式设计如冗余存储以减少表关联带来的随机io和全表扫描，MySQL使用查询缓存：查看是否开启缓存:select @@query_cache_type;查看缓存总大小：select @@query_cache_size;查看记录集缓存限制:select @@query_cache_limit; 使用搜索引擎：在分库分表后，无法进行复杂的条件查询，这个时候就需要搜索引擎了。 使用key-value数据库:对于保有海量数据的互联网企业来说，多表的关联查询是非常忌讳的。SQL的功能被很大程度地弱化了。为了达到更大的并发，可以采用NoSQL数据库。 GC优化: JVM在进行垃圾回收时，会导致所有的工作线程暂停(stop the world),GC已成为影响Java应用性能的一个重要因素。查看GC日志中的MinorGC、Full GC的频率，GC导致的停顿时间及GC发生的原因等。需要注意一点的是:如果GC在PermGen上操作，而通常永久代存放的是已被虚拟机加载的类信息，及常量、静态变量、即使编辑器编译后的代码等数据，启动后一般非常稳定，GC回收的内存也十分有限。如果是因为PermGen空间不够而频繁发生FullGC，可能的情况是1，PermGen确实设置得过小，调整-XX:PermSize和-XX:MaxPermSize，2:可能是由于错误的代码导致频繁类加载，需要使用jmap将堆dump下来进行分析。 硬件提升性能:缓存服务器加大内存，磁盘IO密集的选用SSD，CPU密集的增加CPU核数，负载均衡节点注意网卡和带宽。 Java应用故障排查常用工具在进行故障定位时，知识和经验是发现问题的基础，数据是依据，而工具则是运用知识的手段。知识和经验告诉我们怎么去做，而运用工具能帮助我们更加快速地发现和定位问题。1、jps 输出java进程id，并显示其主类。选项： -q 只输出进程id -m 输出传递给main函数的参数 -l 输出主类全名，如果是jar，则输出jar文件路径 -v 输出虚拟机进程启动时所带的JVM参数 2、jstat可参考http://blog.csdn.net/zhaozheng7758/article/details/8623549用来对虚拟机各种运行状态进行监控，如查看类加载与卸载情况，管理内存使用和垃圾收集等信息，监视JIT的运行情况等。几乎包括了JVM运行的方方面面。在无法使用图形化工具如jconsole,VisualVM时，jstat成为了运行期定位问题的首选。jstat -options 可列出所有选项常见的有 -class (查看类加载器的统计信息) -compiler (JIT信息) -gc (查看JVM中垃圾收集情况的统计信息，包括Eden区，2个survivor区，老年代，永久代的容量和已用空间，GC时间等) -gccapacity (各区大小) -gccause (最近一次GC统计和原因) -gcnew (新区统计) -gcnewcapacity (新区大小) -gcold (老区统计) -gcoldcapacity (老区大小) -gcpermcapacity (永久区大小) -gcutil (GC统计汇总) -printcompilation (HotSpot编译统计) 1234567891011jstat -gcutil &lt;pid&gt;:统计gc信息显示列名具体描述S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比E 年轻代中Eden（伊甸园）已使用的占当前容量百分比O old代已使用的占当前容量百分比P perm代已使用的占当前容量百分比YGC 从应用程序启动到采样时年轻代中gc次数YGCT 从应用程序启动到采样时年轻代中gc所用时间(s)FGC 从应用程序启动到采样时old代(全gc)gc次数FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT 从应用程序启动到采样时gc用的总时间(s) 3、jinfo 查看应用程度的配置参数，及打印运行JVM时所制定的JVM参数。比jsp -v能查看未被显式指定的JVM参数的系统默认值。-sysprops选项将虚拟机进程中所指定的System.getProperties()的内容打印出来-flags：查看vm参数 ,如果不指定，则同时包含-sysprops和flags的输出。jinfo还能够在运行期间修改JVM参数，通过使用-flag name=value或者-flag [+|-]name来修改。 4、jstack用来生成虚拟机当前的线程快照信息，线程快照就是当前虚拟机每一个线程正在执行的方法堆栈的集合。主要是为了定位线程长时间没有响应的原因，如线程死锁、网络请求没有设置超时时间而长时间没有返回、死循环、信号量没有释放等，都有可能导致线程长时间停顿。 -F当jstack [-l] pid’没有相应的时候强制打印栈信息 -l长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表. -m打印java和native c/c++框架的所有栈信息. pid 需要被打印配置信息的java进程id,可以用jps查询. 5、jmap可以输出所有内存中对象的工具。可以用来查看等待回收对象的队列，查看堆的概要信息(包括采用的是哪种GC收集器，堆使用情况，及通过JVM参数指定的各个内存空间的大小等)，甚至可以将VM 中的heap以二进制dump输出成文本，之后便可以通过图形化工具如MAT进行堆分析，内存中有哪些对象，分别占用的空间，以便找到诸如内存泄漏等问题的祸根。需要注意的是，jmap执行堆dump操作时，由于生成的转储文件较大，将耗费大量的系统资源。因此，应避免在系统高位运行时执行该指令，否则有可能造成短时间内系统无法响应的情况。 -heap 打印heap的概要信息，包括使用的回收器类型、堆的配置信息、各内存分代的空间使用情况 -dump:[live,]format=b,file= 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件. -finalizerinfo 打印正等候回收的对象的信息. -histo[:live] 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live子参数加上后,只统计活的对象数量. -permstat 打印classload和jvm heap永久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来. -F 当JVM对-dump操作没有响应时，强制生成转储快照。 -J 传递参数给jmap启动的jvm. 6、BTrace可参考：http://mgoann.iteye.com/blog/1409667 http://www.jianshu.com/p/93e94b724476BTrace是一个开源的Java程序动态跟踪工具，前面已介绍过如何使用它来监控方法的执行时间。它的基本工作原理是通过Hotsopt虚拟机的HotSwap技术将跟踪的代码动态替换到被跟踪的Java程序内，以观察程序运行的细节(BTrace 主要使用了 Instrumentation + ASM技术来实现对正在运行进程的探测。)。如打印方法的参数，变量的值及返回值等。通过使用BTrace，可以在不修改代码、不重启应用的情况下，动态地查看程序运行的细节，方便地对程序进行调试。 123456789101112131415161718192021222324原方法：priavte int sub(int a,int b)&#123; return a+b;&#125;import com.sun.btrace.annotations.*;import static com.sun.btrace.BTraceUtils.*;btrace脚本：@BTracepublic class MethodTimeCost&#123; @TLS private static long starttime; @OnMethod(clazz=\"net.xby1993.test.Main\", method=\"sub\",location=@Location(Kind.ENTRY)) public static void startExecute()&#123; starttime=timeMillis(); &#125; @OnMethod(clazz=\"net.xby1993.test.Main\", method=\"sub\",location=@Location(Kind.RETURN)) public static void endExecute(@Return int rtn,int a,int b)&#123; long timecost=timeMillis()-starttime; println(strcat(\"a:\",str(a))); println(strcat(\"b:\",str(b))); println(strcat(\"return:\",str(rtn))); println(strcat(\"costtime:\",str(timecost))); &#125;&#125; 12btrace &lt; pid &gt; &lt; btrace-script &gt;btrace 3050 MethodTimeCost.java 值得注意的是，@TLS声明的变量是 ThreadLocal的， 每个线程都会有一份这个自己的startTime 变量。 btrace还提供了一个vaisualvm上的一个插件，可以执行btrace脚本。尝试了下，可以attach到本机的jvm进程上，但是远程主机的JVM进程不行。有的说通过端口转发绑定的方式可以，但是还是没有试出来。运行jvisualvm.exe, 选择工具-&gt;插件-&gt;可用插件 选择 BTrace Workbench进行在线安装。 选择需要监控的进程,右击 trace application,在btrace的工作台中直接编写脚本并执行,执行后，当被监控的程序运行了这些检查点的方法时，btrace会在控制台对执行时间进行输出。 注解说明： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@BTrace声明这个类是个BTrace脚本.unsafe参数表示是否不安全的模式执行.方法annotation@OnMethod: 声明 探查点（probe point）clazz: 全路径类名，支持正则表达式，格式为/正则表达式/+类名 匹配子类@前缀 匹配anotation声明的类method: 方法名，支持正则表达式，格式为/正则表达式/， anotation使用@location: 用@Location来表明在什么时候时候去执行脚本Kind.ENTRY 进入方法时Kind.RETURN 方法返回时Kind.THROW 抛出异常时Kind.ARRAY_SET 设置数组元素时Kind.ARRAY_GET 获取数组元素时Kind.NEWARRAY 创建新数组时Kind.NEW 创建新对象时Kind.CALL 调用方法时Kind.CATCH 捕获异常时Kind.FIELD_SET 获取对象属性时Kind.FIELD_SET 设置对象属性时Kind.ERROR 方法由于发生未被捕获的异常结束时Kind.SYNC_ENTRY 进入同步块时Kind.SYNC_EXIT 离开同步块时type 方法类型， 不含方法名、参数民、异常声明。@OnTimer 定时器，间隔出发动作。参数： 间隔时间，单位毫秒@OnError BTrace代码发生异常时回调@OnExit BTrace代码调用exit来结束探测时回调该注释的方法@OnEvent 接受客户端事件时会回调。目前，当客户端命令上执行Ctrl-C (SIGINT)时会发送一个时间到服务器端，从而触发@OnEvent注释的方法。@OnLowMemory 内存低于设置的阈值时回调方法pool 内存池名称threshold 阈值大小@OnProbe 支持使用xml格式来声明探测点点和探测动作。未声明注解的方法参数未声明注解的方法参数的映射，根据探测点类型locaiton的不同而不同：Kind.ENTRY 方法参数Kind.RETURN 方法返回值Kind.THROW 被抛出的异常Kind.ARRAY_SET 数值下标Kind.ARRAY_GET 数组下标Kind.CATCH 被捕获的异常Kind.FIELD_SET 被设置属性的值Kind.NEW 创建的对象的类型Kind.ERROR 被抛出的异常字段注解Export 将字段保罗给jstat访问Property 将字段暴露注册为MBean 属性，可以通过JMX进行查看TLS 将字段声明为TheadLocal字段，每个线程拥有自己独立的字段参数annotation介绍@Self 声明探测的当前对象this@Return 方法返回对象@ProbeClassName 当前探测点所在的类名@ProbeMethodName 当前探测点所在的方法名fqn 是否获取全路径方法名称fully qualified name (FQN)@Duration 执行时间，单位纳秒，一般同 Kind.RETURN 和 Kind.ERROR 配合使用@TargetInstance 配合 Kind.CALL使用，声明了被调用方法所在的对象@TargetMethodOrField Kind.CALL使用，声明了被调用方法所在的对象的方法 7、JConsole可参考 http://jiajun.iteye.com/blog/810150不过目前推荐使用JVisualVM来替代JConsole 8、JVisualVM可参考：https://www.ibm.com/developerworks/cn/java/j-lo-visualvm/ http://blog.csdn.net/a19881029/article/details/8432368连接：1、本地机器的程序直接可以监听到2、远程机器的程序需要加上JVM参数1234-Dcom.sun.management.jmxremote= true-Dcom.sun.management.jmxremote.port= 9090-Dcom.sun.management.jmxremote.ssl= false-Dcom.sun.management.jmxremote.authenticate= false VisualVM是一款”All-in-One”工具，涵盖了JVM内存监视，性能分析，线程，及堆转储分析、垃圾回收监视等几乎所有功能。常用功能:内存监控，GC监控，应用程序分析，线程分析，堆dump分析，CPU及内存抽样、BTrace跟踪等。 Java VisualVM 插件地址：打开Java VisualVM检查更新插件时，默认的连接连不上，通过浏览器访问之后发现默认的服务器已经404，新地址已经迁移到github，下面这个地址里面有不同版本jdk对应的插件中心地址：https://visualvm.github.io/pluginscenters.html 9、MAT(Memory Analyzer Tool)可参考：http://flychao88.iteye.com/blog/2192266 https://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-ma/一个基于Eclipse的内存分析工具，是一个快速、功能丰富的JAVA heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗。使用内存分析工具从众多的对象中进行分析，快速的计算出在内存中对象的占用大小，看看是谁阻止了垃圾收集器的回收工作，并可以通过报表直观的查看到可能造成这种结果的对象。巧妇难为无米之炊，我们首先需要获得一个堆转储文件。只要你设置了如下所示的 JVM 参数：-XX:+HeapDumpOnOutOfMemoryError JVM 就会在发生内存泄露时抓拍下当时的内存状态，也就是我们想要的堆转储文件。除此之外，还有很多的工具，例如 JMap，JConsole 都可以帮助我们得到一个堆转储文件。 典型案例分析1、内存溢出OutOfMemory测试:1234567891011public class TestOOM&#123; static class Obj&#123; public byte[] bytes=\"hello world\".getBytes(); &#125; public static void main(String[] args)&#123; ArrayList&lt;Obj&gt; list=new ArrayList&lt;&gt;(); while(true)&#123; list.add(new Obj()); &#125; &#125;&#125; 为了尽快出现问题，这里限制堆内存的大小，并在发生OOM时，dump堆。使用的JVM参数如下:-Xms10m -Xmx10m -Xmn5m -XX:+HeapDumpOnOutOfMemoryError 2、线程死锁或信号量没有释放当线程因为资源争用而发生死锁，或者因为使用了信号量而没有及时释放，在测试环境下很难发现该问题，特别是没有进行压力测试就上线的情况下，即便是上线，应用访问量不高，短时间内可能故障也不会发作。这些会导致线程资源耗光(如果采用线程池，此时并不会出现OOM异常，而是表现为请求长时间没有响应，应用僵死)。但是对应的JVM进程却是活跃的，并且此时的系统资源消耗，如CPU的load往往非常低。 这时需要线程dump进行分析。 3、类加载冲突有时候，当使用相同代码的应用发布上线以后，在分布式环境下，会发现一部分机器运行正常，而另一部分机器则会抛出NoClassDefFoundError、NoSuchMethodError这样的异常，这是为何？在一个大型的企业级应用中，可能会依赖很多jar包，而这些jar可能又会依赖其他的jar，最终会导致依赖关系变得错综复杂。有时候，可能会出现依赖一个jar的多个版本，更有甚者，某些jar会直接将依赖的jar也打包进去，这样就使得很多class签名相同的类同时存在。在不同的机器上，对不同jar中同名类的加载有时候并不完全一致。所以才会导致这些问题。那为什么测试时没有问题，因为由于在相同机器上，无论启动多少次，类得加载顺序基本不变。通过在JVM启动时加上-verbose:class,可以查到具体的class究竟是从哪个jar文件中加载进来的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"[读书笔记]chapter3-互联网安全架构-大型网站分布式架构与设计实践","slug":"读书笔记-chapter3-互联网安全架构-大型网站分布式架构与设计实践","date":"2017-12-17T05:03:05.000Z","updated":"2017-12-17T06:38:27.034Z","comments":true,"path":"2017/12/17/读书笔记-chapter3-互联网安全架构-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter3-互联网安全架构-大型网站分布式架构与设计实践/","excerpt":"内容：常见的Web攻击手段和防御方法:如XSS,CSRF,SQL注入等安全算法:如数字摘要，对称加密，非对称加密，数字签名，数字证书等如何采用摘要认证防止信息篡改，通过数字签名来验证通信双方的合法性，及通过Https保证通信过程中数据不被第三方监听和截获。OAuth协议介绍","text":"内容：常见的Web攻击手段和防御方法:如XSS,CSRF,SQL注入等安全算法:如数字摘要，对称加密，非对称加密，数字签名，数字证书等如何采用摘要认证防止信息篡改，通过数字签名来验证通信双方的合法性，及通过Https保证通信过程中数据不被第三方监听和截获。OAuth协议介绍 XSS攻击XSS(Cross-Site Scripting),跨站脚本攻击。防范:Html实体字符转义escapeXml CSRF攻击CSRF(cross site request forgery):跨站请求伪造。举例：CSRF攻击的主要目的是让用户在不知情的情况下攻击自己已登录的一个系统，类似于钓鱼。如用户当前已经登录了邮箱，或bbs，同时用户又在使用另外一个，已经被你控制的站点，我们姑且叫它钓鱼网站。这个网站上面可能因为某个图片吸引你，你去点击一下，此时可能就会触发一个js的点击事件，构造一个bbs发帖的请求，去往你的bbs发帖，由于当前你的浏览器状态已经是登陆状态，所以session登陆cookie信息都会跟正常的请求一样，纯天然的利用当前的登陆状态，让用户在不知情的情况下，帮你发帖或干其他事情。 CSRF防御： 将cookie设置为HttpOnly,这样通过脚本就无法读取到cookie信息。 通过 referer、token 或者 验证码 来检测用户提交。而该token不存在于cookie，而是随着每次响应返回到页面中的，服务端token存在于session中。 尽量不要在页面的链接中暴露用户隐私信息。 对于用户修改删除等操作最好都使用post 操作 。 避免全站通用的cookie，严格设置cookie的域。 SQL注入攻击防范:使用预编译语句；避免密码明文存放；处理好相应异常。 文件上传漏洞防范：对上传的文件进行白名单校验，限制上传文件大小，上传后的文件进行重命名。使用文件的魔数(magic number)来判断文件类型，而不是通过后缀名；对图片文件，可考虑使用imagemagick先缩放再保存。 DDoS攻击DDoS(Distributed Denial of Service)即分布式拒绝服务攻击。http://netsecurity.51cto.com/art/200903/114969.htm先说Dos，DoS攻击是最早出现的,它的攻击方法说白了就是单挑,是比谁的机器性能好、速度快。但是现在的科技飞速发展,一般的网站主机都有十几台主机,而且各个主机的处理能力、内存大小和网络速度都有飞速的发展,有的网络带宽甚至超过了千兆级别。这样我们的一对一单挑式攻击就没有什么作用了,搞不好自己的机子就会死掉。不过,科技在发展,黑客的技术也在发展。DDoS攻击。它的原理说白了就是群殴,用好多的机器对目标机器一起发动DoS攻击,但这不是很多黑客一起参与的,这种攻击只是由一名黑客来操作的。这名黑客不是拥有很多机器,他是通过他的机器在网络上占领很多的“肉鸡”,并且控制这些“肉鸡”来发动DDoS攻击。 DDoS攻击方式： 1、SYN Flood攻击SYN-Flood攻击是当前网络上最为常见的DDoS攻击，也是最为经典的拒绝服务攻击，它利用了TCP协议实现上的一个缺陷，通过向网络服务所在端口发送大量的伪造源地址的攻击报文，就可能造成目标服务器中的半开连接队列被占满，从而阻止其他合法用户进行访问。这种攻击早在1996年就被发现，但至今仍然显示出强大的生命力。很多操作系统，甚至防火墙、路由器都无法有效地防御这种攻击，而且由于它可以方便地伪造源地址，追查起来非常困难。它的数据包特征通常是，源发送了大量的SYN包，并且缺少三次握手的最后一步握手ACK回复。原理例如，攻击者首先伪造地址对服务器发起SYN请求（我可以建立连接吗？），服务器就会回应一个ACK+SYN（可以+请确认）。而真实的IP会认为，我没有发送请求，不作回应。服务器没有收到回应，会重试3-5次并且等待一个SYN Time（一般30秒-2分钟）后，丢弃这个连接。如果攻击者大量发送这种伪造源地址的SYN请求，服务器端将会消耗非常多的资源来处理这种半连接，保存遍历会消耗非常多的CPU时间和内存，何况还要不断对这个列表中的IP进行SYN+ACK的重试。最后的结果是服务器无暇理睬正常的连接请求—拒绝服务。在服务器上用netstat –an命令查看SYN_RECV状态的话 2、ACK Flood攻击ACK Flood攻击是在TCP连接建立之后，所有的数据传输TCP报文都是带有ACK标志位的，主机在接收到一个带有ACK标志位的数据包的时候，需要检查该数据包所表示的连接四元组是否存在，如果存在则检查该数据包所表示的状态是否合法，然后再向应用层传递该数据包。如果在检查中发现该数据包不合法，例如该数据包所指向的目的端口在本机并未开放，则主机操作系统协议栈会回应RST包告诉对方此端口不存在。这里，服务器要做两个动作：查表、回应ACK/RST。这种攻击方式显然没有SYN Flood给服务器带来的冲击大，因此攻击者一定要用大流量ACK小包冲击才会对服务器造成影响。按照我们对TCP协议的理解，随机源IP的ACK小包应该会被Server很快丢弃，因为在服务器的TCP堆栈中没有这些ACK包的状态信息。但是实际上通过测试，发现有一些TCP服务会对ACK Flood比较敏感，比如说JSP Server，在数量并不多的ACK小包的打击下，JSP Server就很难处理正常的连接请求。对于Apache或者IIS来说，10kpps的ACK Flood不构成危胁，但是更高数量的ACK Flood会造成服务器网卡中断频率过高，负载过重而停止响应。可以肯定的是，ACK Flood不但可以危害路由器等网络设备，而且对服务器上的应用有不小的影响。 3、UDP DNS Query Flood攻击原理UDP DNS Query Flood攻击实质上是UDP Flood的一种，但是由于DNS服务器的不可替代的关键作用，一旦服务器瘫痪，影响一般都很大。UDP DNS Query Flood攻击采用的方法是向被攻击的服务器发送大量的域名解析请求，通常请求解析的域名是随机生成或者是网络世界上根本不存在的域名，被攻击的DNS 服务器在接收到域名解析请求的时候首先会在服务器上查找是否有对应的缓存，如果查找不到并且该域名无法直接由服务器解析的时候，DNS 服务器会向其上层DNS服务器递归查询域名信息。域名解析的过程给服务器带来了很大的负载，每秒钟域名解析请求超过一定的数量就会造成DNS服务器解析域名超时。根据微软的统计数据，一台DNS服务器所能承受的动态域名查询的上限是每秒钟9000个请求。而我们知道，在一台P3的PC机上可以轻易地构造出每秒钟几万个域名解析请求，足以使一台硬件配置极高的DNS服务器瘫痪，由此可见DNS 服务器的脆弱性。同时需要注意的是，蠕虫扩散也会带来大量的域名解析请求。 4、CC(Challenge Collapsar)攻击 安全算法12345678public static String toHexString(byte[] b) &#123; StringBuilder sb = new StringBuilder(b.length * 2); for (int i = 0; i &lt; b.length; i++) &#123; sb.append(hexChar[(b[i] &amp; 0xf0) &gt;&gt;&gt; 4]); sb.append(hexChar[b[i] &amp; 0x0f]); &#125; return sb.toString(); &#125; 数字摘要http://www.jb51.net/article/96121.htmhash碰撞:如果待摘要的关键字为k1,Hash函数为f(x),则关键字k1的摘要为f(k1),若关键字k2不等于k1, 而f(k1)=f(k2),这种现象称为hash碰撞。一个hash函数的好坏是由发生碰撞的几率决定的。MD5(Message Digest Algorithm 5)SHA-1(Secure Hash Algorithm) 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.security.MessageDigest; /** * 采用MD5加密 */public class MD5Util &#123; /*** * MD5加密 生成32位md5码 * @param 待加密字符串 * @return 返回32位md5码 */ public static String md5Encode(String inStr) throws Exception &#123; MessageDigest md5 = null; try &#123; md5 = MessageDigest.getInstance(\"MD5\"); &#125; catch (Exception e) &#123; System.out.println(e.toString()); e.printStackTrace(); return \"\"; &#125; byte[] byteArray = inStr.getBytes(\"UTF-8\"); byte[] md5Bytes = md5.digest(byteArray); StringBuffer hexValue = new StringBuffer(); for (int i = 0; i &lt; md5Bytes.length; i++) &#123; int val = ((int) md5Bytes[i]) &amp; 0xff; if (val &lt; 16) &#123; hexValue.append(\"0\"); &#125; hexValue.append(Integer.toHexString(val)); &#125; return hexValue.toString(); &#125; /** * 测试主函数 */ public static void main(String args[]) throws Exception &#123; String str = new String(\"amigoxiexiexingxing\"); System.out.println(\"原始：\" + str); System.out.println(\"MD5后：\" + md5Encode(str)); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 采用SHAA加密 */public class SHAUtil &#123; /*** * SHA加密 生成40位SHA码 * @param 待加密字符串 * @return 返回40位SHA码 */ public static String shaEncode(String inStr) throws Exception &#123; MessageDigest sha = null; try &#123; sha = MessageDigest.getInstance(\"SHA\"); &#125; catch (Exception e) &#123; System.out.println(e.toString()); e.printStackTrace(); return \"\"; &#125; byte[] byteArray = inStr.getBytes(\"UTF-8\"); byte[] md5Bytes = sha.digest(byteArray); StringBuffer hexValue = new StringBuffer(); for (int i = 0; i &lt; md5Bytes.length; i++) &#123; int val = ((int) md5Bytes[i]) &amp; 0xff; if (val &lt; 16) &#123; hexValue.append(\"0\"); &#125; hexValue.append(Integer.toHexString(val)); &#125; return hexValue.toString(); &#125; /** * 测试主函数 */ public static void main(String args[]) throws Exception &#123; String str = new String(\"amigoxiexiexingxing\"); System.out.println(\"原始：\" + str); System.out.println(\"SHA后：\" + shaEncode(str)); &#125;&#125; SHA-1和MD5的比较因为二者均由MD4导出，SHA-1和MD5彼此很相似。相应的，他们的强度和其他特性也是相似，但还有以下几点不同：1）对强行攻击的安全性：最显著和最重要的区别是SHA-1摘要比MD5摘要长32 位。使用强行技术，产生任何一个报文使其摘要等于给定报摘要的难度对MD5是2^128数量级的操作，而对SHA-1则是2^160数量级的操作。这样，SHA-1对强行攻击有更大的强度。2）对密码分析的安全性：由于MD5的设计，易受密码分析的攻击，SHA-1显得不易受这样的攻击。3）速度：在相同的硬件上，SHA-1的运行速度比MD5慢。 彩虹表破解Hash算法：彩虹表预先建立一个可逆向的散列链并将其存储在表中，在破解时先查表得到可能包含结果的散列链，然后在内存中重新计算并得到最终结果。折中方式综合了计算暴力破解和查找表破解的优点，并将计算时间和存储空间降低到可以接受的范围。 对称加密算法http://www.iteye.com/topic/1122076/常用的有:DES,AES等。目前AES是主流。加密：大体上分为双向加密和单向加密，而双向加密又分为对称加密和非对称加密。对称加密 采用单钥密码系统的加密方法，同一个密钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单密钥加密。需要对加密和解密使用相同密钥的加密算法。由于其速度，对称性加密通常在消息发送方需要加密大量数据时使用。对称性加密也称为密钥加密。所谓对称，就是采用这种加密方法的双方使用方式用同样的密钥进行加密和解密。密钥是控制加密及解密过程的指令。 对称加密一般java类中中定义成员 ：1234567891011121314151617//KeyGenerator 提供对称密钥生成器的功能，支持各种算法 private KeyGenerator keygen; //SecretKey 负责保存对称密钥 private SecretKey deskey; //Cipher负责完成加密或解密工作 private Cipher c; //该字节数组负责保存加密的结果 private byte[] cipherByte; //Security.addProvider(new com.sun.crypto.provider.SunJCE()); //实例化支持DES算法的密钥生成器(算法名称命名需按规定，否则抛出异常) keygen = KeyGenerator.getInstance(\"DES\");// //生成密钥 deskey = keygen.generateKey(); //生成Cipher对象,指定其支持的DES算法 c = Cipher.getInstance(\"DES\"); 1、DES算法为密码体制中的对称密码体制，又被成为美国数据加密标准，是1972年美国IBM公司研制的对称密码体制加密算法。 明文按64位进行分组, 密钥长64位，密钥事实上是56位参与DES运算（第8、16、24、32、40、48、56、64位是校验位， 使得每个密钥都有奇数个1）分组后的明文组和56位的密钥按位替代或交换的方法形成密文组的加密方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class EncrypDES &#123; //KeyGenerator 提供对称密钥生成器的功能，支持各种算法 private KeyGenerator keygen; //SecretKey 负责保存对称密钥 private SecretKey deskey; //Cipher负责完成加密或解密工作 private Cipher c; //该字节数组负责保存加密的结果 private byte[] cipherByte; public EncrypDES() throws NoSuchAlgorithmException, NoSuchPaddingException&#123; Security.addProvider(new com.sun.crypto.provider.SunJCE()); //实例化支持DES算法的密钥生成器(算法名称命名需按规定，否则抛出异常) keygen = KeyGenerator.getInstance(\"DES\"); //生成密钥 deskey = keygen.generateKey(); //生成Cipher对象,指定其支持的DES算法 c = Cipher.getInstance(\"DES\"); &#125; /** * 对字符串加密 */ public byte[] Encrytor(String str) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，ENCRYPT_MODE表示加密模式 c.init(Cipher.ENCRYPT_MODE, deskey); byte[] src = str.getBytes(); // 加密，结果保存进cipherByte cipherByte = c.doFinal(src); return cipherByte; &#125; /** * 对字符串解密 */ public byte[] Decryptor(byte[] buff) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，DECRYPT_MODE表示加密模式 c.init(Cipher.DECRYPT_MODE, deskey); cipherByte = c.doFinal(buff); return cipherByte; &#125; public static void main(String[] args) throws Exception &#123; EncrypDES de1 = new EncrypDES(); String msg =\"郭XX-搞笑相声全集\"; byte[] encontent = de1.Encrytor(msg); byte[] decontent = de1.Decryptor(encontent); System.out.println(\"明文是:\" + msg); System.out.println(\"加密后:\" + new String(encontent)); System.out.println(\"解密后:\" + new String(decontent)); &#125; &#125; 2、AES密码学中的高级加密标准（Advanced Encryption Standard，AES）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 public class EncrypAES &#123; //KeyGenerator 提供对称密钥生成器的功能，支持各种算法 private KeyGenerator keygen; //SecretKey 负责保存对称密钥 private SecretKey deskey; //Cipher负责完成加密或解密工作 private Cipher c; //该字节数组负责保存加密的结果 private byte[] cipherByte; public EncrypAES() throws NoSuchAlgorithmException, NoSuchPaddingException&#123; Security.addProvider(new com.sun.crypto.provider.SunJCE()); //实例化支持DES算法的密钥生成器(算法名称命名需按规定，否则抛出异常) keygen = KeyGenerator.getInstance(\"AES\"); //生成密钥 deskey = keygen.generateKey(); //生成Cipher对象,指定其支持的DES算法 c = Cipher.getInstance(\"AES\"); &#125; /** * 对字符串加密 */ public byte[] Encrytor(String str) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，ENCRYPT_MODE表示加密模式 c.init(Cipher.ENCRYPT_MODE, deskey); byte[] src = str.getBytes(); // 加密，结果保存进cipherByte cipherByte = c.doFinal(src); return cipherByte; &#125; /** * 对字符串解密 */ public byte[] Decryptor(byte[] buff) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，DECRYPT_MODE表示加密模式 c.init(Cipher.DECRYPT_MODE, deskey); cipherByte = c.doFinal(buff); return cipherByte; &#125; public static void main(String[] args) throws Exception &#123; EncrypAES de1 = new EncrypAES(); String msg =\"郭XX-搞笑相声全集\"; byte[] encontent = de1.Encrytor(msg); byte[] decontent = de1.Decryptor(encontent); System.out.println(\"明文是:\" + msg); System.out.println(\"加密后:\" + new String(encontent)); System.out.println(\"解密后:\" + new String(decontent)); &#125; &#125; 因为某些国家的进口管制限制，Java发布的运行环境包中的默认仅允许128位密钥的AES加解密 非对称加密与对称加密算法不同，非对称加密算法需要两个密钥：公开密钥（publick ey）和私有密钥 (private key)公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。RSA算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class EncrypRSA &#123; /** * 加密 */ protected byte[] encrypt(RSAPublicKey publicKey,byte[] srcBytes) throws NoSuchAlgorithmException, NoSuchPaddingException, InvalidKeyException, IllegalBlockSizeException, BadPaddingException&#123; if(publicKey!=null)&#123; //Cipher负责完成加密或解密工作，基于RSA Cipher cipher = Cipher.getInstance(\"RSA\"); //根据公钥，对Cipher对象进行初始化 cipher.init(Cipher.ENCRYPT_MODE, publicKey); byte[] resultBytes = cipher.doFinal(srcBytes); return resultBytes; &#125; return null; &#125; /** * 解密 */ protected byte[] decrypt(RSAPrivateKey privateKey,byte[] srcBytes) throws NoSuchAlgorithmException, NoSuchPaddingException, InvalidKeyException, IllegalBlockSizeException, BadPaddingException&#123; if(privateKey!=null)&#123; //Cipher负责完成加密或解密工作，基于RSA Cipher cipher = Cipher.getInstance(\"RSA\"); //根据公钥，对Cipher对象进行初始化 cipher.init(Cipher.DECRYPT_MODE, privateKey); byte[] resultBytes = cipher.doFinal(srcBytes); return resultBytes; &#125; return null; &#125; public static void main(String[] args) throws NoSuchAlgorithmException, InvalidKeyException, NoSuchPaddingException, IllegalBlockSizeException, BadPaddingException &#123; EncrypRSA rsa = new EncrypRSA(); String msg = \"郭XX-精品相声\"; //KeyPairGenerator类用于生成公钥和私钥对，基于RSA算法生成对象 KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(\"RSA\"); //初始化密钥对生成器，密钥大小为1024位 keyPairGen.initialize(1024); //生成一个密钥对，保存在keyPair中 KeyPair keyPair = keyPairGen.generateKeyPair(); //得到私钥 RSAPrivateKey privateKey = (RSAPrivateKey)keyPair.getPrivate(); //得到公钥 RSAPublicKey publicKey = (RSAPublicKey)keyPair.getPublic(); //用公钥加密 byte[] srcBytes = msg.getBytes(); byte[] resultBytes = rsa.encrypt(publicKey, srcBytes); //用私钥解密 byte[] decBytes = rsa.decrypt(privateKey, resultBytes); System.out.println(\"明文是:\" + msg); System.out.println(\"加密后是:\" + new String(resultBytes)); System.out.println(\"解密后是:\" + new String(decBytes)); &#125; &#125; 数字签名https://www.cnblogs.com/SirSmith/p/4985571.htmlhttp://840327220.iteye.com/blog/2225109数字签名是一种安全措施，分为：消息摘要和消息签名。1、消息摘要：是一种算法，分为MD5/SHA算法，主要作用用来防止消息在传递途中被“第三者”篡改了。2、消息签名：其基础是公钥和私钥的非对称加密。主要作用是验证发消息者的身份，确保消息来源的可靠性。 1234567891011121314151617181920212223242526String password=\"test\"; // 1.初始化密钥 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(\"RSA\"); keyPairGenerator.initialize(512); KeyPair keyPair = keyPairGenerator.generateKeyPair(); RSAPublicKey rsaPublicKey = (RSAPublicKey)keyPair.getPublic(); RSAPrivateKey rsaPrivateKey = (RSAPrivateKey)keyPair.getPrivate(); // 2.进行签名 PKCS8EncodedKeySpec pkcs8EncodedKeySpec = new PKCS8EncodedKeySpec(rsaPrivateKey.getEncoded()); KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\"); PrivateKey privateKey = keyFactory.generatePrivate(pkcs8EncodedKeySpec); Signature signature = Signature.getInstance(\"MD5withRSA\"); signature.initSign(privateKey); signature.update(password.getBytes()); byte[] result = signature.sign(); //System.out.println(\"jdk rsa sign:\" + Hex.encodeHexString(result) ); // 3.验证签名 X509EncodedKeySpec x509EncodedKeySpec = new X509EncodedKeySpec(rsaPublicKey.getEncoded()); keyFactory = KeyFactory.getInstance(\"RSA\"); PublicKey publicKey = keyFactory.generatePublic(x509EncodedKeySpec); signature = Signature.getInstance(\"MD5withRSA\"); signature.initVerify(publicKey); signature.update(password.getBytes()); boolean bool = signature.verify(result); 数字证书https://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.htmlhttps://www.2cto.com/article/201203/122095.htmlhttp://yale.iteye.com/blog/1675344http://blog.csdn.net/abinge317/article/details/51791856由于网络上通信的双方可能都不认识对方，那么就需要第三者来介绍，这就是数字证书。数字证书由Certificate Authority( CA 认证中心)颁发。 用户A把自己的证书发送给用户B。用户B使用CA的公钥对证书的签名进行验证，由于只有CA才能生成该证书，因此只要证书验证正确，即说明证书是由CA发布的，证书中用户A的公钥是值得信赖的。用户B以后就可以使用该公钥验证用户A的签名或者进行和A进行加密通信。 数字证书为发布公钥提供了一种简便的途径，其数字证书则成为加密算法以及公钥的载体，依靠数字证书，我们可以构建一个简单的加密网络应用平台，数字证书就好比我们生活中的身份证，现实中，身份证由公安机关签发，而网络用户的身份凭证由数字证书颁发认证机构—CA签发，只有经过CA签发的证书在网络中才具备可认证性，CA并不是一个单纯的防御手段，它集合了多种密码学算法： 消息摘要算法：MD5、和SHA（对数字证书本省做摘要处理，用于验证数据完整性服务器） 对称加密算法：RC2、RC4、IDEA、DES、AES（对数据进行加密/解密操作，用于保证数据保密性服务） 非对称加密算法：RSA、DH（对数据进行加密/解密操作，用于保证数据保密性服务） 数字签名算法：RSA、DSA(对数据进行签名/验证操作，保证数据的完整性和抗否认性)。 证书的签发过程实际上是对申请数字证书的公钥做数字签名，证书的验证过程实际上是对数字证书的公钥做验证签名，其中还包含证书有效期验证，通过CA数字证书，我们对网络上传输的数据进行加密/解密和签名/验证操作，确保数据机密性、完整性、抗否认性、认证性，保证交易实体身份的真实性，保证网络安全性。 所有证书有多种文件编码格式，主要包括: CER编码(规范编码格式)：是数字证书的一种编码格式，它是BER(基本编码格式)的一个变种，比BER规定得更严格 DER(卓越编码格式)：同样是BER的一个变种，与CER的不同在于，DER使用定长模式，而CER使用变长模式。所有证书都符合公钥基础设施(PKI)制定的ITU-T X509国际标准，PKCS(公钥加密标准)由RSA实验室和其他安全系统开发商为促进公钥密码的发展而制定的一系列标准，比如:PKCS#7(密码消息语法标准—-文件后缀名:.p7b、.p7c、.spc)、PKCS#10(证书请求语法标准—-文件后缀名:.p10、.csr)、PKCS#12(个人信息交换语法标准—-文件后缀名:.p12、.pfx)等。在获得数字证书后，可以将其保存在电脑中，也可以保存在USB Key等相应的设备中。 一个数字证书的例子1234567891011121314151617181920212223242526272829303132333435363738394041424344Certificate: Data: &lt;span style=&quot;color:#FF0000;&quot;&gt;证书标准版本号&lt;/span&gt; Version: 1 (0x0) &lt;span style=&quot;color:#FF0000;&quot;&gt;该证书的唯一编号&lt;/span&gt; Serial Number: 7829 (0x1e95) &lt;span style=&quot;color:#FF0000;&quot;&gt;该证书的签名算法&lt;/span&gt; Signature Algorithm: md5WithRSAEncryption &lt;span style=&quot;color:#FF0000;&quot;&gt;颁布本证书的证书机构&lt;/span&gt; Issuer: C=ZA, ST=Western Cape, L=Cape Town, O=Thawte Consulting cc, OU=Certification Services Division, CN=Thawte Server CA/emailAddress=server-certs@thawte.com &lt;span style=&quot;color:#FF0000;&quot;&gt;证书有效期&lt;/span&gt; Validity Not Before: Jul 9 16:04:02 1998 GMT Not After : Jul 9 16:04:02 1999 GMT &lt;span style=&quot;color:#FF0000;&quot;&gt;证书持有人的姓名、地址等信息&lt;/span&gt; Subject: C=US, ST=Maryland, L=Pasadena, O=Brent Baccala, OU=FreeSoft, CN=www.freesoft.org/emailAddress=baccala@freesoft.org &lt;span style=&quot;color:#FF0000;&quot;&gt;证书持有人的公钥&lt;/span&gt; Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public Key: (1024 bit) Modulus (1024 bit): 00:b4:31:98:0a:c4:bc:62:c1:88:aa:dc:b0:c8:bb: 33:35:19:d5:0c:64:b9:3d:41:b2:96:fc:f3:31:e1: 66:36:d0:8e:56:12:44:ba:75:eb:e8:1c:9c:5b:66: 70:33:52:14:c9:ec:4f:91:51:70:39:de:53:85:17: 16:94:6e:ee:f4:d5:6f:d5:ca:b3:47:5e:1b:0c:7b: c5:cc:2b:6b:c1:90:c3:16:31:0d:bf:7a:c7:47:77: 8f:a0:21:c7:4c:d0:16:65:00:c1:0f:d7:b8:80:e3: d2:75:6b:c1:ea:9e:5c:5c:ea:7d:c1:a1:10:bc:b8: e8:35:1c:9e:27:52:7e:41:8f Exponent: 65537 (0x10001) &lt;span style=&quot;color:#FF0000;&quot;&gt;证书机构对该证书的数字签名&lt;/span&gt; Signature Algorithm: md5WithRSAEncryption 93:5f:8f:5f:c5:af:bf:0a:ab:a5:6d:fb:24:5f:b6:59:5d:9d: 92:2e:4a:1b:8b:ac:7d:99:17:5d:cd:19:f6:ad:ef:63:2f:92: ab:2f:4b:cf:0a:13:90:ee:2c:0e:43:03:be:f6:ea:8e:9c:67: d0:a2:40:03:f7:ef:6a:15:09:79:a9:46:ed:b7:16:1b:41:72: 0d:19:aa:ad:dd:9a:df:ab:97:50:65:f5:5e:85:a6:ef:19:d1: 5a:de:9d:ea:63:cd:cb:cc:6d:5d:01:85:b5:6d:c8:f3:d9:f7: 8f:0e:fc:ba:1f:34:e9:96:6e:6c:cf:f2:ef:9b:bf:de:b5:22: 68:9f 我们先来看一个简单的证书机构签发的流程:这里的认证机构如何是证书申请者本身，将获得自签名证书。当客户端获得服务器下发的数字证书后，即可使用数字证书进行加密交互：数字证书的应用环境是在https安全协议中，使用流程远比上述加密交互流程复杂，但是相关操作封装在传输层，对于应用层透明，在https安全协议中使用非对称加密算法交换密钥，使用对称加密算法对数据进行加密/解密操作，提高加密/解密效率要获得数字证书，我们需要使用数字证书管理工具：KeyTool和OpenSSL构建CSR(数字证书签发申请)，交由CA机构签发，形成最终的数字证书。 SSL/TLS协议分为两层： 记录协议:建议在可靠的传输协议之上，为高层协议提供数据封装、压缩、加密等基本功能的支持 握手协议:建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等经过了SSL/TLS握手协议交互后，数据交互双方确定了本次会话使用的对称加密算法以及密钥，就可以开始进行加密数据交互了，以下是握手协议服务器端和客户端构建加密交互的相关流程图：1、 随机数为后续构建密钥准备2、 其他信息包括服务器证书、甚至包含获取客户端证书的请求3、验证算法如果服务器端回复客户端时带有其他信息，则进入数字证书验证阶段客户端验证服务器端证书：服务器端验证客户端证书:(非金融行业等关键性行业，可选)4、产生密钥当服务器端和客户端经过上述流程后，就开始密钥构建交互了，服务器端和客户端最初需要主密钥为构建会话密钥做准备：5、 会话密钥 (用于对称加密)完成上述主密钥构建操作后，服务器端和客户端将建立会话密钥，完成握手协议：6、加密交互上述服务器端和客户端完成了握手协议以后就进入正式会话阶段，如果上述流程中有任何一端受到外界因素干扰发生异常，则重新进入协商算法阶段，下面流程表现进入会话阶段后，服务器端和客户端将使用会话密钥进行加密交互： 代码解释在JAVA 6 以上版本中提供了完善的数字证书管理的实现，我们不需要关注相关具体算法，仅通过操作密钥库和数字证书就可以完成相应的加密/解密和签名/验证操作，密钥库管理私钥，数字证书管理公钥，私钥和密钥分属消息传递两方，进行加密消息的传递。因此，我们可以将密钥库看做私钥相关操作的入口，数字证书则是公钥相关操作的入口：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234/**** * 获得私钥，获得私钥后，通过RSA算方法实现进行\"私钥加密，公钥解密\"和\"公钥加密，私钥解密\"操作 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 私钥 */ private static PrivateKey getPrivateKeyByKeyStore(String keyStorePath,String alias,String password)throws Exception&#123; //获得密钥库 KeyStore ks = getKeyStore(keyStorePath,password); //获得私钥 return (PrivateKey)ks.getKey(alias, password.toCharArray()); &#125; /**** * 由Certificate获得公钥，获得公钥后，通过RSA算方法实现进行\"私钥加密，公钥解密\"和\"公钥加密，私钥解密\"操作 * @param certificatePath 证书路径 * @return 公钥 */ private static PublicKey getPublicKeyByCertificate(String certificatePath)throws Exception &#123; //获得证书 Certificate certificate = getCertificate(certificatePath); //获得公钥 return certificate.getPublicKey(); &#125; /**** * 加载数字证书，JAVA 6仅支持x.509的数字证书 * @param certificatePath 证书路径 * @return 证书 * @throws Exception */ private static Certificate getCertificate(String certificatePath) throws Exception&#123; //实例化证书工厂 CertificateFactory certificateFactory = CertificateFactory.getInstance(\"x.509\"); //取得证书文件流 FileInputStream in = new FileInputStream(certificatePath); //生成证书 Certificate certificate = certificateFactory.generateCertificate(in); //关闭证书文件流 in.close(); return certificate; &#125; /**** * 获得Certificate * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 证书 * @throws Exception */ private static Certificate getCertificate(String keyStorePath,String alias,String password) throws Exception&#123; //由密钥库获得数字证书构建数字签名对象 //获得密钥库 KeyStore ks = getKeyStore(keyStorePath,password); //获得证书 return ks.getCertificate(alias); &#125; /**** * 加载密钥库，加载了以后，我们就能通过相应的方法获得私钥，也可以获得数字证书 * @param keyStorePath 密钥库路径 * @param password 密码 * @return 密钥库 * @throws Exception */ private static KeyStore getKeyStore(String keyStorePath,String password) throws Exception&#123; //实例化密钥库 KeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType()); //获得密钥库文件流 FileInputStream is = new FileInputStream(keyStorePath); //加载密钥库 ks.load(is,password.toCharArray()); //关闭密钥库文件流 is.close(); return ks; &#125; /**** * 私钥加密 * @param data 待加密的数据 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 加密数据 * @throws Exception */ public static byte[] encryptByPriateKey(byte[] data,String keyStorePath,String alias,String password) throws Exception&#123; //获得私钥 PrivateKey privateKey = getPrivateKeyByKeyStore(keyStorePath,alias,password); //对数据加密 Cipher cipher = Cipher.getInstance(privateKey.getAlgorithm()); return cipher.doFinal(data); &#125; /**** * 私钥解密 * @param data 待解密数据 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 解密数据 * @throws Exception */ public static byte[] decryptByPrivateKey(byte[] data,String keyStorePath,String alias,String password) throws Exception&#123; //取得私钥 PrivateKey privateKey = getPrivateKeyByKeyStore(keyStorePath,alias,password); //对数据解密 Cipher cipher = Cipher.getInstance(privateKey.getAlgorithm()); cipher.init(Cipher.DECRYPT_MODE,privateKey); return cipher.doFinal(data); &#125; /**** * 公钥加密 * @param data 等待加密数据 * @param certificatePath 证书路径 * @return 加密数据 * @throws Exception */ public static byte[] encryptByPublicKey(byte[] data,String certificatePath) throws Exception&#123; //取得公钥 PublicKey publicKey = getPublicKeyByCertificate(certificatePath); //对数据加密 Cipher cipher = Cipher.getInstance(publicKey.getAlgorithm()); cipher.init(Cipher.ENCRYPT_MODE,publicKey); return cipher.doFinal(data); &#125; /**** * 公钥解密 * @param data 等待解密的数据 * @param certificatePath 证书路径 * @return 解密数据 * @throws Exception */ public static byte[] decryptByPublicKey(byte[] data,String certificatePath)throws Exception&#123; //取得公钥 PublicKey publicKey = getPublicKeyByCertificate(certificatePath); //对数据解密 Cipher cipher = Cipher.getInstance(publicKey.getAlgorithm()); cipher.init(Cipher.DECRYPT_MODE, publicKey); return cipher.doFinal(data); &#125; /**** * @param sign 签名 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 签名 * @throws Exception */ public static byte[] sign(byte[] sign,String keyStorePath,String alias,String password)throws Exception&#123; //获得证书 X509Certificate x509Certificate = (X509Certificate) getCertificate(keyStorePath,alias,password); //构建签名,由证书指定签名算法 Signature signature = Signature.getInstance(x509Certificate.getSigAlgName()); //获取私钥 PrivateKey privateKey = getPrivateKeyByKeyStore(keyStorePath,alias,password); //初始化签名，由私钥构建 signature.initSign(privateKey); signature.update(sign); return signature.sign(); &#125; /**** * 验证签名 * @param data 数据 * @param sign 签名 * @param certificatePath 证书路径 * @return 验证通过为真 * @throws Exception */ public static boolean verify(byte[] data,byte[] sign,String certificatePath) throws Exception&#123; //获得证书 X509Certificate x509Certificate = (X509Certificate)getCertificate(certificatePath); //由证书构建签名 Signature signature = Signature.getInstance(x509Certificate.getSigAlgName()); //由证书初始化签名，实际上是使用了证书中的公钥 signature.initVerify(x509Certificate); signature.update(data); return signature.verify(sign); &#125; //我们假定密钥库文件yale.keystore存储在D盘根目录，数字证书文件yale.cer也存储在D盘根目录 /**** * 公钥加密---私钥解密 * @throws Exception */ public static void test1() throws Exception&#123; System.err.println(\"公钥加密---私钥解密\"); String inputStr = \"数字证书\"; byte[] data = inputStr.getBytes(); //公钥加密 byte[] encrypt = CertificateCoder.encryptByPublicKey(data, certificatePath); //私钥解密 byte[] decrypt = CertificateCoder.decryptByPrivateKey(encrypt, keyStorePath, alias, password); String outputStr = new String(decrypt); System.err.println(\"加密前：\\n\" + inputStr); System.err.println(\"解密后：\\n\" + outputStr); &#125; /**** * 私钥加密---公钥解密 * @throws Exception */ public static void test2()throws Exception&#123; System.err.println(\"私钥加密---公钥解密\"); String inputStr = \"数字签名\"; byte[] data = inputStr.getBytes(); //私钥加密 byte[] encodedData = CertificateCoder.encryptByPriateKey(data, keyStorePath, alias, password); //公钥加密 byte[] decodeData = CertificateCoder.decryptByPublicKey(encodedData, certificatePath); String outputStr = new String (decodeData); System.err.println(\"加密前：\\n\" + inputStr); System.err.println(\"解密后：\\n\" + outputStr); &#125; public static void testSign()throws Exception&#123; String inputStr = \"签名\"; byte[] data = inputStr.getBytes(); System.err.println(\"私钥签名---公钥验证\"); //产生签名 byte[] sign = CertificateCoder.sign(data, keyStorePath, alias, password); System.err.println(\"签名:\\n\" + Hex.encodeHexString(sign)); //验证签名 boolean status = CertificateCoder.verify(data, sign, certificatePath); System.err.println(\"状态：\\n \" + status); &#125; RSA非对称加密的2个用途及在HTTPS加密（防窃听） RSA非对称加密会用到一对密钥，分别称为公钥和私钥，公钥加密之后的数据可以通过私钥来进行解密，私钥加密的数据也同样可以用对应的公钥进行解密。在web数据传输过程中，由于客户端和服务器端是多对一的关系，因此可以让所有的客户端持有相同的公钥，服务器持有私钥，这样一来就能方便地实现数据的加密传输。 签名（防篡改） 由于私钥只在某一个体手中，因此可以通过这一点来进行身份识别。比如用户A和B分别有一对密钥中的私钥和公钥，现在A向B发送消息”abc”，可进行如下操作：A用私钥对该文本进行加密之后变成密文”#￥%”，并附加上原文，组合成文本”#￥%：abc”(冒号起分隔作用，并无其他含义，具体实现中可自行处理)一起发送，B接收到该文本之后利用公钥对密文进行解密，将得到的解密后文本与传送过来的文本”abc”之间进行比对，如果一切正常，那么公钥解密之后的文本就是私钥加密之前的文本”abc”，比对结果一致，因此可以说明这段”abc”文本确实是A发送过来的，因为只有A才有对文本进行签名的私钥。能得到这个结论的前提是——A所用的私钥跟B所用的公钥确实是一对。 假如在传送途中别人篡改了”abc”，改成”aaa”，由于中间人没有A所持有的私钥，因此无法对篡改之后的数据生成新的正确签名，那么B在收到数据之后用公钥进行解密，再与传送的文本进行比对的话就不会一致。或者中间人篡改了数据之后用另一私钥对篡改之后的数据进行签名，同样由于B没有中间人的私钥对应的公钥，因此比对也不会一致。记住一点：B的公钥所对应的私钥只在A的手中，因此比对一致就说明该文本来自A。 https如何保证安全？如何保证客户端所持有的公钥就是某合法服务器声明的公钥？ 如果不能保证这一点，那么客户端发送的信息就有可能存在被窃听的危险，因为用此公钥加密的数据可以被其对应的私钥拥有者获取，而该私钥并不在客户端所认为的服务器上。因此可采用一个权威机构进行证书的颁发，所谓证书就是包含了服务器声明的公钥以及组织名称等信息，这里我们只考虑最关键的公钥信息。该权威机构会对申请证书的组织进行审核，确保其身份合法，然后将服务器公钥信息发布给客户端，客户端可利用该公钥与对应的服务器进行通信。整个过程可归纳为以下几步：1、服务器生成一对密钥，私钥自己留着，公钥交给数字证书认证机构（CA）2、CA进行审核，并用CA自己的私钥对服务器提供的公钥进行签名（参照上文RSA签名）3、客户端从CA获取证书（即服务器端公钥），用CA的公钥对签名的证书进行验证，比对一致，说明该服务器公钥确实是CA颁发的（得此结论有一个前提就是：客户端的CA公钥确实是CA的公钥，即该CA的公钥与CA对证书进行签名的私钥确实是一对。参照上文RSA签名中所论述的情况），而CA又作为权威机构保证该公钥的确是服务器端提供的，从而可以确认该证书中的公钥确实是合法服务器端提供的 注：为保证第3步中提到的前提条件，CA的公钥必须要安全地转交给客户端，因此，CA的公钥一般来说由浏览器开发商内置在浏览器的内部。于是，该前提条件在各种信任机制上，基本保证成立。由此可见：所谓的安全的HTTP，其实也是要建立在信任的机制上。 总结：整个过程涉及2对公私密钥对，一对由服务器产生，用于加密，一对由CA产生，用于签名。整个过程还涉及2个信任：客户端信任CA，CA发布的证书中的公钥就是合法服务器的公钥。客户端信任浏览器内置的CA公钥就是与CA私钥对应的公钥。最后要说明的是，非对称加密在https中只是用来对对称加密密钥进行协商的过程才使用，在两端协商完对称加密的密钥之后，数据的加密传输均采用对称加密的方式。 HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL协议不仅仅是一套加密传输的协议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用了非对称加密，对称加密以及HASH算法。握手过程的具体描述如下：1234567891011121. 浏览器将自己支持的一套加密规则发送给网站。 2.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 3.浏览器获得网站证书之后浏览器要做以下工作： a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。 b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。 c) 使用约定好的HASH算法计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。 4.网站接收浏览器发来的数据之后要做以下的操作： a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。 b) 使用密码加密一段握手消息，发送给浏览器。 5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。 linux下生成https的crt和key证书http://blog.csdn.net/xuplus/article/details/51613883linux下openssl生成 签名的步骤：x509证书一般会用到三类文，key，csr，crt。Key 是私用密钥openssl格，通常是rsa算法。Csr 是证书请求文件，用于申请证书。在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥。crt是CA认证后的证书文，（windows下面的，其实是crt），签署人用自己的key给你签署的凭证。 1.key的生成openssl genrsa -des3 -out server.key 2048这样是生成rsa私钥，des3算法，openssl格式，2048位强度。server.key是密钥文件名。为了生成这样的密钥，需要一个至少四位的密码。可以通过以下方法生成没有密码的key:openssl rsa -in server.key -out server.key server.key就是没有密码的版本了。 生成CA的crtopenssl req -new -x509 -key server.key -out ca.crt -days 3650生成的ca.crt文件是用来签署下面的server.csr文件。 csr的生成方法openssl req -new -key server.key -out server.csr需要依次输入国家，地区，组织，email。最重要的是有一个common name，可以写你的名字或者域名。如果为了https申请，这个必须和域名吻合，否则会引发浏览器警报。生成的csr文件交给CA签名后形成服务端自己的证书。 crt生成方法CSR文件必须有CA的签名才可形成证书，可将此文件发送到verisign等地方由它验证，要交一大笔钱，何不自己做CA呢。openssl x509 -req -days 3650 -in server.csr -CA ca.crt -CAkey server.key -CAcreateserial -out server.crt输入key的密钥后，完成证书生成。-CA选项指明用于被签名的csr证书，-CAkey选项指明用于签名的密钥，-CAserial指明序列号文件，而-CAcreateserial指明文件不存在时自动生成。最后生成了私用密钥：server.key和自己认证的SSL证书：server.crt证书合并：cat server.key server.crt &gt; server.pem 什么是数字签名和证书？http://www.jianshu.com/p/9db57e7612551.信息安全三要素 信息安全中有三个需要解决的问题： 保密性(Confidentiality)：信息在传输时不被泄露 完整性（Integrity）：信息在传输时不被篡改 有效性（Availability）：信息的使用者是合法的这三要素统称为CIA Triad。 公钥密码解决保密性问题 数字签名解决完整性问题和有效性问题 2.数字签名 现实生活中，签名有什么作用？在一封信中，文末的签名是为了表示这封信是签名者写的。计算机中，数字签名也是相同的含义：证明消息是某个特定的人，而不是随随便便一个人发送的（有效性）；除此之外，数字签名还能证明消息没有被篡改（完整性）。 简单来说，数字签名（digital signature）是公钥密码的逆应用：用私钥加密消息，用公钥解密消息。 用私钥加密的消息称为签名，只有拥有私钥的用户可以生成签名。 用公钥解密签名这一步称为验证签名，所有用户都可以验证签名(因为公钥是公开的) 一旦签名验证成功，根据公私钥数学上的对应关系，就可以知道该消息是唯一拥有私钥的用户发送的，而不是随便一个用户发送的。 由于私钥是唯一的，因此数字签名可以保证发送者事后不能抵赖对报文的签名。由此，消息的接收者可以通过数字签名，使第三方确信签名人的身份及发出消息的事实。当双方就消息发出与否及其内容出现争论时，数字签名就可成为一个有力的证据。 生成签名 一般来说，不直接对消息进行签名，而是对消息的哈希值进行签名，步骤如下。 对消息进行哈希计算，得到哈希值 利用私钥对哈希值进行加密，生成签名 将签名附加在消息后面，一起发送过去 验证签名 收到消息后，提取消息中的签名 用公钥对签名进行解密，得到哈希值1。 对消息中的正文进行哈希计算，得到哈希值2。 比较哈希值1和哈希值2，如果相同，则验证成功。 3.证书 证书实际上就是对公钥进行数字签名，它是对公钥合法性提供证明的技术。 考虑这样一种场景：我们对签名进行验证时，需要用到公钥。如果公钥也是伪造的，那怎么办？如果公钥是假的，验证数字签名那就无从谈起，根本不可能从数字签名确定对方的合法性。这时候证书就派上用场了。 证书一般包含：公钥（记住证书中是带有公钥的），公钥的数字签名，公钥拥有者的信息若证书验证成功，这表示该公钥是合法，可信的。 接下来又有问题了：验证证书中的数字签名需要另一个公钥，那么这个公钥的合法性又该如何保证？该问题可以无限循环下去，岂不是到不了头了？这已经是个社会学问题了。我们为什么把钱存进银行？因为我们相信银行，它是一个可信的机构（虽然也有破产的风险）。跟银行一样，我们需要一个可信的机构来颁发证书和提供公钥，只要是它提供的公钥，我们就相信是合法的。 这种机构称为认证机构(Certification Authority， CA)。CA就是能够认定”公钥确实属于此人”，并能生成公钥的数字签名的组织或机构。CA有国际性组织和政府设立的组织，也有通过提供认证服务来盈利的组织。 如何生成证书？ 服务器将公钥A给CA（公钥是服务器的） CA用自己的私钥B给公钥A加密，生成数字签名A CA把公钥A，数字签名A，附加一些服务器信息整合在一起，生成证书，发回给服务器。注：私钥B是用于加密公钥A的，私钥B和公钥A并不是配对的。 如何验证证书？ 客户端得到证书 客户端得到证书的公钥B（通过CA或其它途径） 客户端用公钥B对证书中的数字签名解密，得到哈希值 客户端对公钥进行哈希值计算 两个哈希值对比，如果相同，则证书合法。注：公钥B和上述的私钥B是配对的，分别用于对证书的验证（解密）和生成（加密）。 证书作废 当用户私钥丢失、被盗时，认证机构需要对证书进行作废(revoke)。要作废证书，认证机构需要制作一张证书作废清单(Certificate Revocation List)，简称CRL 假设我们有Bob的证书，该证书有合法的认证机构签名，而且在有效期内，但仅凭这些还不能说明该证书一定有效，还需要查询认证机构最新的CRL，并确认该证书是否有效。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"[读书笔记]chapter2-分布式基础设施-大型网站分布式架构与设计实践","slug":"读书笔记-chapter2-分布式基础设施-大型网站分布式架构与设计实践","date":"2017-12-17T05:02:13.000Z","updated":"2017-12-17T06:38:27.033Z","comments":true,"path":"2017/12/17/读书笔记-chapter2-分布式基础设施-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter2-分布式基础设施-大型网站分布式架构与设计实践/","excerpt":"","text":"分布式系统的支撑系统： 协作及配置管理:Zookeeper 缓存:Redis 消息:ActiveMQ 持久化存储:MySQL,HBase 搜索引擎:Lucene,solr,ElastickSearch CDN 负载均衡:F5,HAProxy,Nginx,SQLProxy 运维自动化 计算:Spark,Spark Streaming,Storm 分布式文件系统:HDFS,FastDfs 日志收集系统:Kafka,ELK 监控系统:Zabbix MySQL高可用方案：(Double)Master-Slave Replication、分库与分表。Master-Slave Replication基于master的binary log进行数据的同步。分库分表的缺点：难以多表关联查询，事务提升到分布式事务，扩容不便会导致数据迁移.考虑点：业务拆分、海量数据带来的单表数据量过大问题、查询效率，高并发访问压力，复杂查询的支持、单点故障。 HBase:分布式列存储关系数据库。集群包含:HMaster和HRegionServer.缺点：支持的查询维度有限，且难以支持复杂查询，如group by,order by,join等。 JMS2种传输模式:Point-to-Point(p2p)模型，Pub/Sub(Publish/Subscribe)模型. 前者称为点对点模型，基于queue，后者称为发布/订阅模型，基于topic。ActiveMQ支持Master-Slave架构，在该架构上，基于恭喜文件系统或共享数据库实现failover(故障转移).ActiveMQ高可用方案:Master-Slave、拆分broker 分库分表、HBase等都会涉及复杂查询的问题，在这个时候，我们可以考虑使用分布式搜索引擎, 如基于Lucene实现的solr和ElasticSearch。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"[读书笔记]chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践","slug":"读书笔记-chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践","date":"2017-12-17T04:57:41.000Z","updated":"2017-12-17T06:38:27.033Z","comments":true,"path":"2017/12/17/读书笔记-chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践/","excerpt":"","text":"分布式应用架构的演变：单一应用-》垂直应用-》分布式应用.垂直应用缺点：通过业务划分，将流量分散到不同的子系统，但子系统见可能存在重叠业务，需要重复造轮子，且容易形成信息孤岛。分布式应用核心：(微)服务化。 协议：基于TCP协议的RPC，基于Http协议的Restful。前者特点是由于处于网络协议的第四层，因此报文较小，网络开销小，性能高，但实现的代价高(不过目前国内有dubbo这个比较成熟的解决方案)，不跨语言；而后者基于网络协议的第7层，可以支持JSON&amp;XML格式数据传输，利于跨语言(目前主流为SpringCloud)。 基于TCP协议的RPCRPC(Remote Process Call):实现又RMI,WebService,Dubbo.涉及服务的提供者和调用方，及参数及结果的序列化。同时伴随着服务的数目增多及服务压力增加：又需要考虑服务分组隔离、服务路由(router)及负载均衡(Load Balance)。 对象的序列化方案：Java本身的,Hessian,Google protobuffer,JSON,xml. 服务的路由和负载均衡服务化(SOA,Service-Oriented Architecture):剥离公共服务，分离不同业务服务。负载均衡方案：硬件负载均衡如F5，软件解决：HAProxy，Ngyinx，LVS，Zookeeper等为了避免服务路由的单点故障，需要一个可以动态注册和获取服务信息的地方，来统一管理服务名称和其对应服务器列表信息，称之为服务配置中心。服务启动时自动将名称、地址注册到服务配置中心，服务消费者通过配置中心来获取机器列表，通过相应的负载均衡算法，选取其中一台服务器进行调用。当服务器宕机或下线时，需要能够动态地从服务配置中心里面移除，并通知相应的服务消费者。(这就是去中心化)。Zookeeper是一个很好的实现。负载均衡算法：轮询(Round Robin)法、随机(Random) 法、源地址哈希法、加权轮询法、加权随机法、最小连接法等.最好可以动态配置负载均衡规则，以满足千变万化的需求。Zookeeper：集群搭建略。客户端推荐zkClient,可以解决ZooKeeper API的一些繁琐问题，如一次性watcher问题，session重建问题等，它将watcher机制转换为一种更加容易理解的订阅模式，并且这种关系可以保持，而非一次性的。 Http服务网关基于网关(gateway)的安全架构:来自外部的请求先经过网关进行权限和安全校验，校验通过后再根据传入的服务名称，去寻找调用服务，最后通过网关返回结果。此时，服务提供者是不直接对外开放的。那么此时需要在网关前面加上一层负载均衡集群，而网关本身也采用集群模式。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"使用hexo搭建博客","slug":"使用hexo搭建博客","date":"2017-12-16T15:32:09.000Z","updated":"2017-12-17T06:38:27.033Z","comments":true,"path":"2017/12/16/使用hexo搭建博客/","link":"","permalink":"http://xbynet.top/2017/12/16/使用hexo搭建博客/","excerpt":"好处:免费、强大、可迁移、markdown+git组合 创建仓库新建一个名为你的用户名.github.io的仓库，比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 http://test.github.io 了仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久。 绑定域名将CNAME指向你的用户名.github.io然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名在你绑定了新域名之后，原来的你的用户名.github.io会自动跳转到你的新域名。","text":"好处:免费、强大、可迁移、markdown+git组合 创建仓库新建一个名为你的用户名.github.io的仓库，比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 http://test.github.io 了仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久。 绑定域名将CNAME指向你的用户名.github.io然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名在你绑定了新域名之后，原来的你的用户名.github.io会自动跳转到你的新域名。 配置SSH keyssh-keygen -t rsa -C &quot;邮件地址&quot;找到.ssh\\id_rsa.pub文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key。测试是否成功$ ssh -T git@github.com # 注意邮箱地址不用改 此时你还需要配置：12$ git config --global user.name &quot;xbynet&quot;// 你的github用户名，非昵称$ git config --global user.email &quot;xxx@xxx.com&quot;// 填写你的github注册邮箱 使用hexo写博客Hexo是一个简单、快速、强大的基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题。官网： http://hexo.iogithub: https://github.com/hexojs/hexo 由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。 安装之前先来说几个注意事项：很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行；hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导；hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的；12345$ npm install -g hexo$ hexo init$ hexo g # 生成$ hexo s # 启动服务 执行以上命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的：hexo s是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故 修改主题采用hexo-theme-next修改_config.yml中的theme: landscape改为theme: next. 保留CNAME、README.md等文件提交之后网页上一看，发现以前其它代码都没了，此时不要慌，一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的 常用hexo命令12345678910111213141516hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本缩写：hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy组合命令：hexo s -g #生成并本地预览hexo d -g #生成并上传 _config.yml:这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 上传到github首先，ssh key肯定要配置好。其次，配置_config.yml中有关deploy的部分：1234567891011正确写法：deploy: type: git repository: git@github.com:liuxianan/liuxianan.github.io.git branch: master 错误写法：deploy: type: github repository: https://github.com/liuxianan/liuxianan.github.io.git branch: master 12npm install hexo-deployer-git --savehexo d -g #生成并上传 遇到的问题：https://stackoverflow.com/questions/17846529/could-not-open-a-connection-to-your-authentication-agenthttps://stackoverflow.com/questions/22575662/filename-too-long-in-git-for-windows如果遇到git not found之类的错误，请使用git bash 而非cmd如果遇到Permission denyed:1、请检查密钥2、可能是没有加载私钥到ssh-agent,到.ssh目录下执行:12eval $(ssh-agent)ssh-add id_rsa 3、git for windows下的Filename too long1git config --global core.longpaths true 写博客定位到我们的hexo根目录，执行命令：hexo new &#39;my-first-blog&#39;hexo会帮我们在source/_posts下生成相关md文件,我们只需要打开这个文件就可以开始写博客了当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。一般完整格式如下：123456789---title: postName #文章页面上的显示名称，一般是中文date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改categories: 默认分类 #分类tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面---以下是正文 那么hexo new page ‘postName’命令和hexo new ‘postName’有什么区别呢？1hexo new page &quot;my-second-blog&quot; 最终部署时生成：hexo\\public\\my-second-blog\\index.html，但是它不会作为文章出现在博文目录。 如何让博文列表不显示全部内容默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？答案是在合适的位置加上即可. 12345678910111213# 前言使用github pages服务搭建博客的好处有：1. 全是静态文件，访问速度快；2. 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；3. 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；&lt;!--more--&gt;4. 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；5. 博客内容可以轻松打包、转移、发布到其它平台；6. 等等； 如何支持目录：为文章添加 toc: true Toc虽然生成了，审查元素看锚也有，但是无法点击:(差了很久，也搜了issues，但是没人遇到和我类似的问题。。。)修改next/layout/_scripts/vendors.swig，添加 12345678910&lt;script&gt; $(function()&#123; $(\".nav-item .nav-link\").each(function(i)&#123; $(this).text($(this).attr(\"href\").replace('#','')); $(this).parent().contents().filter(function() &#123; return this.nodeType == 3; //Node.TEXT_NODE &#125;).remove(); &#125;); &#125;);&lt;/script&gt; 404页面:在source下新建一个404.html文件即可,建议采用腾讯公益404，如下： 1234567891011121314&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" /&gt; &lt;meta name=\"robots\" content=\"all\" /&gt; &lt;meta name=\"robots\" content=\"index,follow\"/&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=\"text/javascript\" src=\"//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"/\" homePageName=\"返回主页\"&gt;&lt;/script&gt; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 配置markdown解析器，这个官方文档没有说明，但是由于hexo采用hexo-renderer-marked,故而可以参考hexo-renderer-marked文档:12345678910marked: gfm: true pedantic: false sanitize: false tables: true breaks: true smartLists: true smartypants: true modifyAnchors: &apos;&apos; autolink: true 安装插件：如报ERROR Deployer not found: git,请执行：npm install --save hexo-deployer-git1、sitemap、feed插件$ npm install hexo-generator-sitemap hexo-generator-feed hexo-generator-baidu-sitemap --save启用，修改Hexo_config.yml，增加以下内容 123456789sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xmfeed: type: atom path: atom.xml limit: 100 添加“Fork me on Github” ribbon给blog主页添加一个“Fork me on Github”的绶带（ribbon）那么将下面的代码（注意将you改为你自己的github上的注册名）,添加到next/layout/_layout.swig的body结束标签之前 (注意：这是next主题的地址，其他主题可能不一致):1&lt;a href=&quot;https://github.com/xbynet&quot;&gt;&lt;img style=&quot;position: absolute; top: 0; left: 0; border: 0;&quot; src=&quot;https://camo.githubusercontent.com/567c3a48d796e2fc06ea80409cc9dd82bf714434/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f6c6566745f6461726b626c75655f3132313632312e706e67&quot; alt=&quot;Fork me on GitHub&quot; data-canonical-src=&quot;https://s3.amazonaws.com/github/ribbons/forkme_left_darkblue_121621.png&quot;&gt;&lt;/a&gt; 插入音乐:两种方式，在线和离线。在线的可以采用网易云音乐的外链播放，不过是一个iframe。离线/在线直播源播放可以采用hexo-tag-aplayer.安装后，修改next/layout/_custom/sidebar.swig:123456789101112131415161718192021222324&lt;div id=&quot;aplayer1&quot; class=&quot;aplayer&quot;&gt;&lt;/div&gt;&lt;script src=&quot;/asserts/js/APlayer.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt; var ap = new APlayer(&#123; element: document.getElementById(&apos;aplayer1&apos;), narrow: false, autoplay: false, showlrc: false, mutex: true, theme: &apos;#e6d0b2&apos;, preload: &apos;metadata&apos;, mode: &apos;circulation&apos;, music: &#123; title: &apos;素雨&apos;, author: &apos;孙雪宁&apos;, url: &apos;http://ws.stream.qqmusic.qq.com/C1000040LV2h3FzIVl.m4a?fromtag=38&apos;, pic: &apos;https://y.gtimg.cn/music/photo_new/T002R300x300M000003mxnKZ0WbTPc.jpg?max_age=2592000&apos; &#125; &#125;);&lt;/script&gt;&lt;!-- &lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=28815250&amp;auto=0&amp;height=66&quot;&gt;&lt;/iframe&gt;--&gt; 如何寻找在线音乐源地址:http://music.liuzhijin.cn/ 参考：https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.htmlhttps://segmentfault.com/a/1190000006831597https://www.cnblogs.com/zhcncn/p/4097881.htmlhttps://github.com/litten/BlogBackuphttp://www.jianshu.com/p/f054333ac9e6","categories":[{"name":"杂项","slug":"杂项","permalink":"http://xbynet.top/categories/杂项/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://xbynet.top/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://xbynet.top/tags/github/"}]}]}