{"meta":{"title":"倚楼听风雨","subtitle":"淡看江湖路","description":"走路人","author":"xbynet","url":"http://xbynet.top"},"pages":[{"title":"","date":"2017-12-17T06:38:27.031Z","updated":"2017-12-17T06:38:27.031Z","comments":true,"path":"404.html","permalink":"http://xbynet.top/404.html","excerpt":"","text":""},{"title":"关于","date":"2017-12-16T09:59:31.000Z","updated":"2017-12-17T06:38:27.037Z","comments":true,"path":"about/index.html","permalink":"http://xbynet.top/about/index.html","excerpt":"","text":"倚楼听风雨，淡看江湖路"},{"title":"分类","date":"2017-12-16T09:58:38.000Z","updated":"2017-12-17T06:38:27.039Z","comments":true,"path":"categories/index.html","permalink":"http://xbynet.top/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2017-12-16T09:57:47.000Z","updated":"2017-12-17T06:38:27.090Z","comments":true,"path":"tags/index.html","permalink":"http://xbynet.top/tags/index.html","excerpt":"","text":""},{"title":"","date":"2017-12-17T06:38:27.038Z","updated":"2017-12-17T06:38:27.038Z","comments":true,"path":"asserts/js/APlayer.min.js","permalink":"http://xbynet.top/asserts/js/APlayer.min.js","excerpt":"","text":"!function(e,t){\"object\"==typeof exports&&\"object\"==typeof module?module.exports=t():\"function\"==typeof define&&define.amd?define(\"APlayer\",[],t):\"object\"==typeof exports?exports.APlayer=t():e.APlayer=t()}(this,function(){return function(e){function t(r){if(n[r])return n[r].exports;var a=n[r]={i:r,l:!1,exports:{}};return e[r].call(a.exports,a,a.exports,t),a.l=!0,a.exports}var n={};return t.m=e,t.c=n,t.i=function(e){return e},t.d=function(e,n,r){t.o(e,n)||Object.defineProperty(e,n,{configurable:!1,enumerable:!0,get:r})},t.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return t.d(n,\"a\",n),n},t.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},t.p=\"\",t(t.s=13)}([function(e,t,n){var r=n(3);\"string\"==typeof r&&(r=[[e.i,r,\"\"]]);n(10)(r,{});r.locals&&(e.exports=r.locals)},function(e,t,n){\"use strict\";function r(e){var t=e.length;if(t%4>0)throw new Error(\"Invalid string. Length must be a multiple of 4\");return\"=\"===e[t-2]?2:\"=\"===e[t-1]?1:0}function a(e){return 3*e.length/4-r(e)}function i(e){var t,n,a,i,o,l,s=e.length;o=r(e),l=new c(3*s/4-o),a=o>0?s-4:s;var u=0;for(t=0,n=0;t>12&63]+u[e>>6&63]+u[63&e]}function l(e,t,n){for(var r,a=[],i=t;i=0,n2147483647?n=2147483647:n=0;u--){for(var c=!0,h=0;ha&&(r=a):r=a;var i=t.length;if(i%2!=0)throw new TypeError(\"Invalid hex string\");r>i/2&&(r=i/2);for(var o=0;o239?4:i>223?3:i>191?2:1;if(a+le.length)throw new RangeError(\"Index out of range\");if(n-1&&i.push(239,191,189);continue}if(o+1===r){(t-=3)>-1&&i.push(239,191,189);continue}a=n;continue}if(n-1&&i.push(239,191,189),a=n;continue}n=65536+(a-552966&63|128,63&n|128)}else{if(!(n>18|240,n>>12&63|128,n>>6&63|128,63&n|128)}}return i}function Z(e){for(var t=[],n=0;n>8,a=n%256,i.push(a),i.push(r);return i}function Q(e){return W.toByteArray(J(e))}function V(e,t,n,r){for(var a=0;a=t.length||a>=e.length);++a)t[a+n]=e[a];return a}function K(e){return e!==e}/*! * The buffer module from node.js, for the browser. * * @author Feross Aboukhadijeh * @license MIT */ var W=n(1),X=n(6),$=n(7);t.Buffer=o,t.SlowBuffer=m,t.INSPECT_MAX_BYTES=50,o.TYPED_ARRAY_SUPPORT=void 0!==e.TYPED_ARRAY_SUPPORT?e.TYPED_ARRAY_SUPPORT:r(),t.kMaxLength=a(),o.poolSize=8192,o._augment=function(e){return e.__proto__=o.prototype,e},o.from=function(e,t,n){return l(null,e,t,n)},o.TYPED_ARRAY_SUPPORT&&(o.prototype.__proto__=Uint8Array.prototype,o.__proto__=Uint8Array,\"undefined\"!=typeof Symbol&&Symbol.species&&o[Symbol.species]===o&&Object.defineProperty(o,Symbol.species,{value:null,configurable:!0})),o.alloc=function(e,t,n){return u(null,e,t,n)},o.allocUnsafe=function(e){return p(null,e)},o.allocUnsafeSlow=function(e){return p(null,e)},o.isBuffer=function(e){return!(null==e||!e._isBuffer)},o.compare=function(e,t){if(!o.isBuffer(e)||!o.isBuffer(t))throw new TypeError(\"Arguments must be Buffers\");if(e===t)return 0;for(var n=e.length,r=t.length,a=0,i=Math.min(n,r);a>1,p=-7,c=n?a-1:0,h=n?-1:1,f=e[t+c];for(c+=h,i=f&(1=-p,p+=l;p>0;i=256*i+e[t+c],c+=h,p-=8);for(o=i&(1=-p,p+=r;p>0;o=256*o+e[t+c],c+=h,p-=8);if(0===i)i=1-u;else{if(i===s)return o?NaN:1/0*(f?-1:1);o+=Math.pow(2,r),i-=u}return(f?-1:1)*o*Math.pow(2,i-r)},t.write=function(e,t,n,r,a,i){var o,l,s,u=8*i-a-1,p=(11,h=23===a?Math.pow(2,-24)-Math.pow(2,-77):0,f=r?0:i-1,d=r?1:-1,y=t=2&&(o++,s/=2),o+c>=p?(l=0,o=p):o+c>=1?(l=(t*s-1)*Math.pow(2,a),o+=c):(l=t*Math.pow(2,c-1)*Math.pow(2,a),o=0));a>=8;e[n+f]=255&l,f+=d,l/=256,a-=8);for(o=o=0;r--){var a=e[r];\".\"===a?e.splice(r,1):\"..\"===a?(e.splice(r,1),n++):n&&(e.splice(r,1),n--)}if(t)for(;n--;n)e.unshift(\"..\");return e}function r(e,t){if(e.filter)return e.filter(t);for(var n=[],r=0;r=-1&&!a;i--){var o=i>=0?arguments[i]:e.cwd();if(\"string\"!=typeof o)throw new TypeError(\"Arguments to path.resolve must be strings\");o&&(t=o+\"/\"+t,a=\"/\"===o.charAt(0))}return t=n(r(t.split(\"/\"),function(e){return!!e}),!a).join(\"/\"),(a?\"/\":\"\")+t||\".\"},t.normalize=function(e){var a=t.isAbsolute(e),i=\"/\"===o(e,-1);return e=n(r(e.split(\"/\"),function(e){return!!e}),!a).join(\"/\"),e||a||(e=\".\"),e&&i&&(e+=\"/\"),(a?\"/\":\"\")+e},t.isAbsolute=function(e){return\"/\"===e.charAt(0)},t.join=function(){var e=Array.prototype.slice.call(arguments,0);return t.normalize(r(e,function(e,t){if(\"string\"!=typeof e)throw new TypeError(\"Arguments to path.join must be strings\");return e}).join(\"/\"))},t.relative=function(e,n){function r(e){for(var t=0;t=0&&\"\"===e[n];n--);return t>n?[]:e.slice(t,n-t+1)}e=t.resolve(e).substr(1),n=t.resolve(n).substr(1);for(var a=r(e.split(\"/\")),i=r(n.split(\"/\")),o=Math.min(a.length,i.length),l=o,s=0;s\\n \",this.element.innerHTML=f,this.element.offsetWidth"}],"posts":[{"title":"[杂记]有趣的句子","slug":"杂记-有趣的句子","date":"2017-12-18T01:28:20.000Z","updated":"2017-12-18T01:30:19.154Z","comments":true,"path":"2017/12/18/杂记-有趣的句子/","link":"","permalink":"http://xbynet.top/2017/12/18/杂记-有趣的句子/","excerpt":"","text":"微服务的定义：In short, the microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. 康威定律：Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure. Of course, just because you can do something, doesn’t mean you should - but partitioning your system in this way means you have the option.你可以做什么事，并不意味着你必须做这些事，但如果将系统通过微服务的方式拆分，意味着你有这个选择。-灵活性。 Being woken up at 3am every night by your pager is certainly a powerful incentive to focus on quality when writing your code.被凌晨3点的传输机吵醒无疑对你写代码时关注质量是一个很大的激励(毕竟谁都不想在凌晨3点被吵醒) Change control doesn’t necessarily mean change reduction - with the right attitudes and tools you can make frequent, fast, and well-controlled changes to software.关于控制改变的 We can’t say for sure where we’ll end up, but one of the challenges of software development is that you can only make decisions based on the imperfect information that you currently have to hand.关于软件设计的 You can’t control what you can’t measure Should you measure something be sure what you really measure otherwise the results can keep you far from reality. Always validate your assumptions and RTFM! 一大波有趣的短语：RTFM/RTM：RTFM是一组缩写，Unix程序员的一种习惯，意思是：去读他妈的手册，Read the fucking manual！这句话通常用在回复那些只要查阅文件就可以解决，拿出来提问只是浪费别人时间的问题。延伸：RTFSC/RTFS(Reading The Fucking Source Code)UTFH (“Use The Fucking Help”)STFW (“Search The Fucking Web”)STFG (“Search The Fucking Google” or “Search The Fantastic Google”)GIYF (“Google Is Your Friend”)JFGI (“Just Fucking Google It”)JGIYN (“Just Google It You Noob”)UTSL (“Use The Source Luke”—alternately, RTFS)RTFA (“Read The Fucking Article”—common on news forums such as Fark.com[3] and Slashdot)RTFE (“Read The Fucking Email”)RTFC (“Read The Fucking Code,” or “Reboot The Fucking Computer”)RTFSC (“Read The Fucking Source Code”)RTFQ (“Read The Fucking Question”)RTFFAQ (“Read The Fucking Frequently Asked Questions”)LMGTFY (“Let Me Google That For You”)WIDGI (“When In Doubt Google It”—also occasionally “WIDGIT”)FIOTI (“Find It On The Internet”)","categories":[{"name":"杂记","slug":"杂记","permalink":"http://xbynet.top/categories/杂记/"}],"tags":[{"name":"杂记","slug":"杂记","permalink":"http://xbynet.top/tags/杂记/"}]},{"title":"限流令牌桶算法","slug":"限流令牌桶算法","date":"2017-12-17T05:53:52.000Z","updated":"2017-12-17T06:38:27.036Z","comments":true,"path":"2017/12/17/限流令牌桶算法/","link":"","permalink":"http://xbynet.top/2017/12/17/限流令牌桶算法/","excerpt":"缓存(Caching)，限流(Throttling)和降级(BackOff)是系统的三把利剑。 原理做限流(Rate Limiting/Throttling)的时候，除了简单的控制并发，如果要准确的控制TPS，简单的做法是维护一个单位时间内的Counter，如判断单位时间已经过去，则将Counter重置零。此做法被认为没有很好的处理单位时间的边界，比如在前一秒的最后一毫秒里和下一秒的第一毫秒都触发了最大的请求数，将目光移动一下，就看到在两毫秒内发生了两倍的TPS。因此更平滑的算法如Leaky Bucket–漏桶算法，又或者将原来单位时间内单一的Counter拆分为单位时间内的多个Buckets并滑动计算。","text":"缓存(Caching)，限流(Throttling)和降级(BackOff)是系统的三把利剑。 原理做限流(Rate Limiting/Throttling)的时候，除了简单的控制并发，如果要准确的控制TPS，简单的做法是维护一个单位时间内的Counter，如判断单位时间已经过去，则将Counter重置零。此做法被认为没有很好的处理单位时间的边界，比如在前一秒的最后一毫秒里和下一秒的第一毫秒都触发了最大的请求数，将目光移动一下，就看到在两毫秒内发生了两倍的TPS。因此更平滑的算法如Leaky Bucket–漏桶算法，又或者将原来单位时间内单一的Counter拆分为单位时间内的多个Buckets并滑动计算。 Leaky Bucket 与 Token Bucket 算法 漏桶算法简单的想象有一个木桶，有新请求就是不断的倒水进来，然后桶底下有个洞，按照固定的速率把水漏走，如果水进来的速度比漏走的快，桶可能就会满了，然后就拒绝请求。可见这里有两个变量，一个是桶的大小，支持流量突发增多时可以存多少的水(burst)，另一个是水桶漏洞的大小(rate)，可以简单的让burst等于rate，也可以让burst更大接收更多突发请求，伪代码如下：123456789101112131415161718192021double rate; // leak rate in calls/sdouble burst; // bucket size in callslong refreshTime; // time for last water refreshdouble water; // water count at refreshTimerefreshWater() &#123; long now = getTimeOfDay(); water = max(0, water- (now - refreshTime)*rate); // 水随着时间流逝，不断流走，最多就流干到0. refreshTime = now;&#125;bool permissionGranted() &#123; refreshWater(); if (water &lt; burst) &#123; // 水桶还没满，继续加1 water ++; return true; &#125; else &#123; return false; &#125;&#125; 但是对于很多情况下，除了要求能够限制平均处理速度外，还要求能允许一定程度的的突发情况。这样的话，漏桶算法就不合适了，用令牌桶算法更合适。Token Bucket 是与 Leaky Bucket 效果一样但方向相反的算法，更加容易理解。随着时间流逝，系统会按速率 1/rate 的时间间隔(如果rate=100，则间隔是10ms)往桶里加入Token(想象和漏洞漏水相反，有个水龙头在不断的加水)，如果桶已经满了就不再加了。新请求来临时，会各自拿走一个Token，如果没有Token可拿了就拒绝服务。 Google Guava中的RateLimiter，实际上就实现了Token Bucket的算法。它支持两种获取permits接口，一种是如果拿不到立刻返回false，一种会阻塞等待一段时间看能不能拿到。Leacky Bucket算法默认一开始水桶是空的，可以立即就接收最多burst的请求，而Token Bucket就要设置初始Token的数量。RateLimiter有两个子类，一个是WarmingUp，一个是Bursty。 WarmingUp，burst = warmUp时间/固定token添加间隔(即上例那个10ms)，初始token数量 = burst，有算法保证系统总是相对平滑。 Bursty， burst = rate或另外的参数设置，初始token数量 = 0 ，当系统冷了一段时间，支持突发到burst。Guava以micros为时间单位，计算token的变化。 guava RateLimiter123456789101112131415161718192021222324252627private static RateLimiter one=RateLimiter.create(2);//每秒2个 private static RateLimiter two=RateLimiter.create(2);//每秒2个 private RateLimitUtil()&#123;&#125;; public static void acquire(RateLimiter r,int num)&#123; double time =r.acquire(num); System.out.println(\"wait time=\"+time); &#125; public static void main(String[] args) throws InterruptedException &#123; acquire(one,1); acquire(one,1); acquire(one,1); System.out.println(\"-----\"); acquire(two,10); acquire(two,1); &#125; 输出:wait time=0.0wait time=0.499163wait time=0.489308-----wait time=0.0wait time=4.497819 Guava RateLimiter在Web应用中的使用一般Web系统的访问限制都可以用容器本身来实现，比如tomcat就可以在connector上面配置connection数目的限制，servlet thread限制。有时候系统复杂后希望对不同服务提供不同的RateLimiter，例如对数据库操作要求比较大的速率小些，在内存可以处理的速率大写，还有可能对集群提供rate limiter服务。 这里记录下实践过程中系统如何使用RateLimiter来限制所有spring访问的访问速率。1234567891011121314151617181920212223242526272829public class RateLimiterFilter implements Filter &#123; private static Logger logger = Logger.getLogger(RateLimiterFilter.class); private RateLimiter limiter = null; public void init(FilterConfig config) throws ServletException &#123; limiter = RateLimiter.create(100); //100 request per second &#125; public void destroy() &#123; &#125; public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest req = (HttpServletRequest) request; HttpServletResponse res = (HttpServletResponse) response; if(limiter.tryAcquire()) &#123; if(logger.isTraceEnabled())&#123; logger.trace(\"get access: \"); &#125; chain.doFilter(request, response) &#125; else &#123; logger.info(\"system limitation reached!\"); req.getRequestDispatcher(\"/WEB-INF/jsp/error/429.jsp\").forward(req,res); &#125; &#125;&#125; 源码解析guava的限流算法有2种模式，一种是稳定速度，还有一种是生成令牌的速度慢慢提升直到维持在一个稳定的速度。2种模式原理类似，只是在具体等待多久的时间计算上有区别。以下就专门指稳定速度的模式。 先来看看它的acquire()方法：12345public double acquire(int permits) &#123; long microsToWait = reserve(permits);//先计算获取这些请求需要让线程等待多长时间 stopwatch.sleepMicrosUninterruptibly(microsToWait);//让线程阻塞microTowait微秒长的时间 return 1.0 * microsToWait / SECONDS.toMicros(1L);//返回阻塞的时间 &#125; 主要分3步： 1. 根据limiter创建时传入的参数，计算出生成这些数量的令牌需要多长的时间。 2. 让线程阻塞microTowait这么长的时间（单位：微秒） 3. 再返回阻塞了多久，单位：秒 具体它是怎么计算需要多长时间的呢？让我们来看看reserve(permits)方法。 12345678910111213141516171819202122232425262728final long reserve(int permits) &#123; checkPermits(permits);//检查参数是否合法 synchronized (mutex()) &#123; return reserveAndGetWaitLength(permits, stopwatch.readMicros()); &#125; &#125; ↓ ↓ ↓final long reserveAndGetWaitLength(int permits, long nowMicros) &#123; long momentAvailable = reserveEarliestAvailable(permits, nowMicros); return max(momentAvailable - nowMicros, 0); &#125; ↓ ↓ ↓final long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; resync(nowMicros);//here long returnValue = nextFreeTicketMicros; double storedPermitsToSpend = min(requiredPermits, this.storedPermits); double freshPermits = requiredPermits - storedPermitsToSpend; long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros; this.storedPermits -= storedPermitsToSpend; return returnValue; 最终调用的是reserveEarliestAvailable方法。先看看resync(nowMicros)方法。 12345678private void resync(long nowMicros) &#123; // if nextFreeTicket is in the past, resync to now if (nowMicros &gt; nextFreeTicketMicros) &#123; storedPermits = min(maxPermits, storedPermits + (nowMicros - nextFreeTicketMicros) / stableIntervalMicros); nextFreeTicketMicros = nowMicros; &#125; &#125; nextFreeTicketMicros的意思是：下次获取的时候需要减去的时间。如果是第一次调用accquire()方法，那nowMicros - nextFreeTicketMicros 就是从初始化（初始化的时候会给nextFreeTicketMicros 赋值一次,具体可以看RateLimiter的构造器）到第一次请求，这中间发生的时间。 这个方法的意思，如果当前时间比上一轮设置的下次获取的时间大（因为存在提前获取的情况，比如上次直接获取了10个，那上轮设置的nextFreeTicketMicros就是上一轮的时间+5s。后面会提到），那就计算这个中间理论上能生成多少的令牌。比如这中间隔了1秒钟，然后stableIntervalMicros=5000（稳定生成速度的情况下）,那么，就这中间就可以生成2个令牌。再加上它原先存储的storedPermits个，如果比maxPermits大，那最大也只能存maxPermits这么多。如果比maxPermits小，那就是storedPermits=原先存的+这中间生成的数量。同时记录下下次获取的时候需要减去的时间，也就是当前时间 （nextFreeTicketMicros ）。接下来继续看reserveEarliestAvailable方法： 12345678910111213final long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; //1 resync(nowMicros); //2 long returnValue = nextFreeTicketMicros;//3 double storedPermitsToSpend = min(requiredPermits, this.storedPermits);//4 double freshPermits = requiredPermits - storedPermitsToSpend;//5 long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros);//6 this.nextFreeTicketMicros = nextFreeTicketMicros + waitMicros;//7 this.storedPermits -= storedPermitsToSpend;//8 return returnValue;//9 &#125; 我们一行一行来看： 第二行设置好之后。第3行中将下次获取的时候需要减去的时间作为返回值（这点很重要）。 第4行是从存储的许可数量和请求的数量中获取小的那个值，第5行是获取这个值和请求的值的差。 这2句是什么意思呢？ 其实这2句就是使得RateLimiter能一定程度的突发请求的原因。假设requiredPermits=10，而我们能存的storedPermits=2，那么freshPermits=8，也就是多取了8个。而第6行就是计算这多取的8个需要多长时间才能生成？需要3秒。那么，就将这3秒钟加到我们前面赋值的“下次获取的时候需要减去的时间 ”。 比如在05秒的时候一次性获取了10个，那么，第7行的意思就是nextFreeTicketMicros=13S对应的系统的毫秒数。然后storedPermits就是-8。当过了1秒钟，下一次请求来调用acquire(1)的时候，resync方法中由于nowMicros1234final long reserveAndGetWaitLength(int permits, long nowMicros) &#123; long momentAvailable = reserveEarliestAvailable(permits, nowMicros); return max(momentAvailable - nowMicros, 0);//取较大的值 &#125; 也就是说，reserveAndGetWaitLength会返回max(13-6,0)，也就是7。而该方法的返回值又是用于sleep线程的，也就是我们在一开始看到的：12345public double acquire(int permits) &#123; long microsToWait = reserve(permits); stopwatch.sleepMicrosUninterruptibly(microsToWait); return 1.0 * microsToWait / SECONDS.toMicros(1L); &#125; 总结起来，最主要的是nowMicros,nextFreeTicketMicros这2个值。nextFreeTicketMicros在一开始构造器执行的时候会赋值一次为构造器执行的时间。当第一次调用accquire()的时候，resync会被执行，然后在accquire()中将nextFreeTicketMicros设置为当前时间。但是，需要注意的是，在reserveEarliestAvailable中会根据请求的令牌数和当前存储的令牌数进行比较。如果请求的令牌数很大，则会计算出生成这些多余的令牌需要的时间，并加在nextFreeTicketMicros上，从而保证下次调用accquire()的时候，根据nextFreeTicketMicros和当时的nowMicros相减，若&gt;0，则需要等到对应的时间。也就能应对流量的突增情况了。 所以最重要的是nextFreeTicketMicros，它记录了你这次获取的时候，能够开始生成令牌的时间。比如当前是05S，那若nextFreeTicketMicros=10，表示它要到10S才能开始生成令牌，谁叫前面的多拿了这么多呢。至于它这次是多拿了还是只是拿一个令牌，等待时间都是这么多。如果这次又多拿了，那下次就等待更久！ 123456789101112131415private static RateLimiter too=RateLimiter.create(2);//每秒2个 private RateLimitUtil()&#123;&#125;; public static void acquire(RateLimiter r,int num)&#123; double time =r.acquire(num); System.out.println(\"wait time=\"+time); &#125; public static void main(String[] args) throws InterruptedException &#123; acquire(too,1); acquire(too,10);//只等待了0.5秒就获取了10个 acquire(too,10);//等待了5秒就获取了10个 acquire(too,1);//虽然只获取1个，也是等待5秒 &#125; 参考:https://github.com/springside/springside4/wiki/Rate-Limiterhttp://blog.csdn.net/FoolishAndStupid/article/details/76285690http://blog.csdn.net/jiesa/article/details/50412027http://ifeve.com/guava-ratelimiter/https://github.com/google/guava/blob/fd919e54a55ba169dc7d9f54b7b3485aa7fa0970/guava/src/com/google/common/util/concurrent/RateLimiter.javahttps://github.com/google/guava/blob/fd919e54a55ba169dc7d9f54b7b3485aa7fa0970/guava-tests/test/com/google/common/util/concurrent/RateLimiterTest.java","categories":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/tags/算法/"}]},{"title":"Consistent-Hash一致性哈希算法","slug":"Consistent-Hash一致性哈希算法","date":"2017-12-17T05:53:21.000Z","updated":"2017-12-17T06:38:27.032Z","comments":true,"path":"2017/12/17/Consistent-Hash一致性哈希算法/","link":"","permalink":"http://xbynet.top/2017/12/17/Consistent-Hash一致性哈希算法/","excerpt":"理论部分一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题。一致性哈希修正了简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。","text":"理论部分一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希（DHT）实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题。一致性哈希修正了简单哈希算法带来的问题，使得分布式哈希（DHT）可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：1、平衡性(Balance)：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。2、单调性(Monotonicity)：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。3、分散性(Spread)：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。4、负载(Load)：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 场景描述：在了解一致性哈希算法之前，最好先了解一下缓存中的一个应用场景。假设，我们有三台缓存服务器，用于缓存图片，我们为这三台缓存服务器编号为0号、1号、2号，现在，有3万张图片需要缓存，我们希望这些图片被均匀的缓存到这3台服务上，以便它们能够分摊缓存的压力。原始的做法是对缓存项的键进行哈希，将hash后的结果对缓存器的数量进行取模操作，通过取模后的结果，决定缓存项将会缓存在哪一台服务器上，我们仍然以刚才描述的场景为例，假设我们使用名称作为访问图片的key，假设图片名称是不重复的，那么，我们可以使用如下公式，计算出图片应该存放在哪台服务器上。hash（图片名称）% N,我们暂时称上述算ASH算法或者取模算法。 但是，使用上述HASH算法进行缓存时，会出现一些缺陷，试想一下，如果3台缓存服务器已经不能满足我们的缓存需求，那么我们应该怎么做呢？没错，很简单，多增加两存服务器不就行了，假设，我们增加了一台缓存服务器，那么缓存服务器的数量就由3台变成了4台，此时，如果仍然使用上述方法对同一张图片进行缓存，那么这张图片所在务器编号必定与原来3台服务器时所在的服务器编号不同，因为除数由3变为了4，被除数不变的情况下，余数肯定不同，这种情况带来的结果就是当服务器数量变动时，所有的位置都要发生改变，换句话说，当服务器数量发生改变时，所有缓存在一定时间内是失效的，当应用无法从缓存中获取数据时，则会向后端服务器请求数据，同理，假设3存中突然有一台缓存服务器出现了故障，无法进行缓存，那么我们则需要将故障机器移除，但是如果移除了一台缓存服务器，那么缓存服务器数量从3台变为2台，如果想要访张图片，这张图片的缓存位置必定会发生改变，以前缓存的图片也会失去缓存的作用与意义， 由于大量缓存在同一时间失效，造成了缓存的雪崩，此时前端缓存已经无法起到部分压力的作用，后端服务器将会承受巨大的压力，整个系统很有可能被压垮，所以，我们应该想办法不让这种情况发生，但是由于上述HASH算法本身的缘故，使用取模法缓存时，这种情况是无法避免的，为了解决这些问题，一致性哈希算法诞生了。 我们来回顾一下使用上述算法会出现的问题。问题1：当缓存服务器数量发生变化时，会引起缓存的雪崩，可能会引起整体系统压力过大而崩溃（大量缓存同一时间失效）。问题2：当缓存服务器数量发生变化时，几乎所有缓存的位置都会发生改变，怎样才能尽量减少受影响的缓存呢？ 其实，一致性哈希算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性哈希算法是对2^32取模.首先，我们把二的三十二次方想象成一个圆，就像钟表一样，钟表的圆可以理解成由60个点组成的圆，而此处我们把这个圆想象成由2^32个点组成的圆,称为Hash环.仍然以之前描述的场景为例，假设我们有3台缓存服务器，服务器A、服务器B、服务器C，那么，在生产中，这三台服务器肯定有自己的IP地址，我们使用它们各自的IP地址进行哈希计算，使用哈希后的结果对2^32取模，可以使用如下公式示意。hash（服务器A的IP地址） % 2^32通过上述公式算出的结果一定是一个0到2^32-1之间的一个整数，我们就用算出的这个整数，代表服务器A，既然这个整数肯定处于0到2^32-1之间，那么，上图中的hash环定有一个点与这个整数对应，而我们刚才已经说明，使用这个整数代表服务器A，那么，服务器A就可以映射到这个环上,以此类推。 好了，到目前为止，我们已经把缓存服务器与hash环联系在了一起，我们通过上述方法，把缓存服务器映射到了hash环上，那么使用同样的方法，我们也可以将需要缓存的映射到hash环上。假设，我们需要使用缓存服务器缓存图片，而且我们仍然使用图片的名称作为找到图片的key，那么我们使用如下公式可以将图片映射到上图中的hash环上。hash（图片名称） % 2^32 现在服务器与图片都被映射到了hash环上，那么这个图片到底应该被缓存到哪一台服务器上呢？从图位置开始，沿顺时针方向遇到的第一个服务器就是需要缓存该图片的服务器。节点机器的失效删除：节点机器的添加：总结一下：1、与简单哈希不同，一致性hash有个hash环，同时会对服务器和需要换乘的对象进行hash，最终所有结果都会落到这个hash环上。然后根据顺时针规则找到最近的服务器进行缓存的存取。2、基于第1点,一致性hash无论是新增主机还是删除主机,需要改变位置的都是离那台主机最近的那些缓存,其他换成不需要改变位置。从而避免当服务器数量发生变化时，会产生缓存的雪崩。(如果使用之前的算法，服务器数量发生改变时，所有服务器的所有缓存在同一时间失效了，而使用一致性哈希算法时，服务器的数量如果发生改变，并不是所有缓存都会失效，而是只有部分会失效，而不至于所有压力都在同一时间集中到后端服务器上。) hash环的偏斜在介绍一致性哈希的概念时，我们理想化的将3台服务器均匀的映射到了hash环上但是，理想很丰满，现实很骨感，我们想象的与实际情况往往不一样。在实际的映射中，服务器可能会被映射成如下模样。如果服务器被映射成上图中的模样，那么被缓存的对象很有可能大部分集中缓存在某一台服务器上。如果出现上图中的情况，A、B、台服务器并没有被合理的平均的充分利用，缓存分布的极度不均匀，而且，如果此时服务器A出现故障，那么失效缓存的数量也将达到最大值，在极端情况下，仍然有可能引统的崩溃，上图中的情况则被称之为hash环的偏斜，那么，我们应该怎样防止hash环的偏斜呢？一致性hash算法中使用”虚拟节点“解决了这个问题 虚拟节点如果想要均衡的将缓存分布到3台服务器上，最好能让这3台服务器尽量多的、均匀的出现在hash环上，但是，真实的服务器资源只有3台，我样凭空的让它们多起来呢，没错，就是凭空的让服务器节点多起来，既然没有多余的真正的物理服务器节点，我们就只能将现有的物理节点通过虚拟的方法复制出来，这些由节点虚拟复制而来的节点被称为”虚拟节点”。加入虚拟节点以后的hash环如下。在一致性哈希算法中，为了尽可能的满足平衡性，其引入了虚拟节点。“虚拟节点(virtual node )”是实际节点（实际的物理服务器）在hash环上的复制品,一个实际节点可以对应多个虚拟节点。从上图可以看出，A、B、C三台服务器分别虚拟出了一个虚拟节点，当然，如果你需要，也可以虚拟出更多的虚拟节点。引入虚拟节点的概念后，缓存的分布就均衡多了，上中，1号、3号图片被缓存在服务器A中，5号、4号图片被缓存在服务器B中，6号、2号图片被缓存在服务器C中，如果你还不放心，可以虚拟出更多的虚拟节点，以便减小hash偏斜所带来的影响，虚拟节点越多，hash环上的节点就越多，缓存被均匀分布的概率就越大。 通过虚拟节点的引入，对象的分布就比较均衡了。那么在实际操作中，正真的对象查询是如何工作的呢？对象从hash到虚拟节点到实际节点的转换如下图：“虚拟节点”的hash计算可以采用对应节点的IP地址加数字后缀的方式。例如假设NODE1的IP地址为192.168.1.100。引入“虚拟节点”前，计算 cache A 的 hash 值：Hash(“192.168.1.100”);引入“虚拟节点”后，计算“虚拟节”点NODE1-1和NODE1-2的hash值：Hash(“192.168.1.100#1”); // NODE1-1Hash(“192.168.1.100#2”); // NODE1-2 Java实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101import java.util.Collection;import java.util.HashSet;import java.util.Iterator;import java.util.Set;import java.util.SortedMap;import java.util.SortedSet;import java.util.TreeMap;import java.util.TreeSet;public class ConsistentHash&lt;T&gt; &#123; private final HashFunction hashFunction; private final int numberOfReplicas;// 节点的复制因子(100左右比较合理),实际节点个数 * numberOfReplicas =虚拟节点个数 private final SortedMap&lt;Long, T&gt; circle = new TreeMap&lt;Long, T&gt;();// 存储虚拟节点的hash值到真实节点的映射,server节点分布圆 public ConsistentHash(HashFunction hashFunction, int numberOfReplicas, Collection&lt;T&gt; nodes) &#123; this.hashFunction = hashFunction; this.numberOfReplicas = numberOfReplicas; for (T node : nodes) add(node); &#125; public void add(T node) &#123; for (int i = 0; i &lt; numberOfReplicas; i++) // 对于一个实际机器节点 node, 对应 numberOfReplicas 个虚拟节点 /* * 不同的虚拟节点(i不同)有不同的hash值,但都对应同一个实际机器node * 虚拟node一般是均衡分布在环上的,数据存储在顺时针方向的虚拟node上 */ circle.put(hashFunction.hash(node.toString() + i), node); &#125; public void remove(T node) &#123; for (int i = 0; i &lt; numberOfReplicas; i++) circle.remove(hashFunction.hash(node.toString() + i)); &#125; /* * 获得一个最近的顺时针节点,根据给定的key 取Hash * 然后再取得顺时针方向上最近的一个虚拟节点对应的实际节点 * 再从实际节点中取得 数据 */ public T get(Object key) &#123; if (circle.isEmpty()) return null; long hash = hashFunction.hash((String) key);// node 用String来表示,获得node在哈希环中的hashCode if (!circle.containsKey(hash)) &#123;//数据映射在两台虚拟机器所在环之间,就需要按顺时针方向寻找机器 SortedMap&lt;Long, T&gt; tailMap = circle.tailMap(hash); hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey(); &#125; return circle.get(hash); &#125; public long getSize() &#123; return circle.size(); &#125; /* * 查看MD5算法生成的hashCode值---表示整个哈希环中各个虚拟节点位置 */ public void testBalance()&#123; Set&lt;Long&gt; sets = circle.keySet();//获得TreeMap中所有的Key SortedSet&lt;Long&gt; sortedSets= new TreeSet&lt;Long&gt;(sets);//将获得的Key集合排序 for(Long hashCode : sortedSets)&#123; System.out.println(hashCode); &#125; System.out.println(\"----each location 's distance are follows: ----\"); /* * 查看用MD5算法生成的long hashCode 相邻两个hashCode的差值 */ Iterator&lt;Long&gt; it = sortedSets.iterator(); Iterator&lt;Long&gt; it2 = sortedSets.iterator(); if(it2.hasNext()) it2.next(); long keyPre, keyAfter; while(it.hasNext() &amp;&amp; it2.hasNext())&#123; keyPre = it.next(); keyAfter = it2.next(); System.out.println(keyAfter - keyPre); &#125; &#125; public static void main(String[] args) &#123; Set&lt;String&gt; nodes = new HashSet&lt;String&gt;(); nodes.add(\"A\"); nodes.add(\"B\"); nodes.add(\"C\"); ConsistentHash&lt;String&gt; consistentHash = new ConsistentHash&lt;String&gt;(new HashFunction(), 100, nodes); consistentHash.add(\"D\"); System.out.println(\"hash circle size: \" + consistentHash.getSize()); System.out.println(\"location of each node are follows: \"); consistentHash.testBalance(); //根据一致性hash算法获取客户端对应的服务器节点 System.out.println(consistentHash.get(RandomStringUtils.random(12))); &#125; &#125; 哈希函数如下：12345678910111213141516171819202122232425262728import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;/* * 实现一致性哈希算法中使用的哈希函数,使用MD5算法来保证一致性哈希的平衡性 */public class HashFunction &#123; private MessageDigest md5 = null; public long hash(String key) &#123; if (md5 == null) &#123; try &#123; md5 = MessageDigest.getInstance(\"MD5\"); &#125; catch (NoSuchAlgorithmException e) &#123; throw new IllegalStateException(\"no md5 algrithm found\"); &#125; &#125; md5.reset(); md5.update(key.getBytes()); byte[] bKey = md5.digest(); //具体的哈希函数实现细节--每个字节 &amp; 0xFF 再移位 long result = ((long) (bKey[3] &amp; 0xFF) &lt;&lt; 24) | ((long) (bKey[2] &amp; 0xFF) &lt;&lt; 16 | ((long) (bKey[1] &amp; 0xFF) &lt;&lt; 8) | (long) (bKey[0] &amp; 0xFF)); return result &amp; 0xffffffffL; &#125;&#125; 代码片段解释:在具体JAVA实现代码中，定义了一个TreeMap&lt; k, V&gt;用来保存虚拟机器节点到实际的物理机器的映射。机器以字符串形式来标识，故hash函数的参数为String而对于 数据的存储而言，逻辑上是按顺时针方向存储在虚拟机器节点中，虚拟机器节点通过TreeMap知道它实际需要将数据存储在哪台物理机器上。此外，TreeMap中的Key是有序的，而环也是顺时针有序的，这样才能当数据被映射到两台虚拟机器之间的弧上时，通过TreeMap的 tailMap()来寻找顺时针方向上的下一台虚拟机。1234if (!circle.containsKey(hash)) &#123;//数据映射在两台虚拟机器所在环之间,就需要按顺时针方向寻找机器 SortedMap&lt;Long, T&gt; tailMap = circle.tailMap(hash); hash = tailMap.isEmpty() ? circle.firstKey() : tailMap.firstKey(); &#125; 参考:https://www.codeproject.com/Articles/56138/Consistent-hashinghttp://blog.csdn.net/cywosp/article/details/23397179http://www.zsythink.net/archives/1182http://blog.csdn.net/zhangskd/article/details/50256111https://www.cnblogs.com/hapjin/p/4737207.htmlhttp://langyu.iteye.com/blog/684087http://afghl.github.io/2016/11/19/implement-consistent-hashing.htmlhttps://gist.github.com/meigesir/1bf6338787946c18b47d","categories":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/categories/算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://xbynet.top/tags/算法/"}]},{"title":"[读书笔记]chapter4-系统稳定性-大型网站分布式架构与设计实践","slug":"读书笔记-chapter4-系统稳定性-大型网站分布式架构与设计实践","date":"2017-12-17T05:17:13.000Z","updated":"2017-12-18T01:18:47.136Z","comments":true,"path":"2017/12/17/读书笔记-chapter4-系统稳定性-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter4-系统稳定性-大型网站分布式架构与设计实践/","excerpt":"主要内容:常用的日志分析命令，如cat,grep,wc,less,sed,awk等如何进行集群的监控，包括监控指标的定义、心跳检测、容量评估等如何保障高并发系统的稳定运行，如采用流量控制、依赖管理、服务分级、开关等策略。如何优化应用的性能，包括前端优化、Java程序优化、数据库查询优化等如何进行Java应用故障的在线排查，包括一系列排查工具的使用，及案例。 “You can’t control what you can’t measure”“Should you measure something be sure what you really measure otherwise the results can keep you far from reality. Always validate your assumptions and RTFM”“Don’t assumptions base on lack of understanding of used terminology or it’s ambiguity can be accounted for it”","text":"主要内容:常用的日志分析命令，如cat,grep,wc,less,sed,awk等如何进行集群的监控，包括监控指标的定义、心跳检测、容量评估等如何保障高并发系统的稳定运行，如采用流量控制、依赖管理、服务分级、开关等策略。如何优化应用的性能，包括前端优化、Java程序优化、数据库查询优化等如何进行Java应用故障的在线排查，包括一系列排查工具的使用，及案例。 “You can’t control what you can’t measure”“Should you measure something be sure what you really measure otherwise the results can keep you far from reality. Always validate your assumptions and RTFM”“Don’t assumptions base on lack of understanding of used terminology or it’s ambiguity can be accounted for it” 在线日志分析日志包含信息：异常堆栈信息，访问ip，请求url，应用响应时间，内存垃圾回收信息，及程序日志信息。通过对异常堆栈信息分析定位程序bug；对访问ip及url，参数的分析排查是否遭到攻击，及攻击的形式；通过应用的响应时间、垃圾回收及系统load来判断系统负载；通过线程dump，判断是否死锁及现场阻塞的原因；通过应用的GC(Garbage Collection)日志，对系统代码和JVM内存参数今夕优化，减少GC次数与stop the world时间，优化响应时间。 1、日志分析常用命令1234567891011cat 查看文件内容， -n 显示行号；分页查看的有:more/less; head/tail 显示文件头/尾多少行， -n指定行数， 对于tail -f可以实时持续显示最新的行。 sort:对列进行排序，默认按字符排序，-n指定按数字，-r逆序，-k指定列(从1开始)，-t指定列间分隔符(默认空格) wc:字符统计，-l 行数，-c字节数，-L最长行的长度 ，-w单词数 uniq:连续行去重,通常与sort联合使用。-c 显示重复次数，-u只显示不重复的，-d只显示重复的行 grep:字符串查找，-c显示行数, grep支持正则表达式。 find:文件查找 find path -name [filename|print] whereis:定位可执行文件的位置 expr:表达式求值，*需要转义 tar:归档文件 curl:URL访问工具 cut:过滤指定列，-f指定列号，-d指定列分隔符 例子:nginx为例，查看请求的访问量，访问量排名前10的ip地址。这样可以定位是否存在HTTP flood攻击(也称CC攻击).1cat access.log | cut -f1 -d &quot; &quot; | sort | uniq -c | sort -k 1 -n -r |head -10 例子:页面访问量排名前10的url1cat access.log | cut -f4 -d &quot; &quot; | sort | uniq -c | sort -k 1 -n -r |head -10 例子:查看最耗时页面(响应时间最长的url)1cat access.log | sort -k 2 -n -r |head -10 例子:统计404请求的占比(404请求过多，要么就是有恶意攻击者在进行扫描，要么就是系统出问题了，500也是如此。)1export total_line=`wc -l access.log | cut -f1 -d &quot; &quot;` &amp;&amp; export not_found_line=`awk &apos;$6==&apos;404&apos;&#123;print $6&#125;&apos; access.log|wc -l` &amp;&amp; expr $not_found_line \\* 100 / $total_line 2、日志分析脚本sed：流编辑器，一行一行读取，面向行，不会修改文件本身。 set [options] ‘command’ files 将日志中的xxx替换成yahoo输出: sed ‘s/xxx/yahoo/‘ access.log | head -10筛选日志中指定的行输出: sed -n ‘2,6p’ access.log根据正则表达式删除日志中指定的行 sed ‘/qq/d’ access.log支持将command写到文件里再加载执行: sed [options] -f scriptfile files awk:提供一个类似于编程的开放环境，可以自定义文本处理规则，修改和重新组织文件中的内容。awk [option] ‘pattern {action}’ fileawk ‘/google/{print $5,$6}’ access.log | head -10awk ‘length($0)&gt;40{print $3}’ access.log | head -10 $0表示当前行awk ‘{line = sprintf(“method:%s,response:%s”,$3,$7);print line}’ access.log | head -10支持将command写到文件里再加载执行: awk [options] -f scriptfile files 集群监控1、监控指标系统运行的繁忙程度、健康状态，反映在一系列的运行期指标上。理论基础：木桶原理。指标如CPU负载，磁盘IO，内存占用，FullGC，请求QPS过高，网络繁忙，丢包率等。 load: load即特定时间间隔内运行队列中的平均线程数。如果一个线程没有处于IO等待、等待wait、终止等状态时，那么该线程就会处于运行队列中。每个CPU的核都维护了一个运行队列，系统的load主要由运行队列来决定。load值越大说明系统CPU越繁忙。一般来说，只要每个CPU当前的活动现场数不大于3，其负载就可以认为是正常的，如果大于5，则表示负载挺高了，需要采取措施来降低系统负载。top和uptime可以查看系统的load值。执行uptime将会显示出系统的当前时间、上线时间、当前的用户数量以及过去1、5、15分钟内的系统负载。12$ uptime10:52 PM up 1337 days, 7:45, 3 users, load averages: 0.21, 0.24, 0.23 CPU利用率： CPU消耗主要在这几个方面:用户进程，内核进程，中断处理，I/O等待，Nice时间(优先级处理)，丢失时间，空闲等。CPU利用率就是这些时间所占总时间的百分比。top命令查看:123456789top | grep Cpu us — 用户空间占用CPU的百分比。sy — 内核空间占用CPU的百分比。ni — 改变过优先级的进程占用CPU的百分比id — 空闲CPU百分比wa — IO等待占用CPU的百分比hi — 硬中断（Hardware IRQ）占用CPU的百分比si — 软中断（Software Interrupts）占用CPU的百分比 st — 丢失时间(Steal Time),是在硬件虚拟化开始流行后新增的，表示被强制等待虚拟CPU的时间，此时hypervisor正在为另一个虚拟处理器服务。如果st占比较高，则表示当前虚拟机与宿主上的其他虚拟机间的CPU争用较为频繁。 若 %iowait 的值过高，表示硬盘存在I/O瓶颈 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量 若 %idle 的值持续低于 10，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU。 对于多U多核CPU监控，在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况。如果按Shift+H键，则可以按线程来查看CPU消耗情况。这一点对java应用来说很有用。 Linux查看物理CPU个数、核数、逻辑CPU个数123456789# 总核数 = 物理CPU个数 X 每颗物理CPU的核数# 总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数# 查看物理CPU个数cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l# 查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq# 查看逻辑CPU的个数cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l 磁盘剩余空间: df -h 查看磁盘剩余空间du 查看目录和文件的大小，如du -d 1 -h /home/xby , -d指定递归深度 网络traffic: 对于进行负载均衡和反向代理的节点，或作为集群master的节点，对网卡和带宽的要求更高。在某些突发大流量情况下有可能会成为瓶颈。因此关注网络的流量，清楚各节点的阀值和水位也很重要。sar -n DEV 1 1 查看系统网络状态。-n 汇报网络状态，DEV表示查看各个网卡的流量，1表示抽样间隔为1秒1次，后面的1表示抽样总次数。 12345678IFACE：就是网络设备的名称；rxpck/s：每秒钟接收到的包数目txpck/s：每秒钟发送出去的包数目rxbyt/s：每秒钟接收到的字节数txbyt/s：每秒钟发送出去的字节数rxcmp/s：每秒钟接收到的压缩包数目txcmp/s：每秒钟发送出去的压缩包数目txmcst/s：每秒钟接收到的多播包的包数目 如果你使用SOCK关键字，则会针对socket连接进行汇报，例如：123456$ sar -n SOCK 1 3tcpsck：当前正在被使用于TCP的socket数目udpsck：当前正在被使用于UDP的socket数目rawsck：当前正在被使用于RAW的socket数目ip-frag：当前的IP分片的数目如果你使用FULL关键字，相当于DEV、EDEV和SOCK三者的综合。 让sar在某个特定时间结束12sar 1 0 -e 15:00:00 &gt; data.txt //每隔1秒记录CPU的使用情况，直到15点，数据将保存到data.txt文件中。(-e 参数表示结束时间，注意时间格式：必须为hh:mm:ss格式) 磁盘I/O iostat -d -k 查看系统的I/O状况，-d表示查看磁盘使用情况 -k表示kb单位。12345678tps：该设备每秒的传输次数（transfers per second）。kB_read/s：每秒从设备（drive expressed）读取的数据量；kB_wrtn/s：每秒向设备（drive expressed）写入的数据量；kB_read：读取的总数据量；kB_wrtn：写入的总数量数据量；这些单位都为Kilobytes。 await表示平均每次设备I/O操作的等待时间（以毫秒为单位）。 svctm表示平均每次设备I/O操作的服务时间（以毫秒为单位）。%util表示一秒中有百分之几的时间用于I/O操作。 对以磁盘IO性能，一般有如下评判标准：正常情况下svctm应该是小于await值的，而svctm的大小和磁盘性能有关，CPU、内存的负荷也会对svctm值造成影响，过多的请求也会间接的导致svctm值的增加。await值的大小一般取决与svctm的值和I/O队列长度以及I/O请求模式，如果svctm的值与await很接近，表示几乎没有I/O等待，磁盘性能很好，如果await的值远高于svctm的值，则表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。%util项的值也是衡量磁盘I/O的一个重要指标，如果%util接近100%，表示磁盘产生的I/O请求太多，I/O系统已经满负荷的在工作，该磁盘可能存在瓶颈。长期下去，势必影响系统的性能，可以通过优化程序或者通过更换更高、更快的磁盘来解决此问题。 内存使用:free -m 可用内存=free+buffers+cached123456789101112131415161718[root@nonamelinux ~]# free total used free shared buffers cachedMem: 386024 377116 8908 0 21280 155468-/+ buffers/cache: 200368 185656Swap: 393552 0 393552第二行(mem)：total:总计物理内存的大小。used:已使用多大。free:可用有多少。Shared:多个进程共享的内存总额。Buffers/cached:缓存的大小。第三行(-/+ buffers/cached):used:已使用多大。free:可用有多少。第二行(mem)的used/free与第三行(-/+ buffers/cache) used/free的区别。这两个的区别在于使用的角度来看，第一行是从OS的角度来看，因为对于OS，buffers/cached 都是属于被使用，所以他的可用内存是8908KB,已用内存是377116KB,其中包括，内核（OS）使用+Application(X,oracle,etc)使用的+buffers+cached.第三行所指的是从应用程序角度来看，对于应用程序来说，buffers/cached 是等于可用的，因为buffer/cached是为了提高文件读取的性能，当应用程序需在用到内存的时候，buffer/cached会很快地被回收。所以从应用程序的角度来说，可用内存=free+buffers+cached 使用vmstat查看swap I/O的情况,确保swap I/O较低。否则会严重影响系统性能。 QPS-query per second. 每秒的查询数： qps在很大程度上代表了系统在业务上的繁忙程度，而每次请求的背后，可能对应着多次磁盘io，多次网络请求，以及多个cpu时间片。通过关注qps是否超过阀值，来决定是否进行扩容，以避免压力过大而宕机。 RT-response time 响应时间: rt是一个非常关键的指标，直接关系到前端用户的体验。因此需要尽可能降低rt。例如，通过CDN缩短用户请求的物理路径，通过内容压缩来减少传输的字节数，使用缓存来减少磁盘io和网络请求等。而通过nginx的access log ，便可以得知每个请求的响应时间。不过需要在访问日志的输出格式中加上$request_time变量。 数据库相关指标select/ps,update/ps,delete/ps. 措施:增加读库，分库分表等。 GC:对于Java应用而言，不得不关注GC。GC又分为Minor GC与Full GC.在JVM内存分代回收的情况下，对象在JVM内存的新生代Eden区中分配。当Eden区没有足够的空间时虚拟机将发起一次MinorGC，该GC发生在新生代，而且也会比较频繁，回收速度也很快。而Major GC,也称Full GC,是发生在年老代的，速度比MinorGC慢得多，因此导致应用停顿时间(stop the world)也就更长。可以对JVM的一些内存参数进行调整和优化，以降低GC时应用停止响应的时间。如果一个应用频繁进行Full GC，那么它的性能肯定是有问题的。这时候就需要我们实时获取GC情况。 2、心跳检测对于集群服务器和部署于其上的应用的心跳检测是必不可少的，因为这可以帮助我们及时感知问题。对于自治的分布式系统而言，一般都有一整套的集群心跳检测机制，能够实时地移除掉宕机的Slave，避免路由规则再次分配到它。如果是Master宕机，集群也能够自动进行Master选举。如Zookeeper.也有一部分系统如MySQL,Nginx，可以通过外部干预，使备份机器stand by，或是双机互为备份，以实现故障切换，避免单点故障。ping 是最常用的心跳检测方法。 -c 指定执行次数应用层检测：虽然ping可以检测网络是否畅通，但是对于应用层而言，即使网络畅通，也有可能出现问题，如频繁FullGC导致应用不能响应等。应用可以开放一个自检接口，我们可以通过脚本curl去请求自检接口，来达到心跳检测的目的。 curl -s选项为静默模式。 3、容量评估和应用水位 新系统上线之前或者已上线运行的系统上需要做一些推广活动时，相关的业务方需要对系统的访问量进行评估。业务方给出PV,UV预估，然后我们再逐一细化，推导出落到每一个独立的系统，接口上的流量大概是多少，这样一来，每个子系统所承载的量也就清晰了。然后再评估机器的数量，网络的带宽和技术实现方式。压力测试最关系的是qps和rt两个指标在进行系统峰值评估时，一般会遵循80/20原则。我们也可以通过水位图来了解系统的压力。当前水位=当前总qps/(单台机器极限qpsx机器数)x100% 流量控制为了防止某些热点事件或者推广活动导致的访问量激增的情况，需要做好流量控制，在流量到来之前，指定相应的应急预案，以避免系统被激增的流量压垮。流量控制可以从多个维度来进行，如系统的总并发请求数限制，或者限制单位时间内的请求次数(如限制qps)，或者通过白名单机制来限制每一个接入系统调用的频率等。流控实现，最简单的是基于java的信号量Semaphore,更高级点的是采用漏桶或令牌桶算法，guava中有个RetaLimiter实现了令牌桶算法。还有种方式，就是将消息异步化，扔到消息队列后不管，直接返回响应给用户。如基于ActiveMQ,不过需要考虑消息积压，事务消息，重复投递去重等问题。 服务稳定性：分布式SOA环境下系统的依赖错综复杂。如何控制由于第三方服务不稳定而形成的多米诺骨牌效应。1、依赖管理：分布式系统由于高度解耦，最终形成一个网状的依赖关系。对于服务提供者而言，它必须轻蹙，谁调用了自己，调用的频次怎样，这样才能知道当前系统的压力和水位在一个怎样的层次上，是否需要进行扩容。同时，服务提供者也需要对自己依赖的服务了然于胸，哪些是核心链路所依赖的服务，哪些是非核心链路的依赖，以便依赖的系统出现问题时，及时进行服务降级,避免因非核心依赖导致的故障传导，影响当前系统的稳定性。分布式依赖管理的依据：通过调用日志的收集和整理，将其中的调用关系，频次统计分析出来. 2、优雅降级通过依赖管理，我们知道了服务间的调用关系。接下来，我们便可以根据当前系统所依赖的服务及系统流程，来判断依赖的服务是否会影响应用的主流程，以此来决定当前应用依赖的优先级。当依赖的服务出现不稳定，响应缓慢或者掉调用超时，宕机等时，当前系统需要能够及时感知并进行相应处理，否则大量超时的调用，有可能将当前系统的线程和可用连接数用完，导致新的请求进不来，服务僵死，这便是故障传递。最终形成多米诺骨牌效应。使得整个集群都不能对外提供服务。这时服务调用优雅降级的重要性便体现出来了。对于调用超时的非核心服务，可以设定一个阀值，如果调用超时的次数超过这个阀值，便自动将该服务降级。此时跳过对该服务的调用，并指定一个休眠的时间点进行重试。 3、服务分级服务提供者需要对服务消费者的优先级进行区分，哪些调用将影响核心链路，哪些调用是非核心链路，当系统压力过大时，必须确保等级高的应用、核心的调用链路优先畅通，而其他的可以暂时”丢车保帅”。 4、开关系统需要预先定义一些开关来控制程序的服务提供策略。 5、应急方案应急方案需要明确地规定服务的级别，梳理清楚核心应用的调用链路，对于每一种故障，都做出合理的假设，并且要有针对性的处理方法。对于级别低的调用和功能，事先应准备好屏蔽的开关和接口。服务的级别决定哪些调用者是”车”，哪些调用者是”帅”，必要时候要丢车保帅。备用扩容，开关，验证码，流控，负载均衡策略动态修改，多机房部署，异地容灾等 高并发系统设计高并发系统设计与普通系统设计的区别在于，既要保障系统的可用性和可扩展性，又要兼顾数据的一致性。还要处理多线程同步的问题。任何细微问题，都有可能在高并发环境下被无限放大，直至系统宕机。 1、操作原子性：线程锁，CAS(CompareAndSet) Atomic类,数据库事务操作(ACID,Atomic,Consistency,Isolation,Durability)2、数据一致性:分布式系统常常通过复制数据来提高系统的可靠性和容错性，并且将数据的副本放到不同的机器上。由于多个副本的存在，使得维护副本一致性的代价很高。因此许多分布式系统都采用弱一致性或者是最终一致性，来提高系统的性能和吞吐能力，所以出现了不同的一致性模型和算法。 强一致性要求无论数据的更新操作是在哪个副本上执行，之后所有的读操作都要能够获取到更新的最新数据。这种情况下需要通过分布式事务来保证操作的原子性，并且外界无法读到系统的中间状态。 弱一致性指的是系统的某个数据被更新后，后续对该数据的读取操作取到的可能是更新前的值，也可能是更新后的值。全部用户完全读取到更新后的数据需要经过一段时间，这段时间称为”不一致性窗口”。 最终一致性是弱一致性的特殊形式，与弱一致性的区别就是”不一致性窗口”的时间依赖于网络的延迟、系统的负载、副本的个数。 分布式系统采用最终一致性的例子很多，如MySQL的主从数据同步，ZooKeeper的Leader election和Atomic broadcast等。 3、系统可扩展性/可伸缩性 是一种对软件系统计算处理能力的评价指标。高可扩展性意味着系统只要经过很少的改动，甚至只需要添加硬件设备，便能够实现整个系统处理能力的线性增长。由于单台机器硬件受制于科技发展水平和成本，因此，可扩展性更加侧重于系统的水平扩展。设计好的系统可以限制扩展。系统的可扩展性也会受到一些因素的制约，CAP理论(Consistency,Availability,Tolerance of network Partition)指出，系统的一致性、可用性和可扩展性这三个要素对于分布式系统来说，很难同时满足。因此在设计过程中需要进行一些取舍。某些情况下可以放宽对于一致性的严格要求，以使得系统更易于扩展，可靠性更高。 4、例子：并发减库存采用图像验证码防止机器请求(现在图像识别，打码平台的出现，对验证码的要求更高了，不然很容易被绕过)对于高并发访问的浏览型系统来说，单机数据库如不进行扩展，往往很难支撑。因此常常会采用分库技术来提高数据库的并发能力，并通过分布式缓存技术，降低磁盘io及数据库压力，加快后端的响应速度，qps也就越高。使用分库和缓存技术，吞吐量的确是上去了，但是却带来了跨数据库或者是分布式缓存与数据库之间难以进行事务操作。(分布式事务实现所需付出的性能代价太高)为了避免数据不一致的情况发生，可采用实际库存和浏览库存分离的方式。浏览库存取缓存数据。MySQL的myisam对写操作采用表锁，innodb则是行锁。但即便是行锁缩小了粒度，仍然在高并发修改某一行的情况下可能会出现性能瓶颈，此时我们需要拆行，将原本一行的存储，放在多行上，路由策略可以采用用户id取模等方式。 性能优化如何找到性能瓶颈Web的性能优化涉及前端优化、服务端优化、操作系统优化、数据库查询优化、JVM调优等。对于性能优化来说，第一步也是最重要的一步，便是寻找可以优化的点，即性能瓶颈。根据木桶原理，性能瓶颈就是那块最短的木板。 1、前端优化工具-YSlow：网页性能分析2、页面响应时间：这个受影响因素会很多，不能作为最终的依据。我们更关注服务端的RT(response time)时间。3、方法响应时间：定位到响应慢的请求以后，接下来需要深入发掘导致请求响应慢的原因，并且定位到具体的代码。通过对代码的检查分析，能够定位到具体的方法和代码行。不过我们一般借助于btrace——java动态跟踪工具来快速定位和发现耗时的方法。首先，编写一段测试代码：12345678910@Overrideprotected void doPost(HttpServletRequest req,HttpServletResponse resp) throws ServletException,IOException&#123; PrintWriter out=resp.getWriter(); try&#123; Thread.sleep(500L);//通过休眠模拟执行时间较长的方法 &#125;catch(InterruptException e)&#123; &#125; out.write(\"success\");&#125; 然后，编写计算方法响应的btrace脚本123456789101112131415161718192021import com.sun.btrace.annotations.*;import static com.sun.btrace.BTraceUtils.*;@BTracepublic class MethodTimeCost&#123; @TLS private static long starttime; @OnMethod(clazz=\"/com\\\\.http\\\\.testbtrace\\\\..*/\",method=\"/.+/\",location=@Location(Kind.ENTRY)) public static void startExecute()&#123; starttime=timeMillis(); &#125; @OnMethod(clazz=\"/com\\\\.http\\\\.testbtrace\\\\..*/\",method=\"/.+/\",location=@Location(Kind.RETURN)) public static void endExecute()&#123; long timecost=timeMillis()-starttime; if(timecost&gt;50)&#123; print(strcat(strcat(name(probeClass()),\".\"),probeMethod())); print(\" [\"); print(strcat(\"Time taken: \",str(timecost))); println(\"] \"); &#125; &#125;&#125; 启动需要跟踪的java程序，然后执行jps获取该进程的id，最后执行这段btrace脚本。如id为3683。1btrace -cp build 3683 MethodTimeCost.java 当然btrace的使用并不局限于此，它的功能十分强大，特别是在Java应用在线故障排查方面，是不可或缺的利器。 4、GC日志分析GC日志能够反映出Java应用执行内存回收详细情况，如Minor GC,Full GC的频繁程度、GC所导致应用停止响应的时间，引起GC的原因等。根据程序吞吐量优先还是响应时间优先的不同，sun HotSpot虚拟机1.6版在服务器端提供Parallel Scavenge/Parallel Old与ParNew/CMS两种垃圾收集器组合，其中Parallel Scavenge和ParNew为新生代的垃圾收集器，而Parallel Old和CMS为老年带的垃圾收集器。在JVM启动时加上下面几个参数：-verbose:gc -Xloggc:/gc.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps其他GC日志相关参数有-XX:+PrintGC 输出GC日志 -XX:+PrintHeapAtGC 在进行GC的前后打印出堆的信息日志示例：1234560.756: [Full GC (System) 0.756: [CMS: 0K-&gt;1696K(204800K), 0.0347096 secs] 11488K-&gt;1696K(252608K), [CMS Perm : 10328K-&gt;10320K(131072K)], 0.0347949 secs] [Times: user=0.06 sys=0.00, real=0.05 secs] 1.728: [GC 1.728: [ParNew: 38272K-&gt;2323K(47808K), 0.0092276 secs] 39968K-&gt;4019K(252608K), 0.0093169 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 2.642: [GC 2.643: [ParNew: 40595K-&gt;3685K(47808K), 0.0075343 secs] 42291K-&gt;5381K(252608K), 0.0075972 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 4.349: [GC 4.349: [ParNew: 41957K-&gt;5024K(47808K), 0.0106558 secs] 43653K-&gt;6720K(252608K), 0.0107390 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 5.617: [GC 5.617: [ParNew: 43296K-&gt;7006K(47808K), 0.0136826 secs] 44992K-&gt;8702K(252608K), 0.0137904 secs] [Times: user=0.03 sys=0.00, real=0.02 secs] 7.429: [GC 7.429: [ParNew: 45278K-&gt;6723K(47808K), 0.0251993 secs] 46974K-&gt;10551K(252608K), 0.0252421 secs] 我们取倒数第二条记录分析一下各个字段都代表了什么含义15.617（时间戳）: [ GC（Young GC） 5.617（时间戳）: [ParNew（使用ParNew作为年轻代的垃圾回收期）: 43296K（年轻代垃圾回收前的大小）- &gt;7006K（年轻代垃圾回收以后的大小）(47808K)（年轻代的总大小）, 0.0136826 secs（回收时间）] 44992K（堆区垃圾回收前的大小）-&gt;8702K（堆区垃圾回收后的大小）(252608K)（堆区总大小）, 0.0137904 secs（回收时间）] [ Times: user=0.03（Young GC用户耗时） sys=0.00（Young GC系统耗时）, real=0.02 secs（Young GC实际耗时）] 我们再对数据做一个简单的分析从最后一条GC记录中我们可以看到 Young GC回收了 45278-6723=38555K的内存Heap区通过这次回收总共减少了 46974-10551=36423K的内存。38555-36423=2132K说明通过该次Young GC有2132K的内存被移动到了Old Gen， 我们来验证一下在最后一次Young GC的回收以前 Old Gen的大小为8702-7006=1696回收以后Old Gen的内存使用为10551-6723=3828Old Gen在该次Young GC以后内存增加了3828-1696=2132K 与预计的相符 CMS(Concurrent Mark-Sweep)是以牺牲吞吐量为代价来获得最短回收停顿时间的垃圾回收器。对于要求服务器响应速度的应用上，这种垃圾回收器非常适合。在启动JVM参数加上-XX:+UseConcMarkSweepGC (默认HotSpot JVM使用的是并行收集器)，这个参数表示对于老年代的回收采用CMS。CMS采用的基础算法是：标记—清除。整个过程大致分为4步： 初始标记 (CMS initial mark):会STW(Stop The World),为了收集应用程序的对象引用需要暂停应用程序线程,该阶段完成后，应用程序线程再次启动 并发标记 (CMS concurrent mark):从第一阶段收集到的对象引用开始，遍历所有其他的对象引用 重新标记 (CMS remark) :会STW,由于对象引用可能会发生进一步改变，因此应用程序线程会再一次被暂停以更新这些变化,并且在进行实际的清理之前确保一个正确的对象引用视图 并发清理 (CMS concurrent sweep) :所有不再被引用的对象将从堆里清除掉整个过程中，1、3会stw，但是2、4是最耗时的。所以可以减少stw的时间。 注意：一次CMS至少会给Full GC的次数 + 2，因为Full GC的次数是按照老年代GC时stop the world的次数而定的。一般CMS引起的GC时间会很短如ms级，如果达到秒级，那么就需要注意了，很可能是CMS发生了concurrent mode fail之后会退化成Serial Old收集器，它是单线程的标记-压缩收集器，所以耗时会非常的长。查看日志时需要注意是否存在concurrent mode fail 123456789101112132014-12-08T17:24:18.514+0800: 77443.326: [GC [1 CMS-initial-mark: 1382782K(1843200K)] 1978934K(4710400K), 0.0702700 secs] [Times: user=0.07 sys=0.00, real=0.07 secs]2014-12-08T17:24:18.586+0800: 77443.398: [CMS-concurrent-mark-start] 2014-12-08T17:24:19.890+0800: 77444.702: [CMS-concurrent-mark: 1.206/1.303 secs] [Times: user=2.80 sys=0.07, real=1.30 secs] 2014-12-08T17:24:19.890+0800: 77444.702: [CMS-concurrent-preclean-start] 2014-12-08T17:24:19.906+0800: 77444.718: [CMS-concurrent-preclean: 0.015/0.015 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] 2014-12-08T17:24:19.906+0800: 77444.718: [CMS-concurrent-abortable-preclean-start] CMS: abort preclean due to time 2014-12-08T17:24:25.181+0800: 77449.993: [CMS-concurrent-abortable-preclean: 5.241/5.275 secs] [Times: user=6.03 sys=0.09, real=5.27 secs] 2014-12-08T17:24:25.187+0800: 77449.999: [GC[YG occupancy: 749244 K (2867200 K)]77450.000: [Rescan (parallel) , 0.0276780 secs]77450.028: [weak refs processing, 0.2029030 secs] [1 CMS-remark: 1382782K(1843200K)] 2132027K(4710400K), 0.2340660 secs] [Times: user=0.43 sys=0.00, real=0.23 secs2014-12-08T17:24:25.424+0800: 77450.236: [CMS-concurrent-sweep-start] 2014-12-08T17:24:27.420+0800: 77452.232: [CMS-concurrent-sweep: 1.918/1.996 secs] [Times: user=2.61 sys=0.05, real=2.00 secs] 2014-12-08T17:24:27.421+0800: 77452.233: [CMS-concurrent-reset-start] 2014-12-08T17:24:27.430+0800: 77452.242: [CMS-concurrent-reset: 0.010/0.010 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 我们可以看到Full GC的次数应该是2,(因为Full GC的次数是按照老年代GC时stop the world的次数而定的):0.07 secs(initial mark),0.23 secs(remark).可以用jstat -gc得到的时间Full GC的次数和时间。 最后再次强调一下: Full GC == Major GC指的是对老年代/永久代的stop the world的GC Full GC的次数 = 老年代GC时 stop the world的次数 Full GC的时间 = 老年代GC时 stop the world的总时间 CMS 不等于Full GC，我们可以看到CMS分为多个阶段，只有stop the world的阶段被计算到了Full GC的次数和时间，而和业务线程并发的GC的次数和时间则不被认为是Full GC Full GC本身不会先进行Minor GC，我们可以配置，让Full GC之前先进行一次Minor GC，因为老年代很多对象都会引用到新生代的对象，先进行一次Minor GC可以提高老年代GC的速度。比如老年代使用CMS时，设置CMSScavengeBeforeRemark优化，让CMS remark之前先进行一次Minor GC。 最后要重点注意的是：jstat命令的man-pages说FGC代表的是Full GC事件，而我们通常认为那就是是Full GC的次数。CMS GC参考:https://kamilszymanski.github.io/interpreting-jstats-number-of-full-gc-events/http://blog.csdn.net/iter_zc/article/details/41825395http://www.iteye.com/topic/1119491 CMS缺点:CMS回收器采用的基础算法是Mark-Sweep。所有CMS不会整理、压缩堆空间。这样就会有一个问题：经过CMS收集的堆会产生空间碎片。CMS不对堆空间整理压缩节约了垃圾回收的停顿时间，但也带来的堆空间的浪费。为了解决堆空间浪费问题，CMS回收器不再采用简单的指针指向一块可用堆空间来为下次对象分配使用。而是把一些未分配的空间汇总成一个列表，当JVM分配对象空间的时候，会搜索这个列表找到足够大的空间来hold住这个对象。 需要更多的CPU资源。从上面的图可以看到，为了让应用程序不停顿，CMS线程和应用程序线程并发执行，这样就需要有更多的CPU，单纯靠线程切 换是不靠谱的。并且，重新标记阶段，为空保证STW快速完成，也要用到更多的甚至所有的CPU资源。当然，多核多CPU也是未来的趋势！ CMS的另一个缺点是它需要更大的堆空间。因为CMS标记阶段应用程序的线程还是在执行的，那么就会有堆空间继续分配的情况，为了保证在CMS回 收完堆之前还有空间分配给正在运行的应用程序，必须预留一部分空间。也就是说，CMS不会在老年代满的时候才开始收集。相反，它会尝试更早的开始收集，已 避免上面提到的情况：在回收完成之前，堆没有足够空间分配！默认当老年代使用68%的时候，CMS就开始行动了。 – XX:CMSInitiatingOccupancyFraction =n 来设置这个阀值。但是如果在CMS运行期间，预留的内存无法满足程序需要时，则会出现concurrent mode fail之后会退化成Serial Old收集器，它是单线程的标记-压缩收集器，所以耗时会非常的长.总得来说，CMS回收器减少了回收的停顿时间，但是降低了堆空间的利用率。 啥时候用CMS:如果你的应用程序对停顿比较敏感，并且在应用程序运行的时候可以提供更大的内存和更多的CPU(也就是硬件牛逼)，那么使用CMS来收集会给你带来好处。还有，如果在JVM中，有相对较多存活时间较长的对象(老年代比较大)会更适合使用CMS。 问题：minor GC是否也会导致STW呢? https://www.zhihu.com/question/29114369?sort=createdhttps://blogs.oracle.com/jonthecollector/our-collectorshttps://www.zhihu.com/question/21535747/answer/144884632目前所有的新生代gc都是需要STW的，STW总会发生 不管是新生代还是老年代 就算是CMS也有STW的时候。重点是 时间长短Serial：单线程STW，复制算法ParNew：多线程并行STW，复制算法Parallel Scavange：多线程并行STW，吞吐量优先，复制算法G1：多线程并发，可以精确控制STW时间，整理算法因为full gc耗时远高于minor gc，所以通常忽略minor gc几十毫秒的停顿。 GC收集器分类与常见组合：按线程：单线程：Serial、SerialOld多线程：ParNew、Parallel Scavenge、Parallel Old、CMS、G1按适用代：新生代: Serial、ParNew、Parallel Scavenge老年代: SerialOld、CMS 、Parallel OldG1可以在新生代和老年代使用常见的组合ParNew+CMS ； Parallel Scavenge+Parallel Old HotSpot JVM支持哪些垃圾收集器？Hotspot JVM实现包括了Serial GC, Parallel GC, CMS, G1 GC 4套算法组合。下面来讲一讲这些算法组合分别包括了哪些算法。 Serial GC算法：Serial Young GC ＋ Serial Old GC （实际上它是全局范围的Full GC），适用于小程序或低配置计算机系统； Parallel GC算法：（并行的）Parallel Young GC ＋ PS MarkSweep GC / （并行的）Parallel Old GC（全局范围的Full GC），选PS MarkSweep GC 还是 Parallel Old GC 由参数UseParallelOldGC来控制，适用于对吞吐量敏感的应用； CMS算法：（并行的）ParNew（Young）GC + （并发的）CMS（Old）GC （piggyback on ParNew的结果／老生代存活下来的object只做记录，不做compaction）＋ Full GC for CMS算法（应对核心的CMS GC某些时候的不赶趟，开销很大），适用于对延时敏感的应用； G1 GC：（并行的）Young GC ＋（并行的）mixed GC（新生代，再加上部分老生代）＋ Full GC for G1 GC算法（应对G1 GC算法某些时候的不赶趟，开销很大）。G1 GC中开销较大的object marking算法部分是跟applicaiton一起并发的，其开始到结束时间上甚至可以跨越好几次Young GC。适用于延时和吞吐量都有要求的应用，调教相对前述3中GC算法组合为烦。 上述组合描述已特别指出并行（parallel）还是并发（concurrent）。Hotspot JVM语境下，这两个概念是严格区分的。并行是指STW（stop-the-world）状态下的GC算法或部分算法的多线程运行；并发是指非STW状态下GC算法或部分算法跟applicaiton一起分享多个线程来运行。关于G1，可参考:http://www.importnew.com/15311.html http://blog.csdn.net/qq_34280276/article/details/52863551 https://blogs.oracle.com/jonthecollector/our-collectors http://ivywang.iteye.com/blog/2146645 5、数据库查询许多请求响应速度慢的原因，最终都是由于糟糕的数据库查询语句所导致的。如何定位到这些糟糕的查询语句呢？MySQL提供慢查询日志的功能。能够记录下响应时间超过一定阀值(默认10秒)的SQL查询.查看是否启用慢日志: show variables like ‘log_slow_queries’; 查看慢于多少秒的SQL会记录到慢日志中:show variables like ‘long_query_time’;通过配置my.cnf，可以修改满日志的相关配置: 123456[mysqld]port= 3306slow-query-log=ON # 慢查询：确认开启slow-query-log-file=&quot;/var/log/mysql/mysql-slow.log&quot; # 慢查询：日志文件及路径long_query_time = 1 # 慢查询：指定超过1s仍未完成的语句，为执行过慢的语句.默认是10s 测试： 123451.执行一条慢查询SQL语句mysql&gt; select sleep(2);2.查看是否生成慢查询日志ls /usr/local/mysql/data/slow.log如果日志存在，MySQL开启慢查询设置成功！ 6、系统资源的使用：查看CPU当前的利用率和系统的load，查看网卡的流量，查看磁盘IO的密集程度，查看内存的使用等。通过硬件指标来判断资源是否已经达到瓶颈。通过这些指标可以将应用分为CPU密集型、网络密集型、磁盘IO密集型、内存使用密集型等。根据应用的特征来进行机器配置的选型，以便使资源的利用达到最大化。 性能测试工具性能测试是指通过一些自动化的测试工具模拟多种正常、峰值，以及异常负载的条件来对系统的各项性能指标进行测试。在系统上线之前，需要经过一系列的性能测试，以确定系统在各种负载下的性能指标变化，发现系统潜在的一些瓶颈和问题。 1、ab-apache bench，内置于apache http server中。是一款专门用来对HTTP服务器进行性能测试的工具，可以模拟多个并发请求来对服务器进行压力测试，得出服务器在高负载下能够支持的qps及应用的响应时间。 2、Apache JMeter ：功能比ab更强大。在执行性能测试的同时，可以通过一些工具，如jsconsole,VisualVM,来远程实时查看测试机的负载，内存使用，GC等情况。以Tomcat为例，配置JAVA_OPTS： 12CATALINA_OPTS=&quot;$CATALINA_OPTS -Djava.rmi.server.hostname=172.16.18.155 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=18081 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false&quot; 3、HP LoadRunner -商业性能测试工具 4、反向代理引流在分布式环境下，流量真正到达服务器之前，一般会经过负载均衡设备进行转发，通过改变负载均衡的策略，可以改变后端服务器所承受的压力。在新版本发布之前，可以先对少部分机器进行灰度发布，以验证程序的正确性和稳定性，并且通过修改负载均衡策略，可以改变机器所承受的负载，达到对在线机器进行性能基准测试的目的。 5、TCPCopyTCPCopy是网易开源的，它是一款请求复制工具，能够将在线请求复制到测试机器，模拟真实环境，达到程序在不上线的情况下承担线上真是流量的效果。TCPCopy分为client与server，client运行在真实环境的线上服务器之上，用来捕获在线请求数据包，而server运行在测试机上，用来截获响应包，并将响应包的头部信息传递给client，已完成TCP交互。 性能优化措施通过上述方法找到性能瓶颈点之后，就需要对找到的性能瓶颈点进行优化。可以从多个方面入手，如:前端的资源文件，后端的Java程序，数据传输，结果缓存，数据库，JVM的GC，服务器硬件等。1、前端性能优化指标：页面造成的HTTP请求数量，是否使用CDN网络，是否使用压缩。2、Java程序优化单例模式，Future模式，线程池，服务端网络IO模型，减少线程上下文切换，降低锁竞争(使用原子变量，减小锁范围，将独占锁改为读写锁等)，压缩，结果缓存，数据库查询性能优化(合理使用索引，explain分析SQL，反范式设计如冗余存储以减少表关联带来的随机io和全表扫描，MySQL使用查询缓存：查看是否开启缓存:select @@query_cache_type;查看缓存总大小：select @@query_cache_size;查看记录集缓存限制:select @@query_cache_limit; 使用搜索引擎：在分库分表后，无法进行复杂的条件查询，这个时候就需要搜索引擎了。 使用key-value数据库:对于保有海量数据的互联网企业来说，多表的关联查询是非常忌讳的。SQL的功能被很大程度地弱化了。为了达到更大的并发，可以采用NoSQL数据库。 GC优化: JVM在进行垃圾回收时，会导致所有的工作线程暂停(stop the world),GC已成为影响Java应用性能的一个重要因素。查看GC日志中的MinorGC、Full GC的频率，GC导致的停顿时间及GC发生的原因等。需要注意一点的是:如果GC在PermGen上操作，而通常永久代存放的是已被虚拟机加载的类信息，及常量、静态变量、即使编辑器编译后的代码等数据，启动后一般非常稳定，GC回收的内存也十分有限。如果是因为PermGen空间不够而频繁发生FullGC，可能的情况是1，PermGen确实设置得过小，调整-XX:PermSize和-XX:MaxPermSize，2:可能是由于错误的代码导致频繁类加载，需要使用jmap将堆dump下来进行分析。 硬件提升性能:缓存服务器加大内存，磁盘IO密集的选用SSD，CPU密集的增加CPU核数，负载均衡节点注意网卡和带宽。 Java应用故障排查常用工具在进行故障定位时，知识和经验是发现问题的基础，数据是依据，而工具则是运用知识的手段。知识和经验告诉我们怎么去做，而运用工具能帮助我们更加快速地发现和定位问题。1、jps 输出java进程id，并显示其主类。选项： -q 只输出进程id -m 输出传递给main函数的参数 -l 输出主类全名，如果是jar，则输出jar文件路径 -v 输出虚拟机进程启动时所带的JVM参数 2、jstat可参考http://blog.csdn.net/zhaozheng7758/article/details/8623549用来对虚拟机各种运行状态进行监控，如查看类加载与卸载情况，管理内存使用和垃圾收集等信息，监视JIT的运行情况等。几乎包括了JVM运行的方方面面。在无法使用图形化工具如jconsole,VisualVM时，jstat成为了运行期定位问题的首选。jstat -options 可列出所有选项常见的有 -class (查看类加载器的统计信息) -compiler (JIT信息) -gc (查看JVM中垃圾收集情况的统计信息，包括Eden区，2个survivor区，老年代，永久代的容量和已用空间，GC时间等) -gccapacity (各区大小) -gccause (最近一次GC统计和原因) -gcnew (新区统计) -gcnewcapacity (新区大小) -gcold (老区统计) -gcoldcapacity (老区大小) -gcpermcapacity (永久区大小) -gcutil (GC统计汇总) -printcompilation (HotSpot编译统计) 1234567891011jstat -gcutil &lt;pid&gt;:统计gc信息显示列名具体描述S0 年轻代中第一个survivor（幸存区）已使用的占当前容量百分比S1 年轻代中第二个survivor（幸存区）已使用的占当前容量百分比E 年轻代中Eden（伊甸园）已使用的占当前容量百分比O old代已使用的占当前容量百分比P perm代已使用的占当前容量百分比YGC 从应用程序启动到采样时年轻代中gc次数YGCT 从应用程序启动到采样时年轻代中gc所用时间(s)FGC 从应用程序启动到采样时old代(全gc)gc次数FGCT 从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT 从应用程序启动到采样时gc用的总时间(s) 3、jinfo 查看应用程度的配置参数，及打印运行JVM时所制定的JVM参数。比jsp -v能查看未被显式指定的JVM参数的系统默认值。-sysprops选项将虚拟机进程中所指定的System.getProperties()的内容打印出来-flags：查看vm参数 ,如果不指定，则同时包含-sysprops和flags的输出。jinfo还能够在运行期间修改JVM参数，通过使用-flag name=value或者-flag [+|-]name来修改。 4、jstack用来生成虚拟机当前的线程快照信息，线程快照就是当前虚拟机每一个线程正在执行的方法堆栈的集合。主要是为了定位线程长时间没有响应的原因，如线程死锁、网络请求没有设置超时时间而长时间没有返回、死循环、信号量没有释放等，都有可能导致线程长时间停顿。 -F当jstack [-l] pid’没有相应的时候强制打印栈信息 -l长列表. 打印关于锁的附加信息,例如属于java.util.concurrent的ownable synchronizers列表. -m打印java和native c/c++框架的所有栈信息. pid 需要被打印配置信息的java进程id,可以用jps查询. 5、jmap可以输出所有内存中对象的工具。可以用来查看等待回收对象的队列，查看堆的概要信息(包括采用的是哪种GC收集器，堆使用情况，及通过JVM参数指定的各个内存空间的大小等)，甚至可以将VM 中的heap以二进制dump输出成文本，之后便可以通过图形化工具如MAT进行堆分析，内存中有哪些对象，分别占用的空间，以便找到诸如内存泄漏等问题的祸根。需要注意的是，jmap执行堆dump操作时，由于生成的转储文件较大，将耗费大量的系统资源。因此，应避免在系统高位运行时执行该指令，否则有可能造成短时间内系统无法响应的情况。 -heap 打印heap的概要信息，包括使用的回收器类型、堆的配置信息、各内存分代的空间使用情况 -dump:[live,]format=b,file= 使用hprof二进制形式,输出jvm的heap内容到文件=. live子选项是可选的，假如指定live选项,那么只输出活的对象到文件. -finalizerinfo 打印正等候回收的对象的信息. -histo[:live] 打印每个class的实例数目,内存占用,类全名信息. VM的内部类名字开头会加上前缀”*”. 如果live子参数加上后,只统计活的对象数量. -permstat 打印classload和jvm heap永久层的信息. 包含每个classloader的名字,活泼性,地址,父classloader和加载的class数量. 另外,内部String的数量和占用内存数也会打印出来. -F 当JVM对-dump操作没有响应时，强制生成转储快照。 -J 传递参数给jmap启动的jvm. 6、BTrace可参考：http://mgoann.iteye.com/blog/1409667 http://www.jianshu.com/p/93e94b724476BTrace是一个开源的Java程序动态跟踪工具，前面已介绍过如何使用它来监控方法的执行时间。它的基本工作原理是通过Hotsopt虚拟机的HotSwap技术将跟踪的代码动态替换到被跟踪的Java程序内，以观察程序运行的细节(BTrace 主要使用了 Instrumentation + ASM技术来实现对正在运行进程的探测。)。如打印方法的参数，变量的值及返回值等。通过使用BTrace，可以在不修改代码、不重启应用的情况下，动态地查看程序运行的细节，方便地对程序进行调试。 123456789101112131415161718192021222324原方法：priavte int sub(int a,int b)&#123; return a+b;&#125;import com.sun.btrace.annotations.*;import static com.sun.btrace.BTraceUtils.*;btrace脚本：@BTracepublic class MethodTimeCost&#123; @TLS private static long starttime; @OnMethod(clazz=\"net.xby1993.test.Main\", method=\"sub\",location=@Location(Kind.ENTRY)) public static void startExecute()&#123; starttime=timeMillis(); &#125; @OnMethod(clazz=\"net.xby1993.test.Main\", method=\"sub\",location=@Location(Kind.RETURN)) public static void endExecute(@Return int rtn,int a,int b)&#123; long timecost=timeMillis()-starttime; println(strcat(\"a:\",str(a))); println(strcat(\"b:\",str(b))); println(strcat(\"return:\",str(rtn))); println(strcat(\"costtime:\",str(timecost))); &#125;&#125; 12btrace &lt; pid &gt; &lt; btrace-script &gt;btrace 3050 MethodTimeCost.java 值得注意的是，@TLS声明的变量是 ThreadLocal的， 每个线程都会有一份这个自己的startTime 变量。 btrace还提供了一个vaisualvm上的一个插件，可以执行btrace脚本。尝试了下，可以attach到本机的jvm进程上，但是远程主机的JVM进程不行。有的说通过端口转发绑定的方式可以，但是还是没有试出来。运行jvisualvm.exe, 选择工具-&gt;插件-&gt;可用插件 选择 BTrace Workbench进行在线安装。 选择需要监控的进程,右击 trace application,在btrace的工作台中直接编写脚本并执行,执行后，当被监控的程序运行了这些检查点的方法时，btrace会在控制台对执行时间进行输出。 注解说明： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@BTrace声明这个类是个BTrace脚本.unsafe参数表示是否不安全的模式执行.方法annotation@OnMethod: 声明 探查点（probe point）clazz: 全路径类名，支持正则表达式，格式为/正则表达式/+类名 匹配子类@前缀 匹配anotation声明的类method: 方法名，支持正则表达式，格式为/正则表达式/， anotation使用@location: 用@Location来表明在什么时候时候去执行脚本Kind.ENTRY 进入方法时Kind.RETURN 方法返回时Kind.THROW 抛出异常时Kind.ARRAY_SET 设置数组元素时Kind.ARRAY_GET 获取数组元素时Kind.NEWARRAY 创建新数组时Kind.NEW 创建新对象时Kind.CALL 调用方法时Kind.CATCH 捕获异常时Kind.FIELD_SET 获取对象属性时Kind.FIELD_SET 设置对象属性时Kind.ERROR 方法由于发生未被捕获的异常结束时Kind.SYNC_ENTRY 进入同步块时Kind.SYNC_EXIT 离开同步块时type 方法类型， 不含方法名、参数民、异常声明。@OnTimer 定时器，间隔出发动作。参数： 间隔时间，单位毫秒@OnError BTrace代码发生异常时回调@OnExit BTrace代码调用exit来结束探测时回调该注释的方法@OnEvent 接受客户端事件时会回调。目前，当客户端命令上执行Ctrl-C (SIGINT)时会发送一个时间到服务器端，从而触发@OnEvent注释的方法。@OnLowMemory 内存低于设置的阈值时回调方法pool 内存池名称threshold 阈值大小@OnProbe 支持使用xml格式来声明探测点点和探测动作。未声明注解的方法参数未声明注解的方法参数的映射，根据探测点类型locaiton的不同而不同：Kind.ENTRY 方法参数Kind.RETURN 方法返回值Kind.THROW 被抛出的异常Kind.ARRAY_SET 数值下标Kind.ARRAY_GET 数组下标Kind.CATCH 被捕获的异常Kind.FIELD_SET 被设置属性的值Kind.NEW 创建的对象的类型Kind.ERROR 被抛出的异常字段注解Export 将字段保罗给jstat访问Property 将字段暴露注册为MBean 属性，可以通过JMX进行查看TLS 将字段声明为TheadLocal字段，每个线程拥有自己独立的字段参数annotation介绍@Self 声明探测的当前对象this@Return 方法返回对象@ProbeClassName 当前探测点所在的类名@ProbeMethodName 当前探测点所在的方法名fqn 是否获取全路径方法名称fully qualified name (FQN)@Duration 执行时间，单位纳秒，一般同 Kind.RETURN 和 Kind.ERROR 配合使用@TargetInstance 配合 Kind.CALL使用，声明了被调用方法所在的对象@TargetMethodOrField Kind.CALL使用，声明了被调用方法所在的对象的方法 7、JConsole可参考 http://jiajun.iteye.com/blog/810150不过目前推荐使用JVisualVM来替代JConsole 8、JVisualVM可参考：https://www.ibm.com/developerworks/cn/java/j-lo-visualvm/ http://blog.csdn.net/a19881029/article/details/8432368连接：1、本地机器的程序直接可以监听到2、远程机器的程序需要加上JVM参数1234-Dcom.sun.management.jmxremote= true-Dcom.sun.management.jmxremote.port= 9090-Dcom.sun.management.jmxremote.ssl= false-Dcom.sun.management.jmxremote.authenticate= false VisualVM是一款”All-in-One”工具，涵盖了JVM内存监视，性能分析，线程，及堆转储分析、垃圾回收监视等几乎所有功能。常用功能:内存监控，GC监控，应用程序分析，线程分析，堆dump分析，CPU及内存抽样、BTrace跟踪等。 Java VisualVM 插件地址：打开Java VisualVM检查更新插件时，默认的连接连不上，通过浏览器访问之后发现默认的服务器已经404，新地址已经迁移到github，下面这个地址里面有不同版本jdk对应的插件中心地址：https://visualvm.github.io/pluginscenters.html 9、MAT(Memory Analyzer Tool)可参考：http://flychao88.iteye.com/blog/2192266 https://www.ibm.com/developerworks/cn/opensource/os-cn-ecl-ma/一个基于Eclipse的内存分析工具，是一个快速、功能丰富的JAVA heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗。使用内存分析工具从众多的对象中进行分析，快速的计算出在内存中对象的占用大小，看看是谁阻止了垃圾收集器的回收工作，并可以通过报表直观的查看到可能造成这种结果的对象。巧妇难为无米之炊，我们首先需要获得一个堆转储文件。只要你设置了如下所示的 JVM 参数：-XX:+HeapDumpOnOutOfMemoryError JVM 就会在发生内存泄露时抓拍下当时的内存状态，也就是我们想要的堆转储文件。除此之外，还有很多的工具，例如 JMap，JConsole 都可以帮助我们得到一个堆转储文件。 典型案例分析1、内存溢出OutOfMemory测试:1234567891011public class TestOOM&#123; static class Obj&#123; public byte[] bytes=\"hello world\".getBytes(); &#125; public static void main(String[] args)&#123; ArrayList&lt;Obj&gt; list=new ArrayList&lt;&gt;(); while(true)&#123; list.add(new Obj()); &#125; &#125;&#125; 为了尽快出现问题，这里限制堆内存的大小，并在发生OOM时，dump堆。使用的JVM参数如下:-Xms10m -Xmx10m -Xmn5m -XX:+HeapDumpOnOutOfMemoryError 2、线程死锁或信号量没有释放当线程因为资源争用而发生死锁，或者因为使用了信号量而没有及时释放，在测试环境下很难发现该问题，特别是没有进行压力测试就上线的情况下，即便是上线，应用访问量不高，短时间内可能故障也不会发作。这些会导致线程资源耗光(如果采用线程池，此时并不会出现OOM异常，而是表现为请求长时间没有响应，应用僵死)。但是对应的JVM进程却是活跃的，并且此时的系统资源消耗，如CPU的load往往非常低。 这时需要线程dump进行分析。 3、类加载冲突有时候，当使用相同代码的应用发布上线以后，在分布式环境下，会发现一部分机器运行正常，而另一部分机器则会抛出NoClassDefFoundError、NoSuchMethodError这样的异常，这是为何？在一个大型的企业级应用中，可能会依赖很多jar包，而这些jar可能又会依赖其他的jar，最终会导致依赖关系变得错综复杂。有时候，可能会出现依赖一个jar的多个版本，更有甚者，某些jar会直接将依赖的jar也打包进去，这样就使得很多class签名相同的类同时存在。在不同的机器上，对不同jar中同名类的加载有时候并不完全一致。所以才会导致这些问题。那为什么测试时没有问题，因为由于在相同机器上，无论启动多少次，类得加载顺序基本不变。通过在JVM启动时加上-verbose:class,可以查到具体的class究竟是从哪个jar文件中加载进来的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"[读书笔记]chapter3-互联网安全架构-大型网站分布式架构与设计实践","slug":"读书笔记-chapter3-互联网安全架构-大型网站分布式架构与设计实践","date":"2017-12-17T05:03:05.000Z","updated":"2017-12-17T06:38:27.034Z","comments":true,"path":"2017/12/17/读书笔记-chapter3-互联网安全架构-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter3-互联网安全架构-大型网站分布式架构与设计实践/","excerpt":"内容：常见的Web攻击手段和防御方法:如XSS,CSRF,SQL注入等安全算法:如数字摘要，对称加密，非对称加密，数字签名，数字证书等如何采用摘要认证防止信息篡改，通过数字签名来验证通信双方的合法性，及通过Https保证通信过程中数据不被第三方监听和截获。OAuth协议介绍","text":"内容：常见的Web攻击手段和防御方法:如XSS,CSRF,SQL注入等安全算法:如数字摘要，对称加密，非对称加密，数字签名，数字证书等如何采用摘要认证防止信息篡改，通过数字签名来验证通信双方的合法性，及通过Https保证通信过程中数据不被第三方监听和截获。OAuth协议介绍 XSS攻击XSS(Cross-Site Scripting),跨站脚本攻击。防范:Html实体字符转义escapeXml CSRF攻击CSRF(cross site request forgery):跨站请求伪造。举例：CSRF攻击的主要目的是让用户在不知情的情况下攻击自己已登录的一个系统，类似于钓鱼。如用户当前已经登录了邮箱，或bbs，同时用户又在使用另外一个，已经被你控制的站点，我们姑且叫它钓鱼网站。这个网站上面可能因为某个图片吸引你，你去点击一下，此时可能就会触发一个js的点击事件，构造一个bbs发帖的请求，去往你的bbs发帖，由于当前你的浏览器状态已经是登陆状态，所以session登陆cookie信息都会跟正常的请求一样，纯天然的利用当前的登陆状态，让用户在不知情的情况下，帮你发帖或干其他事情。 CSRF防御： 将cookie设置为HttpOnly,这样通过脚本就无法读取到cookie信息。 通过 referer、token 或者 验证码 来检测用户提交。而该token不存在于cookie，而是随着每次响应返回到页面中的，服务端token存在于session中。 尽量不要在页面的链接中暴露用户隐私信息。 对于用户修改删除等操作最好都使用post 操作 。 避免全站通用的cookie，严格设置cookie的域。 SQL注入攻击防范:使用预编译语句；避免密码明文存放；处理好相应异常。 文件上传漏洞防范：对上传的文件进行白名单校验，限制上传文件大小，上传后的文件进行重命名。使用文件的魔数(magic number)来判断文件类型，而不是通过后缀名；对图片文件，可考虑使用imagemagick先缩放再保存。 DDoS攻击DDoS(Distributed Denial of Service)即分布式拒绝服务攻击。http://netsecurity.51cto.com/art/200903/114969.htm先说Dos，DoS攻击是最早出现的,它的攻击方法说白了就是单挑,是比谁的机器性能好、速度快。但是现在的科技飞速发展,一般的网站主机都有十几台主机,而且各个主机的处理能力、内存大小和网络速度都有飞速的发展,有的网络带宽甚至超过了千兆级别。这样我们的一对一单挑式攻击就没有什么作用了,搞不好自己的机子就会死掉。不过,科技在发展,黑客的技术也在发展。DDoS攻击。它的原理说白了就是群殴,用好多的机器对目标机器一起发动DoS攻击,但这不是很多黑客一起参与的,这种攻击只是由一名黑客来操作的。这名黑客不是拥有很多机器,他是通过他的机器在网络上占领很多的“肉鸡”,并且控制这些“肉鸡”来发动DDoS攻击。 DDoS攻击方式： 1、SYN Flood攻击SYN-Flood攻击是当前网络上最为常见的DDoS攻击，也是最为经典的拒绝服务攻击，它利用了TCP协议实现上的一个缺陷，通过向网络服务所在端口发送大量的伪造源地址的攻击报文，就可能造成目标服务器中的半开连接队列被占满，从而阻止其他合法用户进行访问。这种攻击早在1996年就被发现，但至今仍然显示出强大的生命力。很多操作系统，甚至防火墙、路由器都无法有效地防御这种攻击，而且由于它可以方便地伪造源地址，追查起来非常困难。它的数据包特征通常是，源发送了大量的SYN包，并且缺少三次握手的最后一步握手ACK回复。原理例如，攻击者首先伪造地址对服务器发起SYN请求（我可以建立连接吗？），服务器就会回应一个ACK+SYN（可以+请确认）。而真实的IP会认为，我没有发送请求，不作回应。服务器没有收到回应，会重试3-5次并且等待一个SYN Time（一般30秒-2分钟）后，丢弃这个连接。如果攻击者大量发送这种伪造源地址的SYN请求，服务器端将会消耗非常多的资源来处理这种半连接，保存遍历会消耗非常多的CPU时间和内存，何况还要不断对这个列表中的IP进行SYN+ACK的重试。最后的结果是服务器无暇理睬正常的连接请求—拒绝服务。在服务器上用netstat –an命令查看SYN_RECV状态的话 2、ACK Flood攻击ACK Flood攻击是在TCP连接建立之后，所有的数据传输TCP报文都是带有ACK标志位的，主机在接收到一个带有ACK标志位的数据包的时候，需要检查该数据包所表示的连接四元组是否存在，如果存在则检查该数据包所表示的状态是否合法，然后再向应用层传递该数据包。如果在检查中发现该数据包不合法，例如该数据包所指向的目的端口在本机并未开放，则主机操作系统协议栈会回应RST包告诉对方此端口不存在。这里，服务器要做两个动作：查表、回应ACK/RST。这种攻击方式显然没有SYN Flood给服务器带来的冲击大，因此攻击者一定要用大流量ACK小包冲击才会对服务器造成影响。按照我们对TCP协议的理解，随机源IP的ACK小包应该会被Server很快丢弃，因为在服务器的TCP堆栈中没有这些ACK包的状态信息。但是实际上通过测试，发现有一些TCP服务会对ACK Flood比较敏感，比如说JSP Server，在数量并不多的ACK小包的打击下，JSP Server就很难处理正常的连接请求。对于Apache或者IIS来说，10kpps的ACK Flood不构成危胁，但是更高数量的ACK Flood会造成服务器网卡中断频率过高，负载过重而停止响应。可以肯定的是，ACK Flood不但可以危害路由器等网络设备，而且对服务器上的应用有不小的影响。 3、UDP DNS Query Flood攻击原理UDP DNS Query Flood攻击实质上是UDP Flood的一种，但是由于DNS服务器的不可替代的关键作用，一旦服务器瘫痪，影响一般都很大。UDP DNS Query Flood攻击采用的方法是向被攻击的服务器发送大量的域名解析请求，通常请求解析的域名是随机生成或者是网络世界上根本不存在的域名，被攻击的DNS 服务器在接收到域名解析请求的时候首先会在服务器上查找是否有对应的缓存，如果查找不到并且该域名无法直接由服务器解析的时候，DNS 服务器会向其上层DNS服务器递归查询域名信息。域名解析的过程给服务器带来了很大的负载，每秒钟域名解析请求超过一定的数量就会造成DNS服务器解析域名超时。根据微软的统计数据，一台DNS服务器所能承受的动态域名查询的上限是每秒钟9000个请求。而我们知道，在一台P3的PC机上可以轻易地构造出每秒钟几万个域名解析请求，足以使一台硬件配置极高的DNS服务器瘫痪，由此可见DNS 服务器的脆弱性。同时需要注意的是，蠕虫扩散也会带来大量的域名解析请求。 4、CC(Challenge Collapsar)攻击 安全算法12345678public static String toHexString(byte[] b) &#123; StringBuilder sb = new StringBuilder(b.length * 2); for (int i = 0; i &lt; b.length; i++) &#123; sb.append(hexChar[(b[i] &amp; 0xf0) &gt;&gt;&gt; 4]); sb.append(hexChar[b[i] &amp; 0x0f]); &#125; return sb.toString(); &#125; 数字摘要http://www.jb51.net/article/96121.htmhash碰撞:如果待摘要的关键字为k1,Hash函数为f(x),则关键字k1的摘要为f(k1),若关键字k2不等于k1, 而f(k1)=f(k2),这种现象称为hash碰撞。一个hash函数的好坏是由发生碰撞的几率决定的。MD5(Message Digest Algorithm 5)SHA-1(Secure Hash Algorithm) 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.security.MessageDigest; /** * 采用MD5加密 */public class MD5Util &#123; /*** * MD5加密 生成32位md5码 * @param 待加密字符串 * @return 返回32位md5码 */ public static String md5Encode(String inStr) throws Exception &#123; MessageDigest md5 = null; try &#123; md5 = MessageDigest.getInstance(\"MD5\"); &#125; catch (Exception e) &#123; System.out.println(e.toString()); e.printStackTrace(); return \"\"; &#125; byte[] byteArray = inStr.getBytes(\"UTF-8\"); byte[] md5Bytes = md5.digest(byteArray); StringBuffer hexValue = new StringBuffer(); for (int i = 0; i &lt; md5Bytes.length; i++) &#123; int val = ((int) md5Bytes[i]) &amp; 0xff; if (val &lt; 16) &#123; hexValue.append(\"0\"); &#125; hexValue.append(Integer.toHexString(val)); &#125; return hexValue.toString(); &#125; /** * 测试主函数 */ public static void main(String args[]) throws Exception &#123; String str = new String(\"amigoxiexiexingxing\"); System.out.println(\"原始：\" + str); System.out.println(\"MD5后：\" + md5Encode(str)); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 采用SHAA加密 */public class SHAUtil &#123; /*** * SHA加密 生成40位SHA码 * @param 待加密字符串 * @return 返回40位SHA码 */ public static String shaEncode(String inStr) throws Exception &#123; MessageDigest sha = null; try &#123; sha = MessageDigest.getInstance(\"SHA\"); &#125; catch (Exception e) &#123; System.out.println(e.toString()); e.printStackTrace(); return \"\"; &#125; byte[] byteArray = inStr.getBytes(\"UTF-8\"); byte[] md5Bytes = sha.digest(byteArray); StringBuffer hexValue = new StringBuffer(); for (int i = 0; i &lt; md5Bytes.length; i++) &#123; int val = ((int) md5Bytes[i]) &amp; 0xff; if (val &lt; 16) &#123; hexValue.append(\"0\"); &#125; hexValue.append(Integer.toHexString(val)); &#125; return hexValue.toString(); &#125; /** * 测试主函数 */ public static void main(String args[]) throws Exception &#123; String str = new String(\"amigoxiexiexingxing\"); System.out.println(\"原始：\" + str); System.out.println(\"SHA后：\" + shaEncode(str)); &#125;&#125; SHA-1和MD5的比较因为二者均由MD4导出，SHA-1和MD5彼此很相似。相应的，他们的强度和其他特性也是相似，但还有以下几点不同：1）对强行攻击的安全性：最显著和最重要的区别是SHA-1摘要比MD5摘要长32 位。使用强行技术，产生任何一个报文使其摘要等于给定报摘要的难度对MD5是2^128数量级的操作，而对SHA-1则是2^160数量级的操作。这样，SHA-1对强行攻击有更大的强度。2）对密码分析的安全性：由于MD5的设计，易受密码分析的攻击，SHA-1显得不易受这样的攻击。3）速度：在相同的硬件上，SHA-1的运行速度比MD5慢。 彩虹表破解Hash算法：彩虹表预先建立一个可逆向的散列链并将其存储在表中，在破解时先查表得到可能包含结果的散列链，然后在内存中重新计算并得到最终结果。折中方式综合了计算暴力破解和查找表破解的优点，并将计算时间和存储空间降低到可以接受的范围。 对称加密算法http://www.iteye.com/topic/1122076/常用的有:DES,AES等。目前AES是主流。加密：大体上分为双向加密和单向加密，而双向加密又分为对称加密和非对称加密。对称加密 采用单钥密码系统的加密方法，同一个密钥可以同时用作信息的加密和解密，这种加密方法称为对称加密，也称为单密钥加密。需要对加密和解密使用相同密钥的加密算法。由于其速度，对称性加密通常在消息发送方需要加密大量数据时使用。对称性加密也称为密钥加密。所谓对称，就是采用这种加密方法的双方使用方式用同样的密钥进行加密和解密。密钥是控制加密及解密过程的指令。 对称加密一般java类中中定义成员 ：1234567891011121314151617//KeyGenerator 提供对称密钥生成器的功能，支持各种算法 private KeyGenerator keygen; //SecretKey 负责保存对称密钥 private SecretKey deskey; //Cipher负责完成加密或解密工作 private Cipher c; //该字节数组负责保存加密的结果 private byte[] cipherByte; //Security.addProvider(new com.sun.crypto.provider.SunJCE()); //实例化支持DES算法的密钥生成器(算法名称命名需按规定，否则抛出异常) keygen = KeyGenerator.getInstance(\"DES\");// //生成密钥 deskey = keygen.generateKey(); //生成Cipher对象,指定其支持的DES算法 c = Cipher.getInstance(\"DES\"); 1、DES算法为密码体制中的对称密码体制，又被成为美国数据加密标准，是1972年美国IBM公司研制的对称密码体制加密算法。 明文按64位进行分组, 密钥长64位，密钥事实上是56位参与DES运算（第8、16、24、32、40、48、56、64位是校验位， 使得每个密钥都有奇数个1）分组后的明文组和56位的密钥按位替代或交换的方法形成密文组的加密方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class EncrypDES &#123; //KeyGenerator 提供对称密钥生成器的功能，支持各种算法 private KeyGenerator keygen; //SecretKey 负责保存对称密钥 private SecretKey deskey; //Cipher负责完成加密或解密工作 private Cipher c; //该字节数组负责保存加密的结果 private byte[] cipherByte; public EncrypDES() throws NoSuchAlgorithmException, NoSuchPaddingException&#123; Security.addProvider(new com.sun.crypto.provider.SunJCE()); //实例化支持DES算法的密钥生成器(算法名称命名需按规定，否则抛出异常) keygen = KeyGenerator.getInstance(\"DES\"); //生成密钥 deskey = keygen.generateKey(); //生成Cipher对象,指定其支持的DES算法 c = Cipher.getInstance(\"DES\"); &#125; /** * 对字符串加密 */ public byte[] Encrytor(String str) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，ENCRYPT_MODE表示加密模式 c.init(Cipher.ENCRYPT_MODE, deskey); byte[] src = str.getBytes(); // 加密，结果保存进cipherByte cipherByte = c.doFinal(src); return cipherByte; &#125; /** * 对字符串解密 */ public byte[] Decryptor(byte[] buff) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，DECRYPT_MODE表示加密模式 c.init(Cipher.DECRYPT_MODE, deskey); cipherByte = c.doFinal(buff); return cipherByte; &#125; public static void main(String[] args) throws Exception &#123; EncrypDES de1 = new EncrypDES(); String msg =\"郭XX-搞笑相声全集\"; byte[] encontent = de1.Encrytor(msg); byte[] decontent = de1.Decryptor(encontent); System.out.println(\"明文是:\" + msg); System.out.println(\"加密后:\" + new String(encontent)); System.out.println(\"解密后:\" + new String(decontent)); &#125; &#125; 2、AES密码学中的高级加密标准（Advanced Encryption Standard，AES）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 public class EncrypAES &#123; //KeyGenerator 提供对称密钥生成器的功能，支持各种算法 private KeyGenerator keygen; //SecretKey 负责保存对称密钥 private SecretKey deskey; //Cipher负责完成加密或解密工作 private Cipher c; //该字节数组负责保存加密的结果 private byte[] cipherByte; public EncrypAES() throws NoSuchAlgorithmException, NoSuchPaddingException&#123; Security.addProvider(new com.sun.crypto.provider.SunJCE()); //实例化支持DES算法的密钥生成器(算法名称命名需按规定，否则抛出异常) keygen = KeyGenerator.getInstance(\"AES\"); //生成密钥 deskey = keygen.generateKey(); //生成Cipher对象,指定其支持的DES算法 c = Cipher.getInstance(\"AES\"); &#125; /** * 对字符串加密 */ public byte[] Encrytor(String str) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，ENCRYPT_MODE表示加密模式 c.init(Cipher.ENCRYPT_MODE, deskey); byte[] src = str.getBytes(); // 加密，结果保存进cipherByte cipherByte = c.doFinal(src); return cipherByte; &#125; /** * 对字符串解密 */ public byte[] Decryptor(byte[] buff) throws InvalidKeyException, IllegalBlockSizeException, BadPaddingException &#123; // 根据密钥，对Cipher对象进行初始化，DECRYPT_MODE表示加密模式 c.init(Cipher.DECRYPT_MODE, deskey); cipherByte = c.doFinal(buff); return cipherByte; &#125; public static void main(String[] args) throws Exception &#123; EncrypAES de1 = new EncrypAES(); String msg =\"郭XX-搞笑相声全集\"; byte[] encontent = de1.Encrytor(msg); byte[] decontent = de1.Decryptor(encontent); System.out.println(\"明文是:\" + msg); System.out.println(\"加密后:\" + new String(encontent)); System.out.println(\"解密后:\" + new String(decontent)); &#125; &#125; 因为某些国家的进口管制限制，Java发布的运行环境包中的默认仅允许128位密钥的AES加解密 非对称加密与对称加密算法不同，非对称加密算法需要两个密钥：公开密钥（publick ey）和私有密钥 (private key)公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密；如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。RSA算法基于一个十分简单的数论事实：将两个大素数相乘十分容易，但那时想要对其乘积进行因式分解却极其困难，因此可以将乘积公开作为加密密钥。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class EncrypRSA &#123; /** * 加密 */ protected byte[] encrypt(RSAPublicKey publicKey,byte[] srcBytes) throws NoSuchAlgorithmException, NoSuchPaddingException, InvalidKeyException, IllegalBlockSizeException, BadPaddingException&#123; if(publicKey!=null)&#123; //Cipher负责完成加密或解密工作，基于RSA Cipher cipher = Cipher.getInstance(\"RSA\"); //根据公钥，对Cipher对象进行初始化 cipher.init(Cipher.ENCRYPT_MODE, publicKey); byte[] resultBytes = cipher.doFinal(srcBytes); return resultBytes; &#125; return null; &#125; /** * 解密 */ protected byte[] decrypt(RSAPrivateKey privateKey,byte[] srcBytes) throws NoSuchAlgorithmException, NoSuchPaddingException, InvalidKeyException, IllegalBlockSizeException, BadPaddingException&#123; if(privateKey!=null)&#123; //Cipher负责完成加密或解密工作，基于RSA Cipher cipher = Cipher.getInstance(\"RSA\"); //根据公钥，对Cipher对象进行初始化 cipher.init(Cipher.DECRYPT_MODE, privateKey); byte[] resultBytes = cipher.doFinal(srcBytes); return resultBytes; &#125; return null; &#125; public static void main(String[] args) throws NoSuchAlgorithmException, InvalidKeyException, NoSuchPaddingException, IllegalBlockSizeException, BadPaddingException &#123; EncrypRSA rsa = new EncrypRSA(); String msg = \"郭XX-精品相声\"; //KeyPairGenerator类用于生成公钥和私钥对，基于RSA算法生成对象 KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(\"RSA\"); //初始化密钥对生成器，密钥大小为1024位 keyPairGen.initialize(1024); //生成一个密钥对，保存在keyPair中 KeyPair keyPair = keyPairGen.generateKeyPair(); //得到私钥 RSAPrivateKey privateKey = (RSAPrivateKey)keyPair.getPrivate(); //得到公钥 RSAPublicKey publicKey = (RSAPublicKey)keyPair.getPublic(); //用公钥加密 byte[] srcBytes = msg.getBytes(); byte[] resultBytes = rsa.encrypt(publicKey, srcBytes); //用私钥解密 byte[] decBytes = rsa.decrypt(privateKey, resultBytes); System.out.println(\"明文是:\" + msg); System.out.println(\"加密后是:\" + new String(resultBytes)); System.out.println(\"解密后是:\" + new String(decBytes)); &#125; &#125; 数字签名https://www.cnblogs.com/SirSmith/p/4985571.htmlhttp://840327220.iteye.com/blog/2225109数字签名是一种安全措施，分为：消息摘要和消息签名。1、消息摘要：是一种算法，分为MD5/SHA算法，主要作用用来防止消息在传递途中被“第三者”篡改了。2、消息签名：其基础是公钥和私钥的非对称加密。主要作用是验证发消息者的身份，确保消息来源的可靠性。 1234567891011121314151617181920212223242526String password=\"test\"; // 1.初始化密钥 KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(\"RSA\"); keyPairGenerator.initialize(512); KeyPair keyPair = keyPairGenerator.generateKeyPair(); RSAPublicKey rsaPublicKey = (RSAPublicKey)keyPair.getPublic(); RSAPrivateKey rsaPrivateKey = (RSAPrivateKey)keyPair.getPrivate(); // 2.进行签名 PKCS8EncodedKeySpec pkcs8EncodedKeySpec = new PKCS8EncodedKeySpec(rsaPrivateKey.getEncoded()); KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\"); PrivateKey privateKey = keyFactory.generatePrivate(pkcs8EncodedKeySpec); Signature signature = Signature.getInstance(\"MD5withRSA\"); signature.initSign(privateKey); signature.update(password.getBytes()); byte[] result = signature.sign(); //System.out.println(\"jdk rsa sign:\" + Hex.encodeHexString(result) ); // 3.验证签名 X509EncodedKeySpec x509EncodedKeySpec = new X509EncodedKeySpec(rsaPublicKey.getEncoded()); keyFactory = KeyFactory.getInstance(\"RSA\"); PublicKey publicKey = keyFactory.generatePublic(x509EncodedKeySpec); signature = Signature.getInstance(\"MD5withRSA\"); signature.initVerify(publicKey); signature.update(password.getBytes()); boolean bool = signature.verify(result); 数字证书https://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.htmlhttps://www.2cto.com/article/201203/122095.htmlhttp://yale.iteye.com/blog/1675344http://blog.csdn.net/abinge317/article/details/51791856由于网络上通信的双方可能都不认识对方，那么就需要第三者来介绍，这就是数字证书。数字证书由Certificate Authority( CA 认证中心)颁发。 用户A把自己的证书发送给用户B。用户B使用CA的公钥对证书的签名进行验证，由于只有CA才能生成该证书，因此只要证书验证正确，即说明证书是由CA发布的，证书中用户A的公钥是值得信赖的。用户B以后就可以使用该公钥验证用户A的签名或者进行和A进行加密通信。 数字证书为发布公钥提供了一种简便的途径，其数字证书则成为加密算法以及公钥的载体，依靠数字证书，我们可以构建一个简单的加密网络应用平台，数字证书就好比我们生活中的身份证，现实中，身份证由公安机关签发，而网络用户的身份凭证由数字证书颁发认证机构—CA签发，只有经过CA签发的证书在网络中才具备可认证性，CA并不是一个单纯的防御手段，它集合了多种密码学算法： 消息摘要算法：MD5、和SHA（对数字证书本省做摘要处理，用于验证数据完整性服务器） 对称加密算法：RC2、RC4、IDEA、DES、AES（对数据进行加密/解密操作，用于保证数据保密性服务） 非对称加密算法：RSA、DH（对数据进行加密/解密操作，用于保证数据保密性服务） 数字签名算法：RSA、DSA(对数据进行签名/验证操作，保证数据的完整性和抗否认性)。 证书的签发过程实际上是对申请数字证书的公钥做数字签名，证书的验证过程实际上是对数字证书的公钥做验证签名，其中还包含证书有效期验证，通过CA数字证书，我们对网络上传输的数据进行加密/解密和签名/验证操作，确保数据机密性、完整性、抗否认性、认证性，保证交易实体身份的真实性，保证网络安全性。 所有证书有多种文件编码格式，主要包括: CER编码(规范编码格式)：是数字证书的一种编码格式，它是BER(基本编码格式)的一个变种，比BER规定得更严格 DER(卓越编码格式)：同样是BER的一个变种，与CER的不同在于，DER使用定长模式，而CER使用变长模式。所有证书都符合公钥基础设施(PKI)制定的ITU-T X509国际标准，PKCS(公钥加密标准)由RSA实验室和其他安全系统开发商为促进公钥密码的发展而制定的一系列标准，比如:PKCS#7(密码消息语法标准—-文件后缀名:.p7b、.p7c、.spc)、PKCS#10(证书请求语法标准—-文件后缀名:.p10、.csr)、PKCS#12(个人信息交换语法标准—-文件后缀名:.p12、.pfx)等。在获得数字证书后，可以将其保存在电脑中，也可以保存在USB Key等相应的设备中。 一个数字证书的例子1234567891011121314151617181920212223242526272829303132333435363738394041424344Certificate: Data: &lt;span style=&quot;color:#FF0000;&quot;&gt;证书标准版本号&lt;/span&gt; Version: 1 (0x0) &lt;span style=&quot;color:#FF0000;&quot;&gt;该证书的唯一编号&lt;/span&gt; Serial Number: 7829 (0x1e95) &lt;span style=&quot;color:#FF0000;&quot;&gt;该证书的签名算法&lt;/span&gt; Signature Algorithm: md5WithRSAEncryption &lt;span style=&quot;color:#FF0000;&quot;&gt;颁布本证书的证书机构&lt;/span&gt; Issuer: C=ZA, ST=Western Cape, L=Cape Town, O=Thawte Consulting cc, OU=Certification Services Division, CN=Thawte Server CA/emailAddress=server-certs@thawte.com &lt;span style=&quot;color:#FF0000;&quot;&gt;证书有效期&lt;/span&gt; Validity Not Before: Jul 9 16:04:02 1998 GMT Not After : Jul 9 16:04:02 1999 GMT &lt;span style=&quot;color:#FF0000;&quot;&gt;证书持有人的姓名、地址等信息&lt;/span&gt; Subject: C=US, ST=Maryland, L=Pasadena, O=Brent Baccala, OU=FreeSoft, CN=www.freesoft.org/emailAddress=baccala@freesoft.org &lt;span style=&quot;color:#FF0000;&quot;&gt;证书持有人的公钥&lt;/span&gt; Subject Public Key Info: Public Key Algorithm: rsaEncryption RSA Public Key: (1024 bit) Modulus (1024 bit): 00:b4:31:98:0a:c4:bc:62:c1:88:aa:dc:b0:c8:bb: 33:35:19:d5:0c:64:b9:3d:41:b2:96:fc:f3:31:e1: 66:36:d0:8e:56:12:44:ba:75:eb:e8:1c:9c:5b:66: 70:33:52:14:c9:ec:4f:91:51:70:39:de:53:85:17: 16:94:6e:ee:f4:d5:6f:d5:ca:b3:47:5e:1b:0c:7b: c5:cc:2b:6b:c1:90:c3:16:31:0d:bf:7a:c7:47:77: 8f:a0:21:c7:4c:d0:16:65:00:c1:0f:d7:b8:80:e3: d2:75:6b:c1:ea:9e:5c:5c:ea:7d:c1:a1:10:bc:b8: e8:35:1c:9e:27:52:7e:41:8f Exponent: 65537 (0x10001) &lt;span style=&quot;color:#FF0000;&quot;&gt;证书机构对该证书的数字签名&lt;/span&gt; Signature Algorithm: md5WithRSAEncryption 93:5f:8f:5f:c5:af:bf:0a:ab:a5:6d:fb:24:5f:b6:59:5d:9d: 92:2e:4a:1b:8b:ac:7d:99:17:5d:cd:19:f6:ad:ef:63:2f:92: ab:2f:4b:cf:0a:13:90:ee:2c:0e:43:03:be:f6:ea:8e:9c:67: d0:a2:40:03:f7:ef:6a:15:09:79:a9:46:ed:b7:16:1b:41:72: 0d:19:aa:ad:dd:9a:df:ab:97:50:65:f5:5e:85:a6:ef:19:d1: 5a:de:9d:ea:63:cd:cb:cc:6d:5d:01:85:b5:6d:c8:f3:d9:f7: 8f:0e:fc:ba:1f:34:e9:96:6e:6c:cf:f2:ef:9b:bf:de:b5:22: 68:9f 我们先来看一个简单的证书机构签发的流程:这里的认证机构如何是证书申请者本身，将获得自签名证书。当客户端获得服务器下发的数字证书后，即可使用数字证书进行加密交互：数字证书的应用环境是在https安全协议中，使用流程远比上述加密交互流程复杂，但是相关操作封装在传输层，对于应用层透明，在https安全协议中使用非对称加密算法交换密钥，使用对称加密算法对数据进行加密/解密操作，提高加密/解密效率要获得数字证书，我们需要使用数字证书管理工具：KeyTool和OpenSSL构建CSR(数字证书签发申请)，交由CA机构签发，形成最终的数字证书。 SSL/TLS协议分为两层： 记录协议:建议在可靠的传输协议之上，为高层协议提供数据封装、压缩、加密等基本功能的支持 握手协议:建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等经过了SSL/TLS握手协议交互后，数据交互双方确定了本次会话使用的对称加密算法以及密钥，就可以开始进行加密数据交互了，以下是握手协议服务器端和客户端构建加密交互的相关流程图：1、 随机数为后续构建密钥准备2、 其他信息包括服务器证书、甚至包含获取客户端证书的请求3、验证算法如果服务器端回复客户端时带有其他信息，则进入数字证书验证阶段客户端验证服务器端证书：服务器端验证客户端证书:(非金融行业等关键性行业，可选)4、产生密钥当服务器端和客户端经过上述流程后，就开始密钥构建交互了，服务器端和客户端最初需要主密钥为构建会话密钥做准备：5、 会话密钥 (用于对称加密)完成上述主密钥构建操作后，服务器端和客户端将建立会话密钥，完成握手协议：6、加密交互上述服务器端和客户端完成了握手协议以后就进入正式会话阶段，如果上述流程中有任何一端受到外界因素干扰发生异常，则重新进入协商算法阶段，下面流程表现进入会话阶段后，服务器端和客户端将使用会话密钥进行加密交互： 代码解释在JAVA 6 以上版本中提供了完善的数字证书管理的实现，我们不需要关注相关具体算法，仅通过操作密钥库和数字证书就可以完成相应的加密/解密和签名/验证操作，密钥库管理私钥，数字证书管理公钥，私钥和密钥分属消息传递两方，进行加密消息的传递。因此，我们可以将密钥库看做私钥相关操作的入口，数字证书则是公钥相关操作的入口：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234/**** * 获得私钥，获得私钥后，通过RSA算方法实现进行\"私钥加密，公钥解密\"和\"公钥加密，私钥解密\"操作 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 私钥 */ private static PrivateKey getPrivateKeyByKeyStore(String keyStorePath,String alias,String password)throws Exception&#123; //获得密钥库 KeyStore ks = getKeyStore(keyStorePath,password); //获得私钥 return (PrivateKey)ks.getKey(alias, password.toCharArray()); &#125; /**** * 由Certificate获得公钥，获得公钥后，通过RSA算方法实现进行\"私钥加密，公钥解密\"和\"公钥加密，私钥解密\"操作 * @param certificatePath 证书路径 * @return 公钥 */ private static PublicKey getPublicKeyByCertificate(String certificatePath)throws Exception &#123; //获得证书 Certificate certificate = getCertificate(certificatePath); //获得公钥 return certificate.getPublicKey(); &#125; /**** * 加载数字证书，JAVA 6仅支持x.509的数字证书 * @param certificatePath 证书路径 * @return 证书 * @throws Exception */ private static Certificate getCertificate(String certificatePath) throws Exception&#123; //实例化证书工厂 CertificateFactory certificateFactory = CertificateFactory.getInstance(\"x.509\"); //取得证书文件流 FileInputStream in = new FileInputStream(certificatePath); //生成证书 Certificate certificate = certificateFactory.generateCertificate(in); //关闭证书文件流 in.close(); return certificate; &#125; /**** * 获得Certificate * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 证书 * @throws Exception */ private static Certificate getCertificate(String keyStorePath,String alias,String password) throws Exception&#123; //由密钥库获得数字证书构建数字签名对象 //获得密钥库 KeyStore ks = getKeyStore(keyStorePath,password); //获得证书 return ks.getCertificate(alias); &#125; /**** * 加载密钥库，加载了以后，我们就能通过相应的方法获得私钥，也可以获得数字证书 * @param keyStorePath 密钥库路径 * @param password 密码 * @return 密钥库 * @throws Exception */ private static KeyStore getKeyStore(String keyStorePath,String password) throws Exception&#123; //实例化密钥库 KeyStore ks = KeyStore.getInstance(KeyStore.getDefaultType()); //获得密钥库文件流 FileInputStream is = new FileInputStream(keyStorePath); //加载密钥库 ks.load(is,password.toCharArray()); //关闭密钥库文件流 is.close(); return ks; &#125; /**** * 私钥加密 * @param data 待加密的数据 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 加密数据 * @throws Exception */ public static byte[] encryptByPriateKey(byte[] data,String keyStorePath,String alias,String password) throws Exception&#123; //获得私钥 PrivateKey privateKey = getPrivateKeyByKeyStore(keyStorePath,alias,password); //对数据加密 Cipher cipher = Cipher.getInstance(privateKey.getAlgorithm()); return cipher.doFinal(data); &#125; /**** * 私钥解密 * @param data 待解密数据 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 解密数据 * @throws Exception */ public static byte[] decryptByPrivateKey(byte[] data,String keyStorePath,String alias,String password) throws Exception&#123; //取得私钥 PrivateKey privateKey = getPrivateKeyByKeyStore(keyStorePath,alias,password); //对数据解密 Cipher cipher = Cipher.getInstance(privateKey.getAlgorithm()); cipher.init(Cipher.DECRYPT_MODE,privateKey); return cipher.doFinal(data); &#125; /**** * 公钥加密 * @param data 等待加密数据 * @param certificatePath 证书路径 * @return 加密数据 * @throws Exception */ public static byte[] encryptByPublicKey(byte[] data,String certificatePath) throws Exception&#123; //取得公钥 PublicKey publicKey = getPublicKeyByCertificate(certificatePath); //对数据加密 Cipher cipher = Cipher.getInstance(publicKey.getAlgorithm()); cipher.init(Cipher.ENCRYPT_MODE,publicKey); return cipher.doFinal(data); &#125; /**** * 公钥解密 * @param data 等待解密的数据 * @param certificatePath 证书路径 * @return 解密数据 * @throws Exception */ public static byte[] decryptByPublicKey(byte[] data,String certificatePath)throws Exception&#123; //取得公钥 PublicKey publicKey = getPublicKeyByCertificate(certificatePath); //对数据解密 Cipher cipher = Cipher.getInstance(publicKey.getAlgorithm()); cipher.init(Cipher.DECRYPT_MODE, publicKey); return cipher.doFinal(data); &#125; /**** * @param sign 签名 * @param keyStorePath 密钥库路径 * @param alias 别名 * @param password 密码 * @return 签名 * @throws Exception */ public static byte[] sign(byte[] sign,String keyStorePath,String alias,String password)throws Exception&#123; //获得证书 X509Certificate x509Certificate = (X509Certificate) getCertificate(keyStorePath,alias,password); //构建签名,由证书指定签名算法 Signature signature = Signature.getInstance(x509Certificate.getSigAlgName()); //获取私钥 PrivateKey privateKey = getPrivateKeyByKeyStore(keyStorePath,alias,password); //初始化签名，由私钥构建 signature.initSign(privateKey); signature.update(sign); return signature.sign(); &#125; /**** * 验证签名 * @param data 数据 * @param sign 签名 * @param certificatePath 证书路径 * @return 验证通过为真 * @throws Exception */ public static boolean verify(byte[] data,byte[] sign,String certificatePath) throws Exception&#123; //获得证书 X509Certificate x509Certificate = (X509Certificate)getCertificate(certificatePath); //由证书构建签名 Signature signature = Signature.getInstance(x509Certificate.getSigAlgName()); //由证书初始化签名，实际上是使用了证书中的公钥 signature.initVerify(x509Certificate); signature.update(data); return signature.verify(sign); &#125; //我们假定密钥库文件yale.keystore存储在D盘根目录，数字证书文件yale.cer也存储在D盘根目录 /**** * 公钥加密---私钥解密 * @throws Exception */ public static void test1() throws Exception&#123; System.err.println(\"公钥加密---私钥解密\"); String inputStr = \"数字证书\"; byte[] data = inputStr.getBytes(); //公钥加密 byte[] encrypt = CertificateCoder.encryptByPublicKey(data, certificatePath); //私钥解密 byte[] decrypt = CertificateCoder.decryptByPrivateKey(encrypt, keyStorePath, alias, password); String outputStr = new String(decrypt); System.err.println(\"加密前：\\n\" + inputStr); System.err.println(\"解密后：\\n\" + outputStr); &#125; /**** * 私钥加密---公钥解密 * @throws Exception */ public static void test2()throws Exception&#123; System.err.println(\"私钥加密---公钥解密\"); String inputStr = \"数字签名\"; byte[] data = inputStr.getBytes(); //私钥加密 byte[] encodedData = CertificateCoder.encryptByPriateKey(data, keyStorePath, alias, password); //公钥加密 byte[] decodeData = CertificateCoder.decryptByPublicKey(encodedData, certificatePath); String outputStr = new String (decodeData); System.err.println(\"加密前：\\n\" + inputStr); System.err.println(\"解密后：\\n\" + outputStr); &#125; public static void testSign()throws Exception&#123; String inputStr = \"签名\"; byte[] data = inputStr.getBytes(); System.err.println(\"私钥签名---公钥验证\"); //产生签名 byte[] sign = CertificateCoder.sign(data, keyStorePath, alias, password); System.err.println(\"签名:\\n\" + Hex.encodeHexString(sign)); //验证签名 boolean status = CertificateCoder.verify(data, sign, certificatePath); System.err.println(\"状态：\\n \" + status); &#125; RSA非对称加密的2个用途及在HTTPS加密（防窃听） RSA非对称加密会用到一对密钥，分别称为公钥和私钥，公钥加密之后的数据可以通过私钥来进行解密，私钥加密的数据也同样可以用对应的公钥进行解密。在web数据传输过程中，由于客户端和服务器端是多对一的关系，因此可以让所有的客户端持有相同的公钥，服务器持有私钥，这样一来就能方便地实现数据的加密传输。 签名（防篡改） 由于私钥只在某一个体手中，因此可以通过这一点来进行身份识别。比如用户A和B分别有一对密钥中的私钥和公钥，现在A向B发送消息”abc”，可进行如下操作：A用私钥对该文本进行加密之后变成密文”#￥%”，并附加上原文，组合成文本”#￥%：abc”(冒号起分隔作用，并无其他含义，具体实现中可自行处理)一起发送，B接收到该文本之后利用公钥对密文进行解密，将得到的解密后文本与传送过来的文本”abc”之间进行比对，如果一切正常，那么公钥解密之后的文本就是私钥加密之前的文本”abc”，比对结果一致，因此可以说明这段”abc”文本确实是A发送过来的，因为只有A才有对文本进行签名的私钥。能得到这个结论的前提是——A所用的私钥跟B所用的公钥确实是一对。 假如在传送途中别人篡改了”abc”，改成”aaa”，由于中间人没有A所持有的私钥，因此无法对篡改之后的数据生成新的正确签名，那么B在收到数据之后用公钥进行解密，再与传送的文本进行比对的话就不会一致。或者中间人篡改了数据之后用另一私钥对篡改之后的数据进行签名，同样由于B没有中间人的私钥对应的公钥，因此比对也不会一致。记住一点：B的公钥所对应的私钥只在A的手中，因此比对一致就说明该文本来自A。 https如何保证安全？如何保证客户端所持有的公钥就是某合法服务器声明的公钥？ 如果不能保证这一点，那么客户端发送的信息就有可能存在被窃听的危险，因为用此公钥加密的数据可以被其对应的私钥拥有者获取，而该私钥并不在客户端所认为的服务器上。因此可采用一个权威机构进行证书的颁发，所谓证书就是包含了服务器声明的公钥以及组织名称等信息，这里我们只考虑最关键的公钥信息。该权威机构会对申请证书的组织进行审核，确保其身份合法，然后将服务器公钥信息发布给客户端，客户端可利用该公钥与对应的服务器进行通信。整个过程可归纳为以下几步：1、服务器生成一对密钥，私钥自己留着，公钥交给数字证书认证机构（CA）2、CA进行审核，并用CA自己的私钥对服务器提供的公钥进行签名（参照上文RSA签名）3、客户端从CA获取证书（即服务器端公钥），用CA的公钥对签名的证书进行验证，比对一致，说明该服务器公钥确实是CA颁发的（得此结论有一个前提就是：客户端的CA公钥确实是CA的公钥，即该CA的公钥与CA对证书进行签名的私钥确实是一对。参照上文RSA签名中所论述的情况），而CA又作为权威机构保证该公钥的确是服务器端提供的，从而可以确认该证书中的公钥确实是合法服务器端提供的 注：为保证第3步中提到的前提条件，CA的公钥必须要安全地转交给客户端，因此，CA的公钥一般来说由浏览器开发商内置在浏览器的内部。于是，该前提条件在各种信任机制上，基本保证成立。由此可见：所谓的安全的HTTP，其实也是要建立在信任的机制上。 总结：整个过程涉及2对公私密钥对，一对由服务器产生，用于加密，一对由CA产生，用于签名。整个过程还涉及2个信任：客户端信任CA，CA发布的证书中的公钥就是合法服务器的公钥。客户端信任浏览器内置的CA公钥就是与CA私钥对应的公钥。最后要说明的是，非对称加密在https中只是用来对对称加密密钥进行协商的过程才使用，在两端协商完对称加密的密钥之后，数据的加密传输均采用对称加密的方式。 HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握手过程中将确立双方加密传输数据的密码信息。TLS/SSL协议不仅仅是一套加密传输的协议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用了非对称加密，对称加密以及HASH算法。握手过程的具体描述如下：1234567891011121. 浏览器将自己支持的一套加密规则发送给网站。 2.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 3.浏览器获得网站证书之后浏览器要做以下工作： a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。 b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。 c) 使用约定好的HASH算法计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。 4.网站接收浏览器发来的数据之后要做以下的操作： a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。 b) 使用密码加密一段握手消息，发送给浏览器。 5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。 linux下生成https的crt和key证书http://blog.csdn.net/xuplus/article/details/51613883linux下openssl生成 签名的步骤：x509证书一般会用到三类文，key，csr，crt。Key 是私用密钥openssl格，通常是rsa算法。Csr 是证书请求文件，用于申请证书。在制作csr文件的时，必须使用自己的私钥来签署申，还可以设定一个密钥。crt是CA认证后的证书文，（windows下面的，其实是crt），签署人用自己的key给你签署的凭证。 1.key的生成openssl genrsa -des3 -out server.key 2048这样是生成rsa私钥，des3算法，openssl格式，2048位强度。server.key是密钥文件名。为了生成这样的密钥，需要一个至少四位的密码。可以通过以下方法生成没有密码的key:openssl rsa -in server.key -out server.key server.key就是没有密码的版本了。 生成CA的crtopenssl req -new -x509 -key server.key -out ca.crt -days 3650生成的ca.crt文件是用来签署下面的server.csr文件。 csr的生成方法openssl req -new -key server.key -out server.csr需要依次输入国家，地区，组织，email。最重要的是有一个common name，可以写你的名字或者域名。如果为了https申请，这个必须和域名吻合，否则会引发浏览器警报。生成的csr文件交给CA签名后形成服务端自己的证书。 crt生成方法CSR文件必须有CA的签名才可形成证书，可将此文件发送到verisign等地方由它验证，要交一大笔钱，何不自己做CA呢。openssl x509 -req -days 3650 -in server.csr -CA ca.crt -CAkey server.key -CAcreateserial -out server.crt输入key的密钥后，完成证书生成。-CA选项指明用于被签名的csr证书，-CAkey选项指明用于签名的密钥，-CAserial指明序列号文件，而-CAcreateserial指明文件不存在时自动生成。最后生成了私用密钥：server.key和自己认证的SSL证书：server.crt证书合并：cat server.key server.crt &gt; server.pem 什么是数字签名和证书？http://www.jianshu.com/p/9db57e7612551.信息安全三要素 信息安全中有三个需要解决的问题： 保密性(Confidentiality)：信息在传输时不被泄露 完整性（Integrity）：信息在传输时不被篡改 有效性（Availability）：信息的使用者是合法的这三要素统称为CIA Triad。 公钥密码解决保密性问题 数字签名解决完整性问题和有效性问题 2.数字签名 现实生活中，签名有什么作用？在一封信中，文末的签名是为了表示这封信是签名者写的。计算机中，数字签名也是相同的含义：证明消息是某个特定的人，而不是随随便便一个人发送的（有效性）；除此之外，数字签名还能证明消息没有被篡改（完整性）。 简单来说，数字签名（digital signature）是公钥密码的逆应用：用私钥加密消息，用公钥解密消息。 用私钥加密的消息称为签名，只有拥有私钥的用户可以生成签名。 用公钥解密签名这一步称为验证签名，所有用户都可以验证签名(因为公钥是公开的) 一旦签名验证成功，根据公私钥数学上的对应关系，就可以知道该消息是唯一拥有私钥的用户发送的，而不是随便一个用户发送的。 由于私钥是唯一的，因此数字签名可以保证发送者事后不能抵赖对报文的签名。由此，消息的接收者可以通过数字签名，使第三方确信签名人的身份及发出消息的事实。当双方就消息发出与否及其内容出现争论时，数字签名就可成为一个有力的证据。 生成签名 一般来说，不直接对消息进行签名，而是对消息的哈希值进行签名，步骤如下。 对消息进行哈希计算，得到哈希值 利用私钥对哈希值进行加密，生成签名 将签名附加在消息后面，一起发送过去 验证签名 收到消息后，提取消息中的签名 用公钥对签名进行解密，得到哈希值1。 对消息中的正文进行哈希计算，得到哈希值2。 比较哈希值1和哈希值2，如果相同，则验证成功。 3.证书 证书实际上就是对公钥进行数字签名，它是对公钥合法性提供证明的技术。 考虑这样一种场景：我们对签名进行验证时，需要用到公钥。如果公钥也是伪造的，那怎么办？如果公钥是假的，验证数字签名那就无从谈起，根本不可能从数字签名确定对方的合法性。这时候证书就派上用场了。 证书一般包含：公钥（记住证书中是带有公钥的），公钥的数字签名，公钥拥有者的信息若证书验证成功，这表示该公钥是合法，可信的。 接下来又有问题了：验证证书中的数字签名需要另一个公钥，那么这个公钥的合法性又该如何保证？该问题可以无限循环下去，岂不是到不了头了？这已经是个社会学问题了。我们为什么把钱存进银行？因为我们相信银行，它是一个可信的机构（虽然也有破产的风险）。跟银行一样，我们需要一个可信的机构来颁发证书和提供公钥，只要是它提供的公钥，我们就相信是合法的。 这种机构称为认证机构(Certification Authority， CA)。CA就是能够认定”公钥确实属于此人”，并能生成公钥的数字签名的组织或机构。CA有国际性组织和政府设立的组织，也有通过提供认证服务来盈利的组织。 如何生成证书？ 服务器将公钥A给CA（公钥是服务器的） CA用自己的私钥B给公钥A加密，生成数字签名A CA把公钥A，数字签名A，附加一些服务器信息整合在一起，生成证书，发回给服务器。注：私钥B是用于加密公钥A的，私钥B和公钥A并不是配对的。 如何验证证书？ 客户端得到证书 客户端得到证书的公钥B（通过CA或其它途径） 客户端用公钥B对证书中的数字签名解密，得到哈希值 客户端对公钥进行哈希值计算 两个哈希值对比，如果相同，则证书合法。注：公钥B和上述的私钥B是配对的，分别用于对证书的验证（解密）和生成（加密）。 证书作废 当用户私钥丢失、被盗时，认证机构需要对证书进行作废(revoke)。要作废证书，认证机构需要制作一张证书作废清单(Certificate Revocation List)，简称CRL 假设我们有Bob的证书，该证书有合法的认证机构签名，而且在有效期内，但仅凭这些还不能说明该证书一定有效，还需要查询认证机构最新的CRL，并确认该证书是否有效。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"[读书笔记]chapter2-分布式基础设施-大型网站分布式架构与设计实践","slug":"读书笔记-chapter2-分布式基础设施-大型网站分布式架构与设计实践","date":"2017-12-17T05:02:13.000Z","updated":"2017-12-17T06:38:27.033Z","comments":true,"path":"2017/12/17/读书笔记-chapter2-分布式基础设施-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter2-分布式基础设施-大型网站分布式架构与设计实践/","excerpt":"","text":"分布式系统的支撑系统： 协作及配置管理:Zookeeper 缓存:Redis 消息:ActiveMQ 持久化存储:MySQL,HBase 搜索引擎:Lucene,solr,ElastickSearch CDN 负载均衡:F5,HAProxy,Nginx,SQLProxy 运维自动化 计算:Spark,Spark Streaming,Storm 分布式文件系统:HDFS,FastDfs 日志收集系统:Kafka,ELK 监控系统:Zabbix MySQL高可用方案：(Double)Master-Slave Replication、分库与分表。Master-Slave Replication基于master的binary log进行数据的同步。分库分表的缺点：难以多表关联查询，事务提升到分布式事务，扩容不便会导致数据迁移.考虑点：业务拆分、海量数据带来的单表数据量过大问题、查询效率，高并发访问压力，复杂查询的支持、单点故障。 HBase:分布式列存储关系数据库。集群包含:HMaster和HRegionServer.缺点：支持的查询维度有限，且难以支持复杂查询，如group by,order by,join等。 JMS2种传输模式:Point-to-Point(p2p)模型，Pub/Sub(Publish/Subscribe)模型. 前者称为点对点模型，基于queue，后者称为发布/订阅模型，基于topic。ActiveMQ支持Master-Slave架构，在该架构上，基于恭喜文件系统或共享数据库实现failover(故障转移).ActiveMQ高可用方案:Master-Slave、拆分broker 分库分表、HBase等都会涉及复杂查询的问题，在这个时候，我们可以考虑使用分布式搜索引擎, 如基于Lucene实现的solr和ElasticSearch。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"[读书笔记]chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践","slug":"读书笔记-chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践","date":"2017-12-17T04:57:41.000Z","updated":"2017-12-17T06:38:27.033Z","comments":true,"path":"2017/12/17/读书笔记-chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践/","link":"","permalink":"http://xbynet.top/2017/12/17/读书笔记-chapter1-SOA面向服务的体系架构-大型网站分布式架构与设计实践/","excerpt":"","text":"分布式应用架构的演变：单一应用-》垂直应用-》分布式应用.垂直应用缺点：通过业务划分，将流量分散到不同的子系统，但子系统见可能存在重叠业务，需要重复造轮子，且容易形成信息孤岛。分布式应用核心：(微)服务化。 协议：基于TCP协议的RPC，基于Http协议的Restful。前者特点是由于处于网络协议的第四层，因此报文较小，网络开销小，性能高，但实现的代价高(不过目前国内有dubbo这个比较成熟的解决方案)，不跨语言；而后者基于网络协议的第7层，可以支持JSON&amp;XML格式数据传输，利于跨语言(目前主流为SpringCloud)。 基于TCP协议的RPCRPC(Remote Process Call):实现又RMI,WebService,Dubbo.涉及服务的提供者和调用方，及参数及结果的序列化。同时伴随着服务的数目增多及服务压力增加：又需要考虑服务分组隔离、服务路由(router)及负载均衡(Load Balance)。 对象的序列化方案：Java本身的,Hessian,Google protobuffer,JSON,xml. 服务的路由和负载均衡服务化(SOA,Service-Oriented Architecture):剥离公共服务，分离不同业务服务。负载均衡方案：硬件负载均衡如F5，软件解决：HAProxy，Ngyinx，LVS，Zookeeper等为了避免服务路由的单点故障，需要一个可以动态注册和获取服务信息的地方，来统一管理服务名称和其对应服务器列表信息，称之为服务配置中心。服务启动时自动将名称、地址注册到服务配置中心，服务消费者通过配置中心来获取机器列表，通过相应的负载均衡算法，选取其中一台服务器进行调用。当服务器宕机或下线时，需要能够动态地从服务配置中心里面移除，并通知相应的服务消费者。(这就是去中心化)。Zookeeper是一个很好的实现。负载均衡算法：轮询(Round Robin)法、随机(Random) 法、源地址哈希法、加权轮询法、加权随机法、最小连接法等.最好可以动态配置负载均衡规则，以满足千变万化的需求。Zookeeper：集群搭建略。客户端推荐zkClient,可以解决ZooKeeper API的一些繁琐问题，如一次性watcher问题，session重建问题等，它将watcher机制转换为一种更加容易理解的订阅模式，并且这种关系可以保持，而非一次性的。 Http服务网关基于网关(gateway)的安全架构:来自外部的请求先经过网关进行权限和安全校验，校验通过后再根据传入的服务名称，去寻找调用服务，最后通过网关返回结果。此时，服务提供者是不直接对外开放的。那么此时需要在网关前面加上一层负载均衡集群，而网关本身也采用集群模式。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://xbynet.top/categories/读书笔记/"},{"name":"大型网站分布式架构与设计实践","slug":"读书笔记/大型网站分布式架构与设计实践","permalink":"http://xbynet.top/categories/读书笔记/大型网站分布式架构与设计实践/"}],"tags":[{"name":"soa","slug":"soa","permalink":"http://xbynet.top/tags/soa/"},{"name":"msa","slug":"msa","permalink":"http://xbynet.top/tags/msa/"},{"name":"架构","slug":"架构","permalink":"http://xbynet.top/tags/架构/"}]},{"title":"使用hexo搭建博客","slug":"使用hexo搭建博客","date":"2017-12-16T15:32:09.000Z","updated":"2017-12-17T06:38:27.033Z","comments":true,"path":"2017/12/16/使用hexo搭建博客/","link":"","permalink":"http://xbynet.top/2017/12/16/使用hexo搭建博客/","excerpt":"好处:免费、强大、可迁移、markdown+git组合 创建仓库新建一个名为你的用户名.github.io的仓库，比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 http://test.github.io 了仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久。 绑定域名将CNAME指向你的用户名.github.io然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名在你绑定了新域名之后，原来的你的用户名.github.io会自动跳转到你的新域名。","text":"好处:免费、强大、可迁移、markdown+git组合 创建仓库新建一个名为你的用户名.github.io的仓库，比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 http://test.github.io 了仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久。 绑定域名将CNAME指向你的用户名.github.io然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名在你绑定了新域名之后，原来的你的用户名.github.io会自动跳转到你的新域名。 配置SSH keyssh-keygen -t rsa -C &quot;邮件地址&quot;找到.ssh\\id_rsa.pub文件，记事本打开并复制里面的内容，打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key。测试是否成功$ ssh -T git@github.com # 注意邮箱地址不用改 此时你还需要配置：12$ git config --global user.name &quot;xbynet&quot;// 你的github用户名，非昵称$ git config --global user.email &quot;xxx@xxx.com&quot;// 填写你的github注册邮箱 使用hexo写博客Hexo是一个简单、快速、强大的基于 Github Pages 的博客发布工具，支持Markdown格式，有众多优秀插件和主题。官网： http://hexo.iogithub: https://github.com/hexojs/hexo 由于github pages存放的都是静态文件，博客存放的不只是文章内容，还有文章列表、分类、标签、翻页等动态内容，假如每次写完一篇文章都要手动更新博文目录和相关链接信息，相信谁都会疯掉，所以hexo所做的就是将这些md文件都放在本地，每次写完文章后调用写好的命令来批量完成相关页面的生成，然后再将有改动的页面提交到github。 安装之前先来说几个注意事项：很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行；hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导；hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的；12345$ npm install -g hexo$ hexo init$ hexo g # 生成$ hexo s # 启动服务 执行以上命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的：hexo s是开启本地预览服务，打开浏览器访问 http://localhost:4000 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故 修改主题采用hexo-theme-next修改_config.yml中的theme: landscape改为theme: next. 保留CNAME、README.md等文件提交之后网页上一看，发现以前其它代码都没了，此时不要慌，一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的 常用hexo命令12345678910111213141516hexo new &quot;postName&quot; #新建文章hexo new page &quot;pageName&quot; #新建页面hexo generate #生成静态页面至public目录hexo server #开启预览访问端口（默认端口4000，&apos;ctrl + c&apos;关闭server）hexo deploy #部署到GitHubhexo help # 查看帮助hexo version #查看Hexo的版本缩写：hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy组合命令：hexo s -g #生成并本地预览hexo d -g #生成并上传 _config.yml:这里面都是一些全局配置，每个参数的意思都比较简单明了，所以就不作详细介绍了。需要特别注意的地方是，冒号后面必须有一个空格，否则可能会出问题。 上传到github首先，ssh key肯定要配置好。其次，配置_config.yml中有关deploy的部分：1234567891011正确写法：deploy: type: git repository: git@github.com:liuxianan/liuxianan.github.io.git branch: master 错误写法：deploy: type: github repository: https://github.com/liuxianan/liuxianan.github.io.git branch: master 12npm install hexo-deployer-git --savehexo d -g #生成并上传 遇到的问题：https://stackoverflow.com/questions/17846529/could-not-open-a-connection-to-your-authentication-agenthttps://stackoverflow.com/questions/22575662/filename-too-long-in-git-for-windows如果遇到git not found之类的错误，请使用git bash 而非cmd如果遇到Permission denyed:1、请检查密钥2、可能是没有加载私钥到ssh-agent,到.ssh目录下执行:12eval $(ssh-agent)ssh-add id_rsa 3、git for windows下的Filename too long1git config --global core.longpaths true 写博客定位到我们的hexo根目录，执行命令：hexo new &#39;my-first-blog&#39;hexo会帮我们在source/_posts下生成相关md文件,我们只需要打开这个文件就可以开始写博客了当然你也可以直接自己新建md文件，用这个命令的好处是帮我们自动生成了时间。一般完整格式如下：123456789---title: postName #文章页面上的显示名称，一般是中文date: 2013-12-02 15:30:16 #文章生成时间，一般不改，当然也可以任意修改categories: 默认分类 #分类tags: [tag1,tag2,tag3] #文章标签，可空，多标签请用格式，注意:后面有个空格description: 附加一段文章摘要，字数最好在140字以内，会出现在meta的description里面---以下是正文 那么hexo new page ‘postName’命令和hexo new ‘postName’有什么区别呢？1hexo new page &quot;my-second-blog&quot; 最终部署时生成：hexo\\public\\my-second-blog\\index.html，但是它不会作为文章出现在博文目录。 如何让博文列表不显示全部内容默认情况下，生成的博文目录会显示全部的文章内容，如何设置文章摘要的长度呢？答案是在合适的位置加上即可. 12345678910111213# 前言使用github pages服务搭建博客的好处有：1. 全是静态文件，访问速度快；2. 免费方便，不用花一分钱就可以搭建一个自由的个人博客，不需要服务器不需要后台；3. 可以随意绑定自己的域名，不仔细看的话根本看不出来你的网站是基于github的；&lt;!--more--&gt;4. 数据绝对安全，基于github的版本管理，想恢复到哪个历史版本都行；5. 博客内容可以轻松打包、转移、发布到其它平台；6. 等等； 如何支持目录：为文章添加 toc: true Toc虽然生成了，审查元素看锚也有，但是无法点击:(差了很久，也搜了issues，但是没人遇到和我类似的问题。。。)修改next/layout/_scripts/vendors.swig，添加 12345678910&lt;script&gt; $(function()&#123; $(\".nav-item .nav-link\").each(function(i)&#123; $(this).text($(this).attr(\"href\").replace('#','')); $(this).parent().contents().filter(function() &#123; return this.nodeType == 3; //Node.TEXT_NODE &#125;).remove(); &#125;); &#125;);&lt;/script&gt; 404页面:在source下新建一个404.html文件即可,建议采用腾讯公益404，如下： 1234567891011121314&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8;\"/&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\" /&gt; &lt;meta name=\"robots\" content=\"all\" /&gt; &lt;meta name=\"robots\" content=\"index,follow\"/&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=\"text/javascript\" src=\"//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js\" charset=\"utf-8\" homePageUrl=\"/\" homePageName=\"返回主页\"&gt;&lt;/script&gt; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 配置markdown解析器，这个官方文档没有说明，但是由于hexo采用hexo-renderer-marked,故而可以参考hexo-renderer-marked文档:12345678910marked: gfm: true pedantic: false sanitize: false tables: true breaks: true smartLists: true smartypants: true modifyAnchors: &apos;&apos; autolink: true 安装插件：如报ERROR Deployer not found: git,请执行：npm install --save hexo-deployer-git1、sitemap、feed插件$ npm install hexo-generator-sitemap hexo-generator-feed hexo-generator-baidu-sitemap --save启用，修改Hexo_config.yml，增加以下内容 123456789sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xmfeed: type: atom path: atom.xml limit: 100 添加“Fork me on Github” ribbon给blog主页添加一个“Fork me on Github”的绶带（ribbon）那么将下面的代码（注意将you改为你自己的github上的注册名）,添加到next/layout/_layout.swig的body结束标签之前 (注意：这是next主题的地址，其他主题可能不一致):1&lt;a href=&quot;https://github.com/xbynet&quot;&gt;&lt;img style=&quot;position: absolute; top: 0; left: 0; border: 0;&quot; src=&quot;https://camo.githubusercontent.com/567c3a48d796e2fc06ea80409cc9dd82bf714434/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f6769746875622f726962626f6e732f666f726b6d655f6c6566745f6461726b626c75655f3132313632312e706e67&quot; alt=&quot;Fork me on GitHub&quot; data-canonical-src=&quot;https://s3.amazonaws.com/github/ribbons/forkme_left_darkblue_121621.png&quot;&gt;&lt;/a&gt; 插入音乐:两种方式，在线和离线。在线的可以采用网易云音乐的外链播放，不过是一个iframe。离线/在线直播源播放可以采用hexo-tag-aplayer.安装后，修改next/layout/_custom/sidebar.swig:123456789101112131415161718192021222324&lt;div id=&quot;aplayer1&quot; class=&quot;aplayer&quot;&gt;&lt;/div&gt;&lt;script src=&quot;/asserts/js/APlayer.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt; var ap = new APlayer(&#123; element: document.getElementById(&apos;aplayer1&apos;), narrow: false, autoplay: false, showlrc: false, mutex: true, theme: &apos;#e6d0b2&apos;, preload: &apos;metadata&apos;, mode: &apos;circulation&apos;, music: &#123; title: &apos;素雨&apos;, author: &apos;孙雪宁&apos;, url: &apos;http://ws.stream.qqmusic.qq.com/C1000040LV2h3FzIVl.m4a?fromtag=38&apos;, pic: &apos;https://y.gtimg.cn/music/photo_new/T002R300x300M000003mxnKZ0WbTPc.jpg?max_age=2592000&apos; &#125; &#125;);&lt;/script&gt;&lt;!-- &lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=28815250&amp;auto=0&amp;height=66&quot;&gt;&lt;/iframe&gt;--&gt; 如何寻找在线音乐源地址:http://music.liuzhijin.cn/ 参考：https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.htmlhttps://segmentfault.com/a/1190000006831597https://www.cnblogs.com/zhcncn/p/4097881.htmlhttps://github.com/litten/BlogBackuphttp://www.jianshu.com/p/f054333ac9e6","categories":[{"name":"杂项","slug":"杂项","permalink":"http://xbynet.top/categories/杂项/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://xbynet.top/tags/hexo/"},{"name":"github","slug":"github","permalink":"http://xbynet.top/tags/github/"}]}]}